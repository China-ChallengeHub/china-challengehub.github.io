[{"categories":["技术博客"],"content":"1 图学习任务 我们简单回顾下，上一节我们介绍了，图的机器学习任务主要是以下三种：\n Node Level:节点级别 Link Level：边级别 Graph Level：图级别å 并且三部分难度依次是由浅入深的   2 传统ML流程  定义和设计节点/边/图的特征 对所有训练数据构造特征  训练ML模型 （1）随机森林 （2）支持向量机 （3）神经网络等 应用模型 给定一个新的节点、边、图，然后获取特征进行预测   我们总结下 基于Graph的机器学习相关概念和流程，首先明确下目标\n目标：对一些对象集合进行预测，比如是分类或者回归任务 特征设计：\n 特征:d-dimensional向量 对象：Nodes，edges，或者是graps 目标函数：结合具体任务设计目标函数，如下图所示给定一个图G(V,E)，其中V代表节点集合，E代表边集合，然后学习节点到向量空间R的映射函数，也就是我们要学习权重参数W    为了方便，我们下面的例子是基于无向图(undirected grpah)进行解释的。\n 3 节点级别的相关任务 基于图中带有标签的节点训练模型，然后预测未标注节点的标签， 在这里我们主要阐述下Node的四种特征：\n Node degree:节点的度 Node centrality:节点的中度 Clustering coefficient:相似性 Graphlets:图元   节点的度\n kv代表是节点v与邻居节点相连边的个数 所有邻居节点都是相等的  如下图所示，A的度为1，B的度为2，C的度为3，D的度为4 节点的中心度 Node Centrality\n 节点的度只计算了相连节点的个数，但是没有评估节点的重要性 节点的中心度$c_v$考虑了节点在图中的重要程度 节点的中心度有很多种计算方式： (1) Engienvector centrality:特征向量中心性 (2) Betweenness centrality:中介中心性 (3) Closeness centrality:紧密中心性 (4) 其他方式  Eigenvector centrality:特征向量中心性\n 如果一个节点的邻居节点们$u\\in N(v)$越重要，那么该节点$v$就越重要 我们将节点𝑣的中心性建模为相邻节点的中心性之和： $c_v=\\frac{1}{\\lambda}\\sum_{u \\in N(v)}{c_u}$ 其中$\\lambda$为一个正常数。 我们注意到上面的等式是通过递归的方式来计算度度中心性的，所有我们应该怎么求解  $c_v=\\frac{1}{\\lambda}\\sum_{u \\in N(v)}{c_u} \\iff \\lambda c=Ac$\n其中$\\lambda$为正常数，$A$为邻接矩阵，如果$u \\in N(v)$ ,那么$A_{uv}=1$\n 我们可以看到度中心性是一个特征向量(eigenvector)，根据非负矩阵定理(Perron-Frobenius Theorem)我们可以知道$\\lambda_{max}$是一个正值并且是唯一的，特征向量$c_{max}$当做度中心性。  通常来说，有许多不同的特征值$\\lambda$ 能使得一个特征方程有非零解存在。然而，考虑到特征向量中的所有项均为非负值，根据佩伦-弗罗贝尼乌斯定理，只有特征值最大时才能测量出想要的中心性。然后通过计算网络中的节点$v$其特征向量的相关分量$v^{th}$便能得出其对应的中心性的分数。\n 特征向量的定义只有一个公因子，因此各节点中心性的比例可以很好确定。为了确定一个绝对分数，必须将其中一个特征值标准化，例如所有节点评分之和为1或者节点数 n。幂次迭代是许多特征值算法中的一种，该算法可以用来寻找这种主导特征向量。此外，以上方法可以推广，使得矩阵A中每个元素可以是表示连接强度的实数，例如随机矩阵。\u0026mdash;特征向量中心性wiki\n 这里其实涉及到比较多的线性代数的理论以及矩阵分析的算法，我特意查了一些文章帮大家去回顾和理解下这里涉及到的知识： (1) 线性代数之——特征值和特征向量 (2)非负矩阵之Perron-Frobenius定理 (3)非负矩阵 (4)干货 | 万字长文带你复习线性代数！  我们这里再通过文章谁是社会网络中最重要的人？ 解释特征向量中心性： 特征向量中心性的基本思想是，一个节点的中心性是相邻节点中心性的函数。也就是说，与你连接的人越重要，你也就越重要。\n特征向量中心性和点度中心性不同，一个点度中心性高即拥有很多连接的节点特征向量中心性不一定高，因为所有的连接者有可能特征向量中心性很低。同理，特征向量中心性高并不意味着它的点度中心性高，它拥有很少但很重要的连接者也可以拥有高特征向量中心性。\n考虑下面的图，以及相应的5x5的邻接矩阵(Adjacency Matrix)，A。\n邻接矩阵的含义是，如果两个节点没有直接连接，记为0，否则记为1。\n现在考虑x，一个5x1的向量，向量的值对应图中的每个点。在这种情况下，我们计算的是每个点的点度中心性（degree centrality），即以点的连接数来衡量中心性的高低。\n矩阵A乘以这个向量的结果是一个5x1的向量：\n结果向量的第一个元素是用矩阵A的第一行去“获取”每一个与第一个点有连接的点的值（连接数，点度中心性），也就是第2个、第3个和第4个点的值，然后将它们加起来。\n换句话说，邻接矩阵做的事情是将相邻节点的求和值重新分配给每个点。这样做的结果就是“扩散了”点度中心性。你的朋友的朋友越多，你的特征向量中心性就越高。\n我们继续用矩阵A乘以结果向量。如何理解呢？实际上，我们允许这一中心性数值再次沿着图的边界“扩散”。我们会观察到两个方向上的扩散（点既给予也收获相邻节点）。我们猜测，这一过程最后会达到一个平衡，特定点收获的数量会和它给予相邻节点的数量取得平衡。既然我们仅仅是累加，数值会越来越大，但我们最终会到达一个点，各个节点在整体中的比例会保持稳定。\n现在把所有点的数值构成的向量用更一般的形式表示：\n我们认为，图中的点存在一个数值集合，对于它，用矩阵A去乘不会改变向量各个数值的相对大小。也就是说，它的数值会变大，但乘以的是同一个因子。用数学符号表示就是：\n满足这一属性的向量就是矩阵M的特征向量。特征向量的元素就是图中每个点的特征向量中心性。\n特征向量中心性的计算需要读者具备矩阵乘法和特征向量的知识，但不影响这里读者对特征向量中心性思想的理解，不再赘述。\nBetweenness centrality:中介中心性 如果一个节点位于很多条其他节点的最短路径上，那么改节点比较重要，定义如下： $c_{v}=\\sum_{s\\not=v\\not=t}{\\frac{#(shortes,paths ,betwen ,𝑠 , and , 𝑡 , that ,contain ,𝑣)}{#(shortest ,paths ,between ,\u0026lsquo;𝑠\u0026rsquo; ,and ,\u0026lsquo;𝑡\u0026rsquo;)}}$ 我们可以看一个下面的例子： 假设我们要计算D的中介中心性：\n 首先，我们计算节点D之外，所有节点对之间的最短路径有多少条，这里是1条（在5个节点中选择两个节点即节点对的个数）。 然后，我们再看所有这些最短路径中有多少条经过节点D，例如节点A要想找到节点E，必须经过节点D。经过节点D的最短路径有3条（A-C-D-E，B-D-E，C-D-E）。 最后，我们用经过节点D的最短路径除以所有节点对的最短路径总数，这个比率就是节点D的中介中心性。节点D的中介中心性是3/1=3。  4 PyTorch Geometric教程 官方文档：https://pytorch-geometric.readthedocs.io/en/latest/index.html\nPyTorch Geometric（PyG）是PyTorch的扩展库。 它提供了有用的框架来开发图深度学习模型，包括各种图神经网络层和大量基准数据集。\n如果我们暂时不了解某些概念，例如“ GCNConv”，请不要担心，之后我们将在以后的文章中介绍这些概念。\n这个教程来自： https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=ci-LpZWhRJoI by Matthias Fey 大家可以参照colab教程直接运行\n4.1 PyG安装  查看当前torch和cuda版本  !python -c \u0026quot;import torch; print(torch.__version__)\u0026quot; 输出：1.6.0\n!python -c \u0026quot;import torch; print(torch.version.cuda)\u0026quot; 输出：10.1\n 安装gpu版本  # 安装GPU版本 !pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html !pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html !pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html !pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html !pip install torch-geometric 可能安装gpu版本比较麻烦，大家可以多参照下官网进行安装： https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n 安装cuda版本  !pip install torch-scatter==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.6.0.html !pip install torch-sparse==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.6.0.html !pip install torch-cluster==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.6.0.html !pip install torch-spline-conv==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.6.0.html !pip install torch-geometric 4.2 PyG数据集 PyTorch Geometric 可以通过 torch_geometric.datasets 快速的获取默认的数据集:\nhttps://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html\n一共有20+种数据，比较丰富~\n# 导入空手道俱乐部数据集 from torch_geometric.datasets import KarateClub dataset = KarateClub() print(f'Dataset: {dataset}:') print('======================') print(f'Number of graphs: {len(dataset)}') print(f'Number of features: {dataset.num_features}') print(f'Number of classes: {dataset.num_classes}') 输出：\nDataset: KarateClub(): ====================== Number of graphs: 1 Number of features: 34 Number of classes: 4 初始化[KarateClub]（https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.KarateClub） 数据集之后，我们首先可以检查其某些属性。 例如，我们可以看到该数据集恰好有一个Graph，并且该数据集中的每个节点都被分配了** 34维特征向量**（唯一地描述了空手道俱乐部的成员）。 此外，该图正好包含** 4个类别**，代表每个节点所属的社区。\n现在让我们更详细地看一下这个Graph：\ndata = dataset[0] # 获取graph对象. print(data) print('==============================================================') # 获取一些graph的统计信息. print(f'Number of nodes: {data.num_nodes}') # 节点的个数 print(f'Number of edges: {data.num_edges}') # 边的个属于 print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}') # 节点的度平均数 print(f'Number of training nodes: {data.train_mask.sum()}') print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}') print(f'Contains isolated nodes: {data.contains_isolated_nodes()}') print(f'Contains self-loops: {data.contains_self_loops()}') print(f'Is undirected: {data.is_undirected()}') 输出如下：\n Data(edge_index=[2, 156], train_mask=[34], x=[34, 34], y=[34]) ============================================================== Number of nodes: 34 Number of edges: 156 Average node degree: 4.59 Number of training nodes: 4 Training node label rate: 0.12 Contains isolated nodes: False Contains self-loops: False Is undirected: True 通过上面的信息我们可以发现，这个KarateClub网络图一共有34个节点，边的个数为1，每个节点度的平均数有4.59，是一个无向图等等。\n4.3 Data对象 PyTorch Geometric中的每个图形都由单个[Data]（https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data）对象表示，该对象包含所有 描述其图形表示的信息。 我们可以随时通过print（data）打印数据对象，以接收有关其属性及其形状的简短介绍：\nData(edge_index=[2, 156], x=[34, 34], y=[34], train_mask=[34]) 我们可以看到这个data对象拥有4个属性： （1）“ edge_index”属性保存有关“图形连接性”（即*）的信息，即每个边缘的源节点和目标节点索引的元组。 PyG进一步将 （2）节点特征**称为x（向34个节点中的每个节点分配了34维度的特征向量），将 （3）节点标记**称为y（每个节点仅分配给一个类别）。 （4）还有一个名为“ train_mask”的附加属性，它描述了我们已经知道其社区归属的节点。 总体而言，我们只知道4个节点的基本标签（每个社区一个），任务是推断其余节点的社区分配。\n数据对象还提供了一些“实用功能”来推断基础图的一些基本属性。 例如，我们可以轻松推断图中是否存在孤立的节点（* ie *任何节点都没有边），图是否包含自环(*i.e.*, $(v, v) \\in \\mathcal{E}$)，或者图形是否是无向的（ (*i.e.*, for each edge $(v, w) \\in \\mathcal{E}$ there also exists the edge $(w, v) \\in \\mathcal{E}$).\nfrom IPython.display import Javascript # Restrict height of output cell. display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})''')) edge_index = data.edge_index # 打印节点 print(edge_index.t()) 输出：\ntensor([[ 0, 1], [ 0, 2], [ 0, 3], [ 0, 4], [ 0, 5], [ 0, 6], [ 0, 7], [ 0, 8], [ 0, 10], .... [33, 31], [33, 32]]) 通过打印“ edge_index”，我们可以进一步了解PyG如何在内部表示图形连接。 我们可以看到，对于每个边缘，“ edge_index”都包含两个节点索引的元组，其中第一个值描述源节点的节点索引，第二个值描述边缘目标节点的节点索引。\n这种表示称为** COO格式（坐标格式）**，通常用于表示稀疏矩阵。 代替以密集表示形式保存邻接信息 $\\mathbf{A} \\in { 0, 1 }^{|\\mathcal{V}| \\times |\\mathcal{V}|}$,，PyG稀疏地表示图形，这是指仅保存 $\\mathbf{A}$ 中的条目为非零的坐标/值。\n最后，我们可以通过将图形转换为networkx库格式来进一步可视化图形，该格式除了图形操作功能之外，还实现了强大的可视化工具。我们创建一个专门用于展示Graph的函数\n%matplotlib inline import torch import networkx as nx import matplotlib.pyplot as plt # Visualization function for NX graph or PyTorch tensor def visualize(h, color, epoch=None, loss=None): plt.figure(figsize=(7,7)) plt.xticks([]) plt.yticks([]) if torch.is_tensor(h): h = h.detach().cpu().numpy() plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\u0026quot;Set2\u0026quot;) if epoch is not None and loss is not None: plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16) else: nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False, node_color=color, cmap=\u0026quot;Set2\u0026quot;) plt.show() from torch_geometric.utils import to_networkx G = to_networkx(data, to_undirected=True) visualize(G, color=data.y) 4.4 实战：基于GCN的Graph节点分类  接下来将通过Pytorch实现一个最基本的GCN网络用语节点分类，基于带有标签的节点数据进行训练模型，然后预测未带有标签的数据\n 在了解了PyG的数据处理之后，是时候实现我们的第一个Graph神经网络了！我们在这里将使用最简单的GNN网络之一，即GCN层**（[Kipf等人（2017）]（https://arxiv.org/abs/1609.02907））用于Graph节点分类。\nPyG通过[GCNConv]（https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv）来实现此层，可以通过传入 节点要素表示形式“ x”和COO图形连接性表示形式“ edge_index”。\n这样，我们就可以通过在torch.nn.Module类中定义我们的网络架构来创建我们的第一个图形神经网络：\nimport torch from torch.nn import Linear from torch_geometric.nn import GCNConv class GCN(torch.nn.Module): def __init__(self): super(GCN, self).__init__() torch.manual_seed(12345) self.conv1 = GCNConv(dataset.num_features, 4) self.conv2 = GCNConv(4, 4) self.conv3 = GCNConv(4, 2) self.classifier = Linear(2, dataset.num_classes) def forward(self, x, edge_index): h = self.conv1(x, edge_index) h = h.tanh() h = self.conv2(h, edge_index) h = h.tanh() h = self.conv3(h, edge_index) h = h.tanh() # Final GNN embedding space. # Apply a final (linear) classifier. out = self.classifier(h) return out, h model = GCN() print(model) 网络结构输出如下：\nGCN( (conv1): GCNConv(34, 4) (conv2): GCNConv(4, 4) (conv3): GCNConv(4, 2) (classifier): Linear(in_features=2, out_features=4, bias=True) ) 在这里，我们首先在__init__中初始化所有构建块，并在“转发”中定义网络的计算流程。 我们首先定义并堆叠三层图卷积层，这对应于在每个节点周围（距离3个“跳”为止的所有节点）汇总3跳邻域信息。 另外，GCNConv层将节点特征维数减小为$2$, i.e., $34 \\rightarrow 4 \\rightarrow 4 \\rightarrow 2$.。每个[GCNConv]层都通过[tanh]（https://pytorch.org/docs/stable/generation/torch.nn.Tanh.html?highlight=tanh#torch.nn.Tanh）非线性进行了增强。\n之后，我们应用单个线性变换（[torch.nn.Linear]（https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn。线性）），用作将我们的节点映射到4个类/社区中的1个的分类器。\n我们返回最终分类器的输出以及GNN生成的最终节点嵌入。 我们继续通过GCN()初始化最终模型，并打印我们的模型以产生所有使用过的子模块的概括。\n获取隐藏层的表示：\nmodel = GCN() _, h = model(data.x, data.edge_index) print(f'Embedding shape: {list(h.shape)}') visualize(h, color=data.y) 输出：\nEmbedding shape: [34, 2] 在这里值得注意的是，即使在训练我们的模型权重之前，这个初始化的GCN网络也会产生节点的嵌入，并且这些嵌入与图的社区结构非常相似。尽管我们的模型的权重是“完全随机地初始化”的，并且到目前为止，我们还没有进行任何训练，但是相同颜色（社区）的节点已经在嵌入空间中紧密地聚集在一起。得出这样的结论，即GNN引入了强烈的节点偏差，从而导致在输入图中彼此靠近的节点具有相似的嵌入。\n但是，节点表示并不是很完美，我们可以看出来四种类别的节点还是混在一块了（对应途中是四种颜色），我们可以做得更好吗？ 让我们看一个示例，该示例如何基于对图中4四种节点的社区分配（每个社区一个）的知识来训练我们的网络参数：\n由于模型中的所有内容都是可区分的和参数化的，因此我们可以添加一些标签，训练模型并观察嵌入如何反应。 在这里，我们使用一种半监督学习程序：我们仅针对每个类训练一个节点，但是允许使用完整的输入图数据。\n这个怎么理解呢，我们其实可以输出data.y和data.train_mask就明白了:\ndata.y tensor([0, 0, 0, 0, 1, 1, 1, 0, 2, 2, 1, 0, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2]) data.train_mask tensor([ True, False, False, False, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False]) 大家可以看到相当于我们训练网络的时候只针对每一个类别下的token做优化，这样可以加速网络的训练和收敛。\n训练我们的模型与任何其他PyTorch模型非常相似。 除了定义我们的网络架构之外，我们还定义了损失函数在这里[[CrossEntropyLoss]]（https://pytorch.org/docs/stable/generate/torch.nn.CrossEntropyLoss.html）） 并初始化随机梯度优化器（此处为[Adam]（https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam））。 之后，我们执行多轮优化，其中每一轮都包含一个正向和反向传递，以计算模型参数w.r.t的梯度。从前向通行证产生的损失。 如果您对PyTorch并不陌生，则该方案应该对您来说很熟悉。 否则，PyTorch文档会提供[有关如何在PyTorch中训练神经网络的很好的介绍]（https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-loss-function-and-optimizer ）。\n请注意，我们的半监督学习场景是通过以下行实现的：\nloss = criterion(out[data.train_mask], data.y[data.train_mask]) 在计算所有节点的节点嵌入时，我们“仅利用训练节点来计算loss” **。 在这里，这是通过过滤分类器“ out”和真实性标签“ data.y”的输出以仅包含“ train_mask”中的节点来实现的。\n现在让我们开始训练，看看我们的节点嵌入随时间如何演变（最好是显式地运行代码，打印出模型的训练效果）：\nimport time from IPython.display import Javascript #画图. display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 430})''')) model = GCN() criterion = torch.nn.CrossEntropyLoss() # 定义loss optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # 优化器 def train(data): optimizer.zero_grad() # 梯度清零. out, h = model(data.x, data.edge_index) # GCN模型. loss = criterion(out[data.train_mask], data.y[data.train_mask]) # 计算真实loss. loss.backward() # 反向求导. optimizer.step() # 参数更新. return loss, h for epoch in range(401): loss, h = train(data) # 每10个epochs打印Graph if epoch % 10 == 0: visualize(h, color=data.y, epoch=epoch, loss=loss) time.sleep(0.3) 过了一段时间之后，我们可以看到GCN强大的效果：\n可以看到，我们的3层GCN模型可以有效地社区发现并正确地对大多数节点进行分类。\n","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C04-graph-ml/","series":["图神经网络"],"tags":["图神经网络"],"title":"图神经网络(04)-基于Graph的传统机器学习方法"},{"categories":["技术博客"],"content":"#我们回归下，如下图所示Graphs用来做传统机器学习任务的流程为：给定输入Graph,然后用来提取节点，边以及图级别的特征，之后学习模型（比如SVM,NN等等），最后将特征映射为标签。 1 引言 图表示学习可以减轻特征工程的需求，表示学习可以自动学习Graph的特征，用于下游任务，熟悉NLP的同学比较清楚，传统文本特征构建依赖于统计手段来实现，冗余且效果有限，在词向量Word2Vec和预训练模型Bert等出现之后，文本表示变得更为便利且效果强大，自此万物皆可Embedding。\n图的表示学习的目的就是获得独立于不同任务的高效特征，通俗点讲就是能够针对不同任务学习得到适合任务的嵌入表示。 Node Embedding的目的就是能够将节点映射到不同的embedding空间：\n 节点间的embedding的相似性可以表示了节点间在网络的相似性：如果两个节点之间存在边，那么两个节点越相似 节点的Embedding能够编码网络信息 可以用于下游任务，比如节点分类，边的预测，图的分类等 下面是一个Zachary\u0026rsquo;s Karate Club Network的2维节点Embedding展示：   2 节点嵌入：编码和解码 这一节我们主要掌握下如何学习节点的嵌入向量\n2.1 构建输入-图 首先，假设我们有一个图$G$：\n $V$代表节点的集合 $A$ 代表链接矩阵 为了方便起见，我们默认认为节点没有其他的额外特征，如下图所示：   2.2 学习目标-Node Embedding 我们的目标是能够学习到节点的嵌入表示，这种节点嵌入的相似性能够近似节点在图中的相似性。 图中$ENC(u)$代表对节点$u$进行编码表示得到$z_{u}$,同样$ENC(v)$代表对节点$u$进行编码表示得到$z_{v}$\n2.3 学习方法-Encoder和Decoder  **Encoder**能够将节点映射成向量 定义一个节点相似性函数(比如节点在原始图中的相似性评估方法) Decoder DEC能够将节点向量映射成相似性分数 优化编码器的参数： 原始网络的相似性：$similarity(u,v)$ $\\approx$ 节点嵌入的相似性 ： $z_{v}^Tz_{u}$  其中有两个非常关键因素：编码和相似性函数。编码器能够学习到节点的向量，相似性函数能够提供我们优化的目标，如果两个节点在图中存在边或者距离越近，那么它们对应的节点向量在向量空间中相似性也会越大。 如何选择定义节点相似性的方法是关键的地方，我们考虑下什么情况下，两个节点的相似性比较高？\n 是否存在边或者连接 是否共享邻居节点 是否包括相似的属性特征 接下来我们通过随机游走（Random Walks）来学习节点相似性，以及优化节点的嵌入向量。  3 Random Walk Node Embeddings的计算方法之一就是Random Walk，为了方面起见我们定义和引出下面的符号，以便统一解释。\n3.1 符号 为了方面接下来的公式推导，我们统一下符号标记：\n 向量 $z_{u}$:  u节点的嵌入向量\n  概率$P(v|z_{u})$：  从节点$u$出发通过随机游走访问节点$v$的概率\n  Softmax函数：通过softmax函数一作用，一个K维向量就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标。 $\\sigma(z){i}=\\frac{e^{Z{i}}}{\\sum_{j=1}^Ke^{Z_{j}}}$ Sigmoid函数： $S(x)=\\frac{1}{1+e^{-x}}$将一个数映射到（0,1）的区间  3.2 Random Walk 定义 给定一个Graph和一个起始点，我们选择随机选择该点的邻居节点，并且移动到该邻居节点；然后我们根据当前节点随机选择一个邻居节点，然后移动到该邻居节点，重复上述步骤\u0026hellip;通过这种随机游走访问Graph节点的方式可以产生随机序列。下图描述了一个随机游走的实例，第一步从起始节点出发移动到节点5，第二步从节点5移动节点8，第三步从节点8移动节点9，第四步又从节点9移动到节点8，之后第5步移动到节点11，这样访问路径构成一个序列：\nstart_node-\u0026gt;5-\u0026gt;8-\u0026gt;9-\u0026gt;8-\u0026gt;11 3.3 Random Walk如何得到Node Embeddings 相信大家对下面的公式不会感到陌生，一般我们衡量两个向量的相似性时可以通过两个向量点积计算得到，相似地两个节点同时出现在同一随机游走序列的概率可以用如下表示： 所以我们通过Rankdom Walk得到Node Embedding可以通过两个步骤： (1) 通过某种随机游走策略$R$（下文将会介绍）得到从节点$u$出发访问到节点$v$的路径，然后可以估计出节点$u$和$v$同时出现的概率 (2) 优化节点的embeddings表示，使得节点的嵌入表示能够表达或者近似我们上述随机游走得到的统计 回想一下我们机器学习或者深度学习的各种任务，无非就是在优化一个目标，一个近似目标，我们可以笼统地将我们输入表示成X，然后通过方法f来近似y。说到这里上面两个步骤特别像NLP中Glove向量的优化步骤，首先我们统计两个词在语料中共现概率，然后通过词向量来近似共现概率。\n","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C03-node-embeddings/","series":["图神经网络"],"tags":["图神经网络"],"title":"图神经网络（03）-Node Embeddings"},{"categories":["ChallengeHub"],"content":" ChallengeHub:A community dedicated to AI knowledge sharing\n 成员信息  致Great，毕业于中国人民大学，就职于某研究院，算法工程师； lrhao，就职于某互联网大厂数据分析； 不是吧阿sir，华东师范大学研二学生，目前某互联网大厂算法实习； WintoMT，中南大学研二学生； starry，毕业于同济大学，就职于某互联网大厂，算法工程师  成员荣誉  2019年厦门国际银行数创金融杯 冠军 2021年水利知识图谱构建挑战赛 亚军 2020年CCF华为serverless负载预测 亚军 2020年新网银行用户行为体识别 亚军 2020年众安科技用户骗保行为识别 亚军 2020年中国电信翼支付风险用户识别 季军 2020年人工智能图像分类应用挑战赛 季军 2020年长三角创同体数据挖掘竞赛 季军 2020年CCF企业风险非法集资预测 季军 2019年中国银联用户行为购买预测 亚军  联系邮箱 challengehub@126.com\n","permalink":"/about/challengehub/","series":null,"tags":["ChallengeHub"],"title":"ChallengeHub"},{"categories":["技术博客"],"content":"本文展示了如果使用 scikit-learn 使用。\nsklearn (scikit-learn) 是基于 Python 语言的机器学习工具\n 官方链接：https://scikit-learn.org/stable/\n 安装  通过pip安装  $ pip install -U scikit-learn  通过conda安装  $ conda install -c intel scikit-learn 实例 from sklearn.ensemble import RandomForestClassifier clf = RandomForestClassifier(random_state=0) X = [[ 1, 2, 3], # 2 samples, 3 features [11, 12, 13]] y = [0, 1] # classes of each sample clf.fit(X, y) RandomForestClassifier(random_state=0) ","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/scikit-learn/","series":["Scikit-Learn系列教程"],"tags":["scikit-learn"],"title":"Scikit-Learn"},{"categories":["比赛推送"],"content":"KDD 2021 赛题 赛题1 基于多数据集的时间序列异常检测  Multi-dataset Time Series Anomaly Detection https://compete.hexagon-ml.com/practice/competition/39/\n 背景描述-时间序列异常检测 近年来，SIGKDD以及其他数据挖掘，机器学习和数据库会议上出现了有关时间序列异常检测的论文。这些论文中的大多数都在一个或多个基准数据集中进行测试，包括由NASA，Yahoo，Numenta和清华-OMNI 等创建的数据集。\n尽管社区应该非常赞赏这些团队共享数据的努力，但最近的几篇论文[a]认为这些数据集不适用于衡量异常检测的进展。\n简而言之，反对使用这些数据集的两个最引人注目的论据是：\n冗余性：几乎所有上述基准数据集都可以完美解决，而无需查看任何训练数据，并且使用已有十年历史的算法。 标签错误：永远不能完全消除错误检测基准错误贴标签的可能性。但是，上面提到的某些数据集在基本事实中似乎有大量假阳性和假阴性。已经发表了一些论文，认为方法A比方法B更好，因为它在基准X上的准确性要高5％。但是，仔细检查基准X可以发现，有25％以上的标签是错误的，这个数字使标签A的准确性相形见war。声称所比较算法之间的差异。\n除了上面列出的问题以及文件重叠的可能性外，我们认为社区还存在一系列不合适的基准。考虑到这一点，作为比赛的一部分，我们为时间序列异常检测创建了新的基准。\n为此竞赛创建的基准数据集旨在缓解此问题。重要的是要注意我们的主张是“缓解”，而不是“解决”。我们认为，非常有很多研究者本着CASP [d]的精神来解决这个问题将是很棒的。\n同时，作为这一挑战的一部分的200个数据集反映了20多年研究时间序列异常检测文献并收集数据集的工作。除了这场竞赛的本身，我们希望它们可以在未来几年中为社区提供资源，并激发对异常检测评估的更深刻的思考。\n赛题奖励  一等奖：$ 2000 USD 二等奖：$ 1000 USD 三等奖：$ 500美元 对于排名前15位的参与者，我们将提供具有等级的证书。 对于所有其他参与者，我们将提供参赛证书（阳光普照奖）  赛题时间轴  阶段1:2021年3月15日-2021年4月7日 阶段2:2021年4月7日-20210年6月1日  赛题任务与数据 赛题任务：预测时间序列中异常发生的位置\n数据    姓名 下载     提交样例 [下载](https://compete.hexagon-ml.com/media/data/multi-dataset-time-series-anomaly-detection-39/submissionsample.csv)    数据 [下载](https://compete.hexagon-ml.com/media/data/multi-dataset-time-series-anomaly-detection-39/data.zip)    文件格式\n这些文件使用命名约定，该约定在测试和训练之间提供了分隔。\n_ \u0026lt;名称\u0026gt; _ \u0026lt;拆分号\u0026gt; .txt\n例如004_UCR_Anomaly_2500.txt。 此处split-number = 2500表示从2500开始存在异常。\n样本提交文件\n提示：\n提交文件的column标头应“完全”匹配预期的格式。例如，编号，位置\n行数应与总计数完全匹配（第一阶段：25行，第二阶段：200行）\nlocation的值是一个整数。\n第一阶段 数据部分将提供25个时间序列文件以及示例提交文件。 这将是一个培训阶段，在进入第二阶段时将清除排行榜。\n第二阶段\n比赛第二阶段将提供200个时间序列文件，包括第一阶段的前25个文件。\n提交评估 我们在异常范围的两侧添加了+/- 100个位置，以奖励正确的答案。\n例子\n有200个文件，对于每个正确的答案，您将获得1分，对于错误的答案将获得0分。您可以获得的最高分数是100％（只要您使用算法在代码中执行此操作，就无需人工标记）。如果我们怀疑有任何参与者\n赛题可以提交了，别等待了~ 赛题2 城市大脑挑战-交通网络调度  City Brain Challenge http://www.yunqiacademy.org/\n 赛题背景 没有人喜欢被卡在城市交通中。尽管我们在城市中观察到许多车辆，但交通拥堵的原因仍不清楚。是因为车辆数量超出了城市的承载能力，还是因为我们未能以最大承载能力利用道路网络？\n以世界上最大的两个城市为例。东京和纽约市的交通拥堵指数排名相似。但是，值得注意的是，东京的注册车辆比纽约市多50％，而东京的信号交叉口仅比纽约市多15％，道路长度比纽约多30％。（东京：注册车辆313万， 交通信号15,000  ，道路24,650公里。 纽约市注册车辆219万， 交通信号13,000  ，道路18,684 km。 ）      为什么东京可以提供比纽约更多的车辆服务？纽约市是否以最大载客量运营交通？作为数据科学家，我们邀请您协调交通，并根据城市规模的路网及其交通需求找到最大交通容量。\n比赛描述 在这一挑战中，我们将为您提供一个城市规模的道路网络，其交通需求来自真实的交通数据。您将负责协调信号交叉口的交通，同时将延迟指数保持在预定义的阈值以下。我们将增加流量需求，并查看您的协调模型是否仍然可以凑效。\n为了促进您的方法开发，我们将首次发布City Brain Open Research Platform。该平台包含一个城市规模的交通模拟环境和一个具有多核计算机的云计算集群。 时间线  报名 4/1/2021  参赛选手熟悉区域交通的数据以及熟悉模拟环境。\n 参赛 5/1/2021  参与者将进行城市规模的交通协调。可以处理更大流量需求的团队将进入最后一轮。\n 最终提交 6/1/2021  提供大规模的云计算平台。团队将开发方法来处理城市范围内各种未知的交通流量。\n 比赛结束 7/1/2021  比赛奖励 奖金：\n 第一名：$ 3000 第二名：$ 2000 第三名：$ 1000 第四至第十名：$ 500  研究支持：\n 大规模计算资源 潜在的现实世界级研究实验 纸质出版物的其他支持  赛题3 大型图机器学习比赛： OGB-LSC  OGB Large-Scale Challenge https://ogb.stanford.edu/kddcup2021/\n 为什么要举行大型图ML比赛？ 由于在实际应用中普遍使用图结构化数据，因此图上的机器学习（ML）近年来引起了极大的关注。现代应用领域包括网络规模的社交网络，推荐系统，超链接的网络文档，知识图谱（KGs），以及通过不断增长的科学计算生成的分子模拟数据。这些域涉及具有数十亿个边的大规模图形或具有数百万个图形的数据集。大规模部署准确的图ML将产生巨大的实际影响，从而实现更好的推荐结果，改进的Web文档搜索，更全面的KG以及基于ML的准确药物和材料发现。\n然而，社区在大规模图形ML中发展最新技术的努力非常有限。实际上，处理大规模图具有挑战性，特别是对于最先进的表达性图神经网络（GNN），因为它们会根据来自许多其他节点的信息对每个节点进行预测。要有效地大规模训练这些模型，就需要复杂的算法，而这些算法远远超出了基于iid数据的标准SGD。最近，研究人员通过显着简化GNN来提高模型可伸缩性，这不可避免地限制了它们的表达能力。\n但是，在深度学习中，一遍又一遍地表明，人们需要大型的表达模型并在大数据上对其进行训练，以实现最佳性能。在图ML中，趋势是相反的-模型变得简化且表达能力较弱，因此无法缩放到大图。因此，存在着巨大的机会来移动社区以使用现实的和大规模的图形数据集，并将领域的状态向前移动到需要的地方。\nOGB-LSC概述 在这里，我们提出了一个大型图ML竞赛，即OGB大型挑战赛（OGB-LSC），以鼓励开发适用于海量现代数据集的最新图ML模型。具体来说，我们提供了三个数据集：MAG240M-LSC ，WikiKG90M-LSC 和PCQM4M-LSC ，它们的规模空前大，并且分别覆盖了节点，链接和图形级别的预测。 每个数据集提供一个独立的任务，优胜者将分别为每个数据集选择。 我们将宣布每个数据集的前3名获胜团队（总共9个获胜团队），他们将有机会在KDD Cup研讨会上展示他们的解决方案。 下面提供了三个OGB-LSC数据集的说明性概述：  **MAG240M-LSC **是一个异构的学术图，其任务是预测位于异构图中的论文的主题区域（节点分类）。 **WikiKG90M-LSC **是一个知识图，其任务是估算缺少的三元组（链接预测）。 **PCQM4M-LSC **是量子化学数据集，其任务是预测给定分子的重要分子特性，即HOMO-LUMO间隙（图形回归）。  对于每个数据集，我们都会仔细设计其预测任务和数据拆分，以便在任务上实现较高的预测性能将直接影响相应的应用程序。每个数据集页面中都提供了更多详细信息。\n数据集统计信息和基本信息总结如下，表明我们的数据集非常大。 所有这些数据集都可以使用我们的ogbPython包 下载并准备。 模型评估和测试提交文件的准备工作也由我们的软件包处理。 用法在每个数据集页面中都有描述。请通过以下方式安装/更新：\n在我们的**论文中 **，我们进一步对每个数据集进行了广泛的基线分析，大规模实现了简单的基线模型以及高级的表达模型。我们发现，尽管需要更多的努力来进行扩展，但先进的表达模型确实会从大数据中受益，并且明显优于易于扩展的简单基线模型。我们所有的基准代码均已**公开提供， **以方便公众研究。\npip install -U ogb # Make sure below prints the required package version for the dataset you are working on. python -c \u0026quot;import ogb; print(ogb.__version__)\u0026quot; 总体而言，我们的KDD杯将鼓励社区开发和扩展表达性图ML模型，这可以在各个领域取得重大突破。我们希望在2021年KDD杯上的OGB-LSC能够成为图ML领域的“ ImageNet大规模视觉识别挑战”，鼓励社区致力于现实和大规模的图数据集，并显着提高现状-艺术。 OGB-LSC数据集论文 \nKaggle新赛题 赛题1 Shopee - Price Match Guarantee 通过两个图像确定两个产品是否相同\n https://www.kaggle.com/c/shopee-product-matching/overview/description\n 评估指标 采用F1-Score，参赛作品将根据其平均F1分数 进行评估。均值以样本方式计算，这意味着将为每个预测行计算F1分数，然后取平均值。\n选手必须创建一个以空格分隔的列表，posting_id该列表与该posting_id列中的发布匹配的所有。帖子总是自我匹配的。匹配个数上限为50，因此预测50场以上的对比赛没有好处。\n该文件应有一个标题，名为submission.csv，如下所示：\nposting_id,matches test_123,test_123 test_456,test_456 test_789 您应该预测每个比赛posting_id。例如，如果您认为A与B和C相匹配，则A,A B C还应包含B,B A C和C,C A B。\n时间线  2021 年3月8日-比赛开始日期 2021 年5月3日-报名截止日期。您必须在此日期之前接受比赛规则才能参加比赛。 2021 年5月3日-合并团队截止日期。这是参与者可以加入或合并团队的最后一天。 2021 年5月10日-最终提交截止日期。  奖金  第一名-$ 15,000 第二名-$ 10,000 第三名-$ 5,000  数据集 在大型数据集中查找近重复项是许多在线业务的重要问题。对于Shopee，日常用户可以上传自己的图像并撰写自己的产品说明，从而增加了挑战。您的任务是确定哪些产品已重复发布。相关产品之间的差异可能微妙，而相同产品的照片则可能千差万别！\n由于这是一场代码竞赛，因此仅发布测试集的前几行/图像；其余的仅在提交笔记本后才对您的笔记本可用。预计将在隐藏的测试集中找到大约70,000张图像。提供的一些测试行和图像旨在说明隐藏的测试集格式和文件夹结构。\n **[train / test] .csv-**训练集数据。每行包含一次过帐的数据。多个订单可能具有完全相同的图像ID，但标题不同，反之亦然。    posting_id -发布的ID码。\n  image -图片ID / md5sum。\n  image_phash-图像的感知哈希 。\n  title -发布的产品说明。\n  label_group-映射到同一产品的所有发布的ID码。未提供测试集。\n  [train / test] images-与发布相关的图像。\n**sample_submission.csv-**格式正确的示例提交文件。\n  posting_id -发布的ID码。\n  matches-以空格分隔的与此发布匹配的所有发布ID的列表。posting是自我匹配，匹配个数上限为50，因此无需预测超过50个数。\n  赛题2 Bristol-Myers Squibb – Molecular Translation 化学分子图像转换为化学结构序列 https://www.kaggle.com/c/bms-molecular-translation\n背景描述 在技术进步的世界中，有时最好，最简单的工具仍然是纸和笔。有机化学家经常利用骨架式（Skeletal formula）来绘制分子工作，骨架式是一个世纪以来使用的结构符号。最近的出版物还用机器可读的化学描述（InChI）进行了注释，但是数十年的扫描文档无法自动搜索特定的化学描述。在机器学习的帮助下，光学化学结构的自动识别可以加快研发的速度。\n不幸的是，大多数公共数据集太小，无法支持现代机器学习模型。现有工具只能在最佳条件下产生90％的精度。历史来源通常会在某种程度上破坏图像，从而将性能降低到接近零。在这些情况下，需要耗时的手动操作才能将扫描的化学结构图像可靠地转换为机器可读格式。\n百时美施贵宝公司是一家全球性生物制药公司，致力于通过科学改变患者的生活。他们的任务是发现，开发和提供可帮助患者战胜严重疾病的创新药物。\n在这场比赛中，您将解释旧的化学图像。通过访问由Bristol-Myers Squibb生成的大量合成图像数据，您可以将图像转换回标注为InChI文本的基础化学结构。\n整理化学文献的工具将对研究人员带来重大好处。如果成功，您将帮助化学家扩大进行集体化学研究的机会。反过来，通过避免重复先前发表的化学方法，并通过挖掘大数据集来识别新趋势，这将加快许多关键领域的研发工作。\n评估指标 根据您提交的InChi字符串与地面真实InChi值之间的平均Levenshtein距离 评估提交的内容。\n提交文件 对于image_id测试集中的每一个，您必须在相应的图像中预测分子的InChi字符串。该文件应包含标头，并具有以下格式：\nimage_id,InChI 00000d2a601c,InChI=1S/H2O/h1H2 00001f7fc849,InChI=1S/H2O/h1H2 000037687605,InChI=1S/H2O/h1H2 etc. 时间轴  2021 年3月2日-比赛开始日期 2021 年5月26日-报名截止日期。您必须在此日期之前接受比赛规则才能参加比赛。 2021 年5月26日-合并团队截止日期。这是参与者可以加入或合并团队的最后一天。 2021 年6月2日-最终提交截止日期。  奖金  第一名-$ 25,000 第二名-$ 15,000 第三名-$ 10,000  数据集 在本次比赛中，您将获得化学品的图像，目的是预测图像中相应的国际化学品识别码 （InChI）文本字符串。所提供的图像（训练数据和测试数据中的图像）都可以旋转到不同的角度，具有不同的分辨率，并且具有不同的噪声水平。\n**注意：**此数据集中总共约有4m张图像。解压缩下载的数据将花费时间。\n train / -训练图像，由3级文件夹结构排列image_id  test / -测试图像，与文件夹位于相同的文件夹结构中train/ train_labels.csv-训练图像的地面真相InChi标签 sample_submission.csv-格式正确的样本提交文件  ","permalink":"/posts/%E6%AF%94%E8%B5%9B%E6%8E%A8%E9%80%81/kaggle%E9%A1%B6%E7%BA%A7%E8%B5%9B%E4%BA%8B%E7%AD%89%E4%BD%A0%E6%9D%A5%E6%8E%92%E4%BD%8D/","series":["比赛推送"],"tags":["比赛推送"],"title":"【比赛推送】KDD 2021/ Kaggle 顶级赛事等你来排位"},{"categories":["招聘信息"],"content":"1 京东探索研究院（社招）  京东成立探索研究院，将深耕“人工智能”、“量子计算”、“数据科学、工程与管理”、“去中心化计算”、“技术伦理道德”、“科学与艺术”六大技术领域，从基础理论层面实现颠覆式创新，聚焦于打造产业数智化首个源头性科技高地，成为比肩国际领先科研机构的前沿技术基地，通过不断努力，在世界舞台上展现一家中国科技公司的担当、风范。\n  现在，京东探索研究院将在量子计算、机器感知、理论算法方向招募世界顶级科学家，组建首批科研团队，同时励众更多“青年科学家”加入。改变世界，从此刻开始。\n 2 蚂蚁集团（春招实习） 内推方式：\n大佬朋友的组，同学们抓紧上车 2022校招实习开始了，扫码内推，或者直接发简历到yongliang.wyl@antgroup.com。 阿里云 (暑期实习) 【阿里云-分布式块存储研发-暑期实习直推】（实习面向2022年毕业的学生） 一、团队介绍： 阿里云块存储团队，目前提供了中国最大的线上云存储服务。团队管理高效，技术积累丰富，培养体系成熟，在杭州、北京均设有团队。\n二、岗位职责： 1.负责阿里云分布式块存储万亿级别业务的架构设计、研发，提供高稳定性、高可靠性的分布式存储服务； 2.在现有系统设计基础上，完善优化现有系统架构设计，提升系统稳定性及可靠性； 3.为现有系统的稳定可靠运行，提供技术支持；\n三、岗位要求：\n 本科及以上学历在读学生，计算机、软件工程或相关专业或多年分布式开发相关经验者； 熟悉Linux系统开发环境，具有良好的代码风格和质量意识，熟悉C/C++等编程语言（其他语言也可以考虑，但需对C/C++有一定了解）; 有优秀的发现及解决问题的能力，良好的沟通能力及团队合作意识; 对分布式系统的架构和原理有深入了解者优先考虑； 有编程竞赛经验者或分布式系统开发经验者优先考虑。  四、简历投递 邮箱：liangliang.sll@alibaba-inc.com qq：495096408 直接发送简历到邮箱或者qq联系本人\n3 Moka(社招) 4 字节跳动2021春季校园招聘全面启动！（校招）  ps：信息来自友圈，有疑问或者问题可以联系后台进行处理\n ","permalink":"/posts/%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/kaggle%E9%A1%B6%E7%BA%A7%E8%B5%9B%E4%BA%8B%E7%AD%89%E4%BD%A0%E6%9D%A5%E6%8E%92%E4%BD%8D/","series":["招聘信息"],"tags":["招聘信息"],"title":"【阿里，字节，Moka】招聘信息汇总（ML、CV、NLP）"}]