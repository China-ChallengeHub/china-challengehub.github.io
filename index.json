[{"categories":["技术博客"],"content":"#我们回归下，如下图所示Graphs用来做传统机器学习任务的流程为：给定输入Graph,然后用来提取节点，边以及图级别的特征，之后学习模型（比如SVM,NN等等），最后将特征映射为标签。 1 引言 图表示学习可以减轻特征工程的需求，表示学习可以自动学习Graph的特征，用于下游任务，熟悉NLP的同学比较清楚，传统文本特征构建依赖于统计手段来实现，冗余且效果有限，在词向量Word2Vec和预训练模型Bert等出现之后，文本表示变得更为便利且效果强大，自此万物皆可Embedding。\n图的表示学习的目的就是获得独立于不同任务的高效特征，通俗点讲就是能够针对不同任务学习得到适合任务的嵌入表示。 Node Embedding的目的就是能够将节点映射到不同的embedding空间：\n 节点间的embedding的相似性可以表示了节点间在网络的相似性：如果两个节点之间存在边，那么两个节点越相似 节点的Embedding能够编码网络信息 可以用于下游任务，比如节点分类，边的预测，图的分类等 下面是一个Zachary\u0026rsquo;s Karate Club Network的2维节点Embedding展示：   2 节点嵌入：编码和解码 这一节我们主要掌握下如何学习节点的嵌入向量\n2.1 构建输入-图 首先，假设我们有一个图$G$：\n $V$代表节点的集合 $A$ 代表链接矩阵 为了方便起见，我们默认认为节点没有其他的额外特征，如下图所示：   2.2 学习目标-Node Embedding 我们的目标是能够学习到节点的嵌入表示，这种节点嵌入的相似性能够近似节点在图中的相似性。 图中$ENC(u)$代表对节点$u$进行编码表示得到$z_{u}$,同样$ENC(v)$代表对节点$u$进行编码表示得到$z_{v}$\n2.3 学习方法-Encoder和Decoder  **Encoder**能够将节点映射成向量 定义一个节点相似性函数(比如节点在原始图中的相似性评估方法) Decoder DEC能够将节点向量映射成相似性分数 优化编码器的参数： 原始网络的相似性：$similarity(u,v)$ $\\approx$ 节点嵌入的相似性 ： $z_{v}^Tz_{u}$  其中有两个非常关键因素：编码和相似性函数。编码器能够学习到节点的向量，相似性函数能够提供我们优化的目标，如果两个节点在图中存在边或者距离越近，那么它们对应的节点向量在向量空间中相似性也会越大。 如何选择定义节点相似性的方法是关键的地方，我们考虑下什么情况下，两个节点的相似性比较高？\n 是否存在边或者连接 是否共享邻居节点 是否包括相似的属性特征 接下来我们通过随机游走（Random Walks）来学习节点相似性，以及优化节点的嵌入向量。  3 Random Walk Node Embeddings的计算方法之一就是Random Walk，为了方面起见我们定义和引出下面的符号，以便统一解释。\n3.1 符号 为了方面接下来的公式推导，我们统一下符号标记：\n 向量 $z_{u}$:  u节点的嵌入向量\n  概率$P(v|z_{u})$：  从节点$u$出发通过随机游走访问节点$v$的概率\n  Softmax函数：通过softmax函数一作用，一个K维向量就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标。 $\\sigma(z){i}=\\frac{e^{Z{i}}}{\\sum_{j=1}^Ke^{Z_{j}}}$ Sigmoid函数： $S(x)=\\frac{1}{1+e^{-x}}$将一个数映射到（0,1）的区间  3.2 Random Walk 定义 给定一个Graph和一个起始点，我们选择随机选择该点的邻居节点，并且移动到该邻居节点；然后我们根据当前节点随机选择一个邻居节点，然后移动到该邻居节点，重复上述步骤\u0026hellip;通过这种随机游走访问Graph节点的方式可以产生随机序列。下图描述了一个随机游走的实例，第一步从起始节点出发移动到节点5，第二步从节点5移动节点8，第三步从节点8移动节点9，第四步又从节点9移动到节点8，之后第5步移动到节点11，这样访问路径构成一个序列：\nstart_node-\u0026gt;5-\u0026gt;8-\u0026gt;9-\u0026gt;8-\u0026gt;11 3.3 Random Walk如何得到Node Embeddings 相信大家对下面的公式不会感到陌生，一般我们衡量两个向量的相似性时可以通过两个向量点积计算得到，相似地两个节点同时出现在同一随机游走序列的概率可以用如下表示： 所以我们通过Rankdom Walk得到Node Embedding可以通过两个步骤： (1) 通过某种随机游走策略$R$（下文将会介绍）得到从节点$u$出发访问到节点$v$的路径，然后可以估计出节点$u$和$v$同时出现的概率 (2) 优化节点的embeddings表示，使得节点的嵌入表示能够表达或者近似我们上述随机游走得到的统计 回想一下我们机器学习或者深度学习的各种任务，无非就是在优化一个目标，一个近似目标，我们可以笼统地将我们输入表示成X，然后通过方法f来近似y。说到这里上面两个步骤特别像NLP中Glove向量的优化步骤，首先我们统计两个词在语料中共现概率，然后通过词向量来近似共现概率。\n","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C04-node-embeddings/","series":["图神经网络"],"tags":["图神经网络"],"title":"图神经网络（03）-Node Embeddings"},{"categories":["ChallengeHub"],"content":" ChallengeHub:A community dedicated to AI knowledge sharing\n 成员信息  致Great，毕业于中国人民大学，就职于某研究院，算法工程师； lrhao，就职于某互联网大厂数据分析； 不是吧阿sir，华东师范大学研二学生，目前某互联网大厂算法实习； WintoMT，中南大学研二学生； starry，毕业于同济大学，就职于某互联网大厂，算法工程师  成员荣誉  2019年厦门国际银行数创金融杯 冠军 2021年水利知识图谱构建挑战赛 亚军 2020年CCF华为serverless负载预测 亚军 2020年新网银行用户行为体识别 亚军 2020年众安科技用户骗保行为识别 亚军 2020年中国电信翼支付风险用户识别 季军 2020年人工智能图像分类应用挑战赛 季军 2020年长三角创同体数据挖掘竞赛 季军 2020年CCF企业风险非法集资预测 季军 2019年中国银联用户行为购买预测 亚军  联系邮箱 challengehub@126.com\n","permalink":"/about/challengehub/","series":null,"tags":["ChallengeHub"],"title":"ChallengeHub"},{"categories":["技术博客"],"content":"本文展示了如果使用 scikit-learn 使用。\nsklearn (scikit-learn) 是基于 Python 语言的机器学习工具\n 官方链接：https://scikit-learn.org/stable/\n 安装  通过pip安装  $ pip install -U scikit-learn  通过conda安装  $ conda install -c intel scikit-learn 实例 from sklearn.ensemble import RandomForestClassifier clf = RandomForestClassifier(random_state=0) X = [[ 1, 2, 3], # 2 samples, 3 features [11, 12, 13]] y = [0, 1] # classes of each sample clf.fit(X, y) RandomForestClassifier(random_state=0) ","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/scikit-learn/","series":["Scikit-Learn系列教程"],"tags":["scikit-learn"],"title":"Scikit-Learn"},{"categories":["比赛推送"],"content":"KDD 2021 赛题 赛题1 基于多数据集的时间序列异常检测  Multi-dataset Time Series Anomaly Detection https://compete.hexagon-ml.com/practice/competition/39/\n 背景描述-时间序列异常检测 近年来，SIGKDD以及其他数据挖掘，机器学习和数据库会议上出现了有关时间序列异常检测的论文。这些论文中的大多数都在一个或多个基准数据集中进行测试，包括由NASA，Yahoo，Numenta和清华-OMNI 等创建的数据集。\n尽管社区应该非常赞赏这些团队共享数据的努力，但最近的几篇论文[a]认为这些数据集不适用于衡量异常检测的进展。\n简而言之，反对使用这些数据集的两个最引人注目的论据是：\n冗余性：几乎所有上述基准数据集都可以完美解决，而无需查看任何训练数据，并且使用已有十年历史的算法。 标签错误：永远不能完全消除错误检测基准错误贴标签的可能性。但是，上面提到的某些数据集在基本事实中似乎有大量假阳性和假阴性。已经发表了一些论文，认为方法A比方法B更好，因为它在基准X上的准确性要高5％。但是，仔细检查基准X可以发现，有25％以上的标签是错误的，这个数字使标签A的准确性相形见war。声称所比较算法之间的差异。\n除了上面列出的问题以及文件重叠的可能性外，我们认为社区还存在一系列不合适的基准。考虑到这一点，作为比赛的一部分，我们为时间序列异常检测创建了新的基准。\n为此竞赛创建的基准数据集旨在缓解此问题。重要的是要注意我们的主张是“缓解”，而不是“解决”。我们认为，非常有很多研究者本着CASP [d]的精神来解决这个问题将是很棒的。\n同时，作为这一挑战的一部分的200个数据集反映了20多年研究时间序列异常检测文献并收集数据集的工作。除了这场竞赛的本身，我们希望它们可以在未来几年中为社区提供资源，并激发对异常检测评估的更深刻的思考。\n赛题奖励  一等奖：$ 2000 USD 二等奖：$ 1000 USD 三等奖：$ 500美元 对于排名前15位的参与者，我们将提供具有等级的证书。 对于所有其他参与者，我们将提供参赛证书（阳光普照奖）  赛题时间轴  阶段1:2021年3月15日-2021年4月7日 阶段2:2021年4月7日-20210年6月1日  赛题任务与数据 赛题任务：预测时间序列中异常发生的位置\n数据    姓名 下载     提交样例 [下载](https://compete.hexagon-ml.com/media/data/multi-dataset-time-series-anomaly-detection-39/submissionsample.csv)    数据 [下载](https://compete.hexagon-ml.com/media/data/multi-dataset-time-series-anomaly-detection-39/data.zip)    文件格式\n这些文件使用命名约定，该约定在测试和训练之间提供了分隔。\n_ \u0026lt;名称\u0026gt; _ \u0026lt;拆分号\u0026gt; .txt\n例如004_UCR_Anomaly_2500.txt。 此处split-number = 2500表示从2500开始存在异常。\n样本提交文件\n提示：\n提交文件的column标头应“完全”匹配预期的格式。例如，编号，位置\n行数应与总计数完全匹配（第一阶段：25行，第二阶段：200行）\nlocation的值是一个整数。\n第一阶段 数据部分将提供25个时间序列文件以及示例提交文件。 这将是一个培训阶段，在进入第二阶段时将清除排行榜。\n第二阶段\n比赛第二阶段将提供200个时间序列文件，包括第一阶段的前25个文件。\n提交评估 我们在异常范围的两侧添加了+/- 100个位置，以奖励正确的答案。\n例子\n有200个文件，对于每个正确的答案，您将获得1分，对于错误的答案将获得0分。您可以获得的最高分数是100％（只要您使用算法在代码中执行此操作，就无需人工标记）。如果我们怀疑有任何参与者\n赛题可以提交了，别等待了~ 赛题2 城市大脑挑战-交通网络调度  City Brain Challenge http://www.yunqiacademy.org/\n 赛题背景 没有人喜欢被卡在城市交通中。尽管我们在城市中观察到许多车辆，但交通拥堵的原因仍不清楚。是因为车辆数量超出了城市的承载能力，还是因为我们未能以最大承载能力利用道路网络？\n以世界上最大的两个城市为例。东京和纽约市的交通拥堵指数排名相似。但是，值得注意的是，东京的注册车辆比纽约市多50％，而东京的信号交叉口仅比纽约市多15％，道路长度比纽约多30％。（东京：注册车辆313万， 交通信号15,000  ，道路24,650公里。 纽约市注册车辆219万， 交通信号13,000  ，道路18,684 km。 ）      为什么东京可以提供比纽约更多的车辆服务？纽约市是否以最大载客量运营交通？作为数据科学家，我们邀请您协调交通，并根据城市规模的路网及其交通需求找到最大交通容量。\n比赛描述 在这一挑战中，我们将为您提供一个城市规模的道路网络，其交通需求来自真实的交通数据。您将负责协调信号交叉口的交通，同时将延迟指数保持在预定义的阈值以下。我们将增加流量需求，并查看您的协调模型是否仍然可以凑效。\n为了促进您的方法开发，我们将首次发布City Brain Open Research Platform。该平台包含一个城市规模的交通模拟环境和一个具有多核计算机的云计算集群。 时间线  报名 4/1/2021  参赛选手熟悉区域交通的数据以及熟悉模拟环境。\n 参赛 5/1/2021  参与者将进行城市规模的交通协调。可以处理更大流量需求的团队将进入最后一轮。\n 最终提交 6/1/2021  提供大规模的云计算平台。团队将开发方法来处理城市范围内各种未知的交通流量。\n 比赛结束 7/1/2021  比赛奖励 奖金：\n 第一名：$ 3000 第二名：$ 2000 第三名：$ 1000 第四至第十名：$ 500  研究支持：\n 大规模计算资源 潜在的现实世界级研究实验 纸质出版物的其他支持  赛题3 大型图机器学习比赛： OGB-LSC  OGB Large-Scale Challenge https://ogb.stanford.edu/kddcup2021/\n 为什么要举行大型图ML比赛？ 由于在实际应用中普遍使用图结构化数据，因此图上的机器学习（ML）近年来引起了极大的关注。现代应用领域包括网络规模的社交网络，推荐系统，超链接的网络文档，知识图谱（KGs），以及通过不断增长的科学计算生成的分子模拟数据。这些域涉及具有数十亿个边的大规模图形或具有数百万个图形的数据集。大规模部署准确的图ML将产生巨大的实际影响，从而实现更好的推荐结果，改进的Web文档搜索，更全面的KG以及基于ML的准确药物和材料发现。\n然而，社区在大规模图形ML中发展最新技术的努力非常有限。实际上，处理大规模图具有挑战性，特别是对于最先进的表达性图神经网络（GNN），因为它们会根据来自许多其他节点的信息对每个节点进行预测。要有效地大规模训练这些模型，就需要复杂的算法，而这些算法远远超出了基于iid数据的标准SGD。最近，研究人员通过显着简化GNN来提高模型可伸缩性，这不可避免地限制了它们的表达能力。\n但是，在深度学习中，一遍又一遍地表明，人们需要大型的表达模型并在大数据上对其进行训练，以实现最佳性能。在图ML中，趋势是相反的-模型变得简化且表达能力较弱，因此无法缩放到大图。因此，存在着巨大的机会来移动社区以使用现实的和大规模的图形数据集，并将领域的状态向前移动到需要的地方。\nOGB-LSC概述 在这里，我们提出了一个大型图ML竞赛，即OGB大型挑战赛（OGB-LSC），以鼓励开发适用于海量现代数据集的最新图ML模型。具体来说，我们提供了三个数据集：MAG240M-LSC ，WikiKG90M-LSC 和PCQM4M-LSC ，它们的规模空前大，并且分别覆盖了节点，链接和图形级别的预测。 每个数据集提供一个独立的任务，优胜者将分别为每个数据集选择。 我们将宣布每个数据集的前3名获胜团队（总共9个获胜团队），他们将有机会在KDD Cup研讨会上展示他们的解决方案。 下面提供了三个OGB-LSC数据集的说明性概述：  **MAG240M-LSC **是一个异构的学术图，其任务是预测位于异构图中的论文的主题区域（节点分类）。 **WikiKG90M-LSC **是一个知识图，其任务是估算缺少的三元组（链接预测）。 **PCQM4M-LSC **是量子化学数据集，其任务是预测给定分子的重要分子特性，即HOMO-LUMO间隙（图形回归）。  对于每个数据集，我们都会仔细设计其预测任务和数据拆分，以便在任务上实现较高的预测性能将直接影响相应的应用程序。每个数据集页面中都提供了更多详细信息。\n数据集统计信息和基本信息总结如下，表明我们的数据集非常大。 所有这些数据集都可以使用我们的ogbPython包 下载并准备。 模型评估和测试提交文件的准备工作也由我们的软件包处理。 用法在每个数据集页面中都有描述。请通过以下方式安装/更新：\n在我们的**论文中 **，我们进一步对每个数据集进行了广泛的基线分析，大规模实现了简单的基线模型以及高级的表达模型。我们发现，尽管需要更多的努力来进行扩展，但先进的表达模型确实会从大数据中受益，并且明显优于易于扩展的简单基线模型。我们所有的基准代码均已**公开提供， **以方便公众研究。\npip install -U ogb # Make sure below prints the required package version for the dataset you are working on. python -c \u0026quot;import ogb; print(ogb.__version__)\u0026quot; 总体而言，我们的KDD杯将鼓励社区开发和扩展表达性图ML模型，这可以在各个领域取得重大突破。我们希望在2021年KDD杯上的OGB-LSC能够成为图ML领域的“ ImageNet大规模视觉识别挑战”，鼓励社区致力于现实和大规模的图数据集，并显着提高现状-艺术。 OGB-LSC数据集论文 \nKaggle新赛题 赛题1 Shopee - Price Match Guarantee 通过两个图像确定两个产品是否相同\n https://www.kaggle.com/c/shopee-product-matching/overview/description\n 评估指标 采用F1-Score，参赛作品将根据其平均F1分数 进行评估。均值以样本方式计算，这意味着将为每个预测行计算F1分数，然后取平均值。\n选手必须创建一个以空格分隔的列表，posting_id该列表与该posting_id列中的发布匹配的所有。帖子总是自我匹配的。匹配个数上限为50，因此预测50场以上的对比赛没有好处。\n该文件应有一个标题，名为submission.csv，如下所示：\nposting_id,matches test_123,test_123 test_456,test_456 test_789 您应该预测每个比赛posting_id。例如，如果您认为A与B和C相匹配，则A,A B C还应包含B,B A C和C,C A B。\n时间线  2021 年3月8日-比赛开始日期 2021 年5月3日-报名截止日期。您必须在此日期之前接受比赛规则才能参加比赛。 2021 年5月3日-合并团队截止日期。这是参与者可以加入或合并团队的最后一天。 2021 年5月10日-最终提交截止日期。  奖金  第一名-$ 15,000 第二名-$ 10,000 第三名-$ 5,000  数据集 在大型数据集中查找近重复项是许多在线业务的重要问题。对于Shopee，日常用户可以上传自己的图像并撰写自己的产品说明，从而增加了挑战。您的任务是确定哪些产品已重复发布。相关产品之间的差异可能微妙，而相同产品的照片则可能千差万别！\n由于这是一场代码竞赛，因此仅发布测试集的前几行/图像；其余的仅在提交笔记本后才对您的笔记本可用。预计将在隐藏的测试集中找到大约70,000张图像。提供的一些测试行和图像旨在说明隐藏的测试集格式和文件夹结构。\n **[train / test] .csv-**训练集数据。每行包含一次过帐的数据。多个订单可能具有完全相同的图像ID，但标题不同，反之亦然。    posting_id -发布的ID码。\n  image -图片ID / md5sum。\n  image_phash-图像的感知哈希 。\n  title -发布的产品说明。\n  label_group-映射到同一产品的所有发布的ID码。未提供测试集。\n  [train / test] images-与发布相关的图像。\n**sample_submission.csv-**格式正确的示例提交文件。\n  posting_id -发布的ID码。\n  matches-以空格分隔的与此发布匹配的所有发布ID的列表。posting是自我匹配，匹配个数上限为50，因此无需预测超过50个数。\n  赛题2 Bristol-Myers Squibb – Molecular Translation 化学分子图像转换为化学结构序列 https://www.kaggle.com/c/bms-molecular-translation\n背景描述 在技术进步的世界中，有时最好，最简单的工具仍然是纸和笔。有机化学家经常利用骨架式（Skeletal formula）来绘制分子工作，骨架式是一个世纪以来使用的结构符号。最近的出版物还用机器可读的化学描述（InChI）进行了注释，但是数十年的扫描文档无法自动搜索特定的化学描述。在机器学习的帮助下，光学化学结构的自动识别可以加快研发的速度。\n不幸的是，大多数公共数据集太小，无法支持现代机器学习模型。现有工具只能在最佳条件下产生90％的精度。历史来源通常会在某种程度上破坏图像，从而将性能降低到接近零。在这些情况下，需要耗时的手动操作才能将扫描的化学结构图像可靠地转换为机器可读格式。\n百时美施贵宝公司是一家全球性生物制药公司，致力于通过科学改变患者的生活。他们的任务是发现，开发和提供可帮助患者战胜严重疾病的创新药物。\n在这场比赛中，您将解释旧的化学图像。通过访问由Bristol-Myers Squibb生成的大量合成图像数据，您可以将图像转换回标注为InChI文本的基础化学结构。\n整理化学文献的工具将对研究人员带来重大好处。如果成功，您将帮助化学家扩大进行集体化学研究的机会。反过来，通过避免重复先前发表的化学方法，并通过挖掘大数据集来识别新趋势，这将加快许多关键领域的研发工作。\n评估指标 根据您提交的InChi字符串与地面真实InChi值之间的平均Levenshtein距离 评估提交的内容。\n提交文件 对于image_id测试集中的每一个，您必须在相应的图像中预测分子的InChi字符串。该文件应包含标头，并具有以下格式：\nimage_id,InChI 00000d2a601c,InChI=1S/H2O/h1H2 00001f7fc849,InChI=1S/H2O/h1H2 000037687605,InChI=1S/H2O/h1H2 etc. 时间轴  2021 年3月2日-比赛开始日期 2021 年5月26日-报名截止日期。您必须在此日期之前接受比赛规则才能参加比赛。 2021 年5月26日-合并团队截止日期。这是参与者可以加入或合并团队的最后一天。 2021 年6月2日-最终提交截止日期。  奖金  第一名-$ 25,000 第二名-$ 15,000 第三名-$ 10,000  数据集 在本次比赛中，您将获得化学品的图像，目的是预测图像中相应的国际化学品识别码 （InChI）文本字符串。所提供的图像（训练数据和测试数据中的图像）都可以旋转到不同的角度，具有不同的分辨率，并且具有不同的噪声水平。\n**注意：**此数据集中总共约有4m张图像。解压缩下载的数据将花费时间。\n train / -训练图像，由3级文件夹结构排列image_id  test / -测试图像，与文件夹位于相同的文件夹结构中train/ train_labels.csv-训练图像的地面真相InChi标签 sample_submission.csv-格式正确的样本提交文件  ","permalink":"/posts/%E6%AF%94%E8%B5%9B%E6%8E%A8%E9%80%81/kaggle%E9%A1%B6%E7%BA%A7%E8%B5%9B%E4%BA%8B%E7%AD%89%E4%BD%A0%E6%9D%A5%E6%8E%92%E4%BD%8D/","series":["比赛推送"],"tags":["比赛推送"],"title":"【比赛推送】KDD 2021/ Kaggle 顶级赛事等你来排位"},{"categories":["招聘信息"],"content":"1 京东探索研究院（社招）  京东成立探索研究院，将深耕“人工智能”、“量子计算”、“数据科学、工程与管理”、“去中心化计算”、“技术伦理道德”、“科学与艺术”六大技术领域，从基础理论层面实现颠覆式创新，聚焦于打造产业数智化首个源头性科技高地，成为比肩国际领先科研机构的前沿技术基地，通过不断努力，在世界舞台上展现一家中国科技公司的担当、风范。\n  现在，京东探索研究院将在量子计算、机器感知、理论算法方向招募世界顶级科学家，组建首批科研团队，同时励众更多“青年科学家”加入。改变世界，从此刻开始。\n 2 蚂蚁集团（春招实习） 内推方式：\n大佬朋友的组，同学们抓紧上车 2022校招实习开始了，扫码内推，或者直接发简历到yongliang.wyl@antgroup.com。 阿里云 (暑期实习) 【阿里云-分布式块存储研发-暑期实习直推】（实习面向2022年毕业的学生） 一、团队介绍： 阿里云块存储团队，目前提供了中国最大的线上云存储服务。团队管理高效，技术积累丰富，培养体系成熟，在杭州、北京均设有团队。\n二、岗位职责： 1.负责阿里云分布式块存储万亿级别业务的架构设计、研发，提供高稳定性、高可靠性的分布式存储服务； 2.在现有系统设计基础上，完善优化现有系统架构设计，提升系统稳定性及可靠性； 3.为现有系统的稳定可靠运行，提供技术支持；\n三、岗位要求：\n 本科及以上学历在读学生，计算机、软件工程或相关专业或多年分布式开发相关经验者； 熟悉Linux系统开发环境，具有良好的代码风格和质量意识，熟悉C/C++等编程语言（其他语言也可以考虑，但需对C/C++有一定了解）; 有优秀的发现及解决问题的能力，良好的沟通能力及团队合作意识; 对分布式系统的架构和原理有深入了解者优先考虑； 有编程竞赛经验者或分布式系统开发经验者优先考虑。  四、简历投递 邮箱：liangliang.sll@alibaba-inc.com qq：495096408 直接发送简历到邮箱或者qq联系本人\n3 Moka(社招) 4 字节跳动2021春季校园招聘全面启动！（校招）  ps：信息来自友圈，有疑问或者问题可以联系后台进行处理\n ","permalink":"/posts/%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/kaggle%E9%A1%B6%E7%BA%A7%E8%B5%9B%E4%BA%8B%E7%AD%89%E4%BD%A0%E6%9D%A5%E6%8E%92%E4%BD%8D/","series":["招聘信息"],"tags":["招聘信息"],"title":"【阿里，字节，Moka】招聘信息汇总（ML、CV、NLP）"}]