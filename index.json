[{"categories":["æŠ€æœ¯åšå®¢"],"content":"1 å›¾å­¦ä¹ ä»»åŠ¡ æˆ‘ä»¬ç®€å•å›é¡¾ä¸‹ï¼Œä¸Šä¸€èŠ‚æˆ‘ä»¬ä»‹ç»äº†ï¼Œå›¾çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸»è¦æ˜¯ä»¥ä¸‹ä¸‰ç§ï¼š\n Node Level:èŠ‚ç‚¹çº§åˆ« Link Levelï¼šè¾¹çº§åˆ« Graph Levelï¼šå›¾çº§åˆ«Ã¥ å¹¶ä¸”ä¸‰éƒ¨åˆ†éš¾åº¦ä¾æ¬¡æ˜¯ç”±æµ…å…¥æ·±çš„   2 ä¼ ç»ŸMLæµç¨‹  å®šä¹‰å’Œè®¾è®¡èŠ‚ç‚¹/è¾¹/å›¾çš„ç‰¹å¾ å¯¹æ‰€æœ‰è®­ç»ƒæ•°æ®æ„é€ ç‰¹å¾  è®­ç»ƒMLæ¨¡å‹ ï¼ˆ1ï¼‰éšæœºæ£®æ— ï¼ˆ2ï¼‰æ”¯æŒå‘é‡æœº ï¼ˆ3ï¼‰ç¥ç»ç½‘ç»œç­‰ åº”ç”¨æ¨¡å‹ ç»™å®šä¸€ä¸ªæ–°çš„èŠ‚ç‚¹ã€è¾¹ã€å›¾ï¼Œç„¶åè·å–ç‰¹å¾è¿›è¡Œé¢„æµ‹  æˆ‘ä»¬æ€»ç»“ä¸‹ åŸºäºGraphçš„æœºå™¨å­¦ä¹ ç›¸å…³æ¦‚å¿µå’Œæµç¨‹ï¼Œé¦–å…ˆæ˜ç¡®ä¸‹ç›®æ ‡\nç›®æ ‡ï¼šå¯¹ä¸€äº›å¯¹è±¡é›†åˆè¿›è¡Œé¢„æµ‹ï¼Œæ¯”å¦‚æ˜¯åˆ†ç±»æˆ–è€…å›å½’ä»»åŠ¡ ç‰¹å¾è®¾è®¡ï¼š\n ç‰¹å¾:d-dimensionalå‘é‡ å¯¹è±¡ï¼šNodesï¼Œedgesï¼Œæˆ–è€…æ˜¯graps ç›®æ ‡å‡½æ•°ï¼šç»“åˆå…·ä½“ä»»åŠ¡è®¾è®¡ç›®æ ‡å‡½æ•°ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºç»™å®šä¸€ä¸ªå›¾G(V,E)ï¼Œå…¶ä¸­Vä»£è¡¨èŠ‚ç‚¹é›†åˆï¼ŒEä»£è¡¨è¾¹é›†åˆï¼Œç„¶åå­¦ä¹ èŠ‚ç‚¹åˆ°å‘é‡ç©ºé—´Rçš„æ˜ å°„å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬è¦å­¦ä¹ æƒé‡å‚æ•°W    ä¸ºäº†æ–¹ä¾¿ï¼Œæˆ‘ä»¬ä¸‹é¢çš„ä¾‹å­æ˜¯åŸºäºæ— å‘å›¾(undirected grpah)è¿›è¡Œè§£é‡Šçš„ã€‚\n 3 èŠ‚ç‚¹çº§åˆ«çš„ç›¸å…³ä»»åŠ¡ åŸºäºå›¾ä¸­å¸¦æœ‰æ ‡ç­¾çš„èŠ‚ç‚¹è®­ç»ƒæ¨¡å‹ï¼Œç„¶åé¢„æµ‹æœªæ ‡æ³¨èŠ‚ç‚¹çš„æ ‡ç­¾ï¼Œ åœ¨è¿™é‡Œæˆ‘ä»¬ä¸»è¦é˜è¿°ä¸‹Nodeçš„å››ç§ç‰¹å¾ï¼š\n Node degree:èŠ‚ç‚¹çš„åº¦ Node centrality:èŠ‚ç‚¹çš„ä¸­åº¦ Clustering coefficient:ç›¸ä¼¼æ€§ Graphlets:å›¾å…ƒ   èŠ‚ç‚¹çš„åº¦\n kvä»£è¡¨æ˜¯èŠ‚ç‚¹vä¸é‚»å±…èŠ‚ç‚¹ç›¸è¿è¾¹çš„ä¸ªæ•° æ‰€æœ‰é‚»å±…èŠ‚ç‚¹éƒ½æ˜¯ç›¸ç­‰çš„  å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒAçš„åº¦ä¸º1ï¼ŒBçš„åº¦ä¸º2ï¼ŒCçš„åº¦ä¸º3ï¼ŒDçš„åº¦ä¸º4 èŠ‚ç‚¹çš„ä¸­å¿ƒåº¦ Node Centrality\n èŠ‚ç‚¹çš„åº¦åªè®¡ç®—äº†ç›¸è¿èŠ‚ç‚¹çš„ä¸ªæ•°ï¼Œä½†æ˜¯æ²¡æœ‰è¯„ä¼°èŠ‚ç‚¹çš„é‡è¦æ€§ èŠ‚ç‚¹çš„ä¸­å¿ƒåº¦$c_v$è€ƒè™‘äº†èŠ‚ç‚¹åœ¨å›¾ä¸­çš„é‡è¦ç¨‹åº¦ èŠ‚ç‚¹çš„ä¸­å¿ƒåº¦æœ‰å¾ˆå¤šç§è®¡ç®—æ–¹å¼ï¼š (1) Engienvector centrality:ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ (2) Betweenness centrality:ä¸­ä»‹ä¸­å¿ƒæ€§ (3) Closeness centrality:ç´§å¯†ä¸­å¿ƒæ€§ (4) å…¶ä»–æ–¹å¼  Eigenvector centrality:ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§\n å¦‚æœä¸€ä¸ªèŠ‚ç‚¹çš„é‚»å±…èŠ‚ç‚¹ä»¬$u\\in N(v)$è¶Šé‡è¦ï¼Œé‚£ä¹ˆè¯¥èŠ‚ç‚¹$v$å°±è¶Šé‡è¦ æˆ‘ä»¬å°†èŠ‚ç‚¹ğ‘£çš„ä¸­å¿ƒæ€§å»ºæ¨¡ä¸ºç›¸é‚»èŠ‚ç‚¹çš„ä¸­å¿ƒæ€§ä¹‹å’Œï¼š $c_v=\\frac{1}{\\lambda}\\sum_{u \\in N(v)}{c_u}$ å…¶ä¸­$\\lambda$ä¸ºä¸€ä¸ªæ­£å¸¸æ•°ã€‚ æˆ‘ä»¬æ³¨æ„åˆ°ä¸Šé¢çš„ç­‰å¼æ˜¯é€šè¿‡é€’å½’çš„æ–¹å¼æ¥è®¡ç®—åº¦åº¦ä¸­å¿ƒæ€§çš„ï¼Œæ‰€æœ‰æˆ‘ä»¬åº”è¯¥æ€ä¹ˆæ±‚è§£  $c_v=\\frac{1}{\\lambda}\\sum_{u \\in N(v)}{c_u} \\iff \\lambda c=Ac$\nå…¶ä¸­$\\lambda$ä¸ºæ­£å¸¸æ•°ï¼Œ$A$ä¸ºé‚»æ¥çŸ©é˜µï¼Œå¦‚æœ$u \\in N(v)$ ,é‚£ä¹ˆ$A_{uv}=1$\n æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åº¦ä¸­å¿ƒæ€§æ˜¯ä¸€ä¸ªç‰¹å¾å‘é‡(eigenvector)ï¼Œæ ¹æ®éè´ŸçŸ©é˜µå®šç†(Perron-Frobenius Theorem)æˆ‘ä»¬å¯ä»¥çŸ¥é“$\\lambda_{max}$æ˜¯ä¸€ä¸ªæ­£å€¼å¹¶ä¸”æ˜¯å”¯ä¸€çš„ï¼Œç‰¹å¾å‘é‡$c_{max}$å½“åšåº¦ä¸­å¿ƒæ€§ã€‚  é€šå¸¸æ¥è¯´ï¼Œæœ‰è®¸å¤šä¸åŒçš„ç‰¹å¾å€¼$\\lambda$ èƒ½ä½¿å¾—ä¸€ä¸ªç‰¹å¾æ–¹ç¨‹æœ‰éé›¶è§£å­˜åœ¨ã€‚ç„¶è€Œï¼Œè€ƒè™‘åˆ°ç‰¹å¾å‘é‡ä¸­çš„æ‰€æœ‰é¡¹å‡ä¸ºéè´Ÿå€¼ï¼Œæ ¹æ®ä½©ä¼¦-å¼—ç½—è´å°¼ä¹Œæ–¯å®šç†ï¼Œåªæœ‰ç‰¹å¾å€¼æœ€å¤§æ—¶æ‰èƒ½æµ‹é‡å‡ºæƒ³è¦çš„ä¸­å¿ƒæ€§ã€‚ç„¶åé€šè¿‡è®¡ç®—ç½‘ç»œä¸­çš„èŠ‚ç‚¹$v$å…¶ç‰¹å¾å‘é‡çš„ç›¸å…³åˆ†é‡$v^{th}$ä¾¿èƒ½å¾—å‡ºå…¶å¯¹åº”çš„ä¸­å¿ƒæ€§çš„åˆ†æ•°ã€‚\n ç‰¹å¾å‘é‡çš„å®šä¹‰åªæœ‰ä¸€ä¸ªå…¬å› å­ï¼Œå› æ­¤å„èŠ‚ç‚¹ä¸­å¿ƒæ€§çš„æ¯”ä¾‹å¯ä»¥å¾ˆå¥½ç¡®å®šã€‚ä¸ºäº†ç¡®å®šä¸€ä¸ªç»å¯¹åˆ†æ•°ï¼Œå¿…é¡»å°†å…¶ä¸­ä¸€ä¸ªç‰¹å¾å€¼æ ‡å‡†åŒ–ï¼Œä¾‹å¦‚æ‰€æœ‰èŠ‚ç‚¹è¯„åˆ†ä¹‹å’Œä¸º1æˆ–è€…èŠ‚ç‚¹æ•° nã€‚å¹‚æ¬¡è¿­ä»£æ˜¯è®¸å¤šç‰¹å¾å€¼ç®—æ³•ä¸­çš„ä¸€ç§ï¼Œè¯¥ç®—æ³•å¯ä»¥ç”¨æ¥å¯»æ‰¾è¿™ç§ä¸»å¯¼ç‰¹å¾å‘é‡ã€‚æ­¤å¤–ï¼Œä»¥ä¸Šæ–¹æ³•å¯ä»¥æ¨å¹¿ï¼Œä½¿å¾—çŸ©é˜µAä¸­æ¯ä¸ªå…ƒç´ å¯ä»¥æ˜¯è¡¨ç¤ºè¿æ¥å¼ºåº¦çš„å®æ•°ï¼Œä¾‹å¦‚éšæœºçŸ©é˜µã€‚\u0026mdash;ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§wiki\n è¿™é‡Œå…¶å®æ¶‰åŠåˆ°æ¯”è¾ƒå¤šçš„çº¿æ€§ä»£æ•°çš„ç†è®ºä»¥åŠçŸ©é˜µåˆ†æçš„ç®—æ³•ï¼Œæˆ‘ç‰¹æ„æŸ¥äº†ä¸€äº›æ–‡ç« å¸®å¤§å®¶å»å›é¡¾å’Œç†è§£ä¸‹è¿™é‡Œæ¶‰åŠåˆ°çš„çŸ¥è¯†ï¼š (1) çº¿æ€§ä»£æ•°ä¹‹â€”â€”ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ (2)éè´ŸçŸ©é˜µä¹‹Perron-Frobeniuså®šç† (3)éè´ŸçŸ©é˜µ (4)å¹²è´§ | ä¸‡å­—é•¿æ–‡å¸¦ä½ å¤ä¹ çº¿æ€§ä»£æ•°ï¼  æˆ‘ä»¬è¿™é‡Œå†é€šè¿‡æ–‡ç« è°æ˜¯ç¤¾ä¼šç½‘ç»œä¸­æœ€é‡è¦çš„äººï¼Ÿ è§£é‡Šç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ï¼š ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§çš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œä¸€ä¸ªèŠ‚ç‚¹çš„ä¸­å¿ƒæ€§æ˜¯ç›¸é‚»èŠ‚ç‚¹ä¸­å¿ƒæ€§çš„å‡½æ•°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸ä½ è¿æ¥çš„äººè¶Šé‡è¦ï¼Œä½ ä¹Ÿå°±è¶Šé‡è¦ã€‚\nç‰¹å¾å‘é‡ä¸­å¿ƒæ€§å’Œç‚¹åº¦ä¸­å¿ƒæ€§ä¸åŒï¼Œä¸€ä¸ªç‚¹åº¦ä¸­å¿ƒæ€§é«˜å³æ‹¥æœ‰å¾ˆå¤šè¿æ¥çš„èŠ‚ç‚¹ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ä¸ä¸€å®šé«˜ï¼Œå› ä¸ºæ‰€æœ‰çš„è¿æ¥è€…æœ‰å¯èƒ½ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§å¾ˆä½ã€‚åŒç†ï¼Œç‰¹å¾å‘é‡ä¸­å¿ƒæ€§é«˜å¹¶ä¸æ„å‘³ç€å®ƒçš„ç‚¹åº¦ä¸­å¿ƒæ€§é«˜ï¼Œå®ƒæ‹¥æœ‰å¾ˆå°‘ä½†å¾ˆé‡è¦çš„è¿æ¥è€…ä¹Ÿå¯ä»¥æ‹¥æœ‰é«˜ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ã€‚\nè€ƒè™‘ä¸‹é¢çš„å›¾ï¼Œä»¥åŠç›¸åº”çš„5x5çš„é‚»æ¥çŸ©é˜µ(Adjacency Matrix)ï¼ŒAã€‚\né‚»æ¥çŸ©é˜µçš„å«ä¹‰æ˜¯ï¼Œå¦‚æœä¸¤ä¸ªèŠ‚ç‚¹æ²¡æœ‰ç›´æ¥è¿æ¥ï¼Œè®°ä¸º0ï¼Œå¦åˆ™è®°ä¸º1ã€‚\nç°åœ¨è€ƒè™‘xï¼Œä¸€ä¸ª5x1çš„å‘é‡ï¼Œå‘é‡çš„å€¼å¯¹åº”å›¾ä¸­çš„æ¯ä¸ªç‚¹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è®¡ç®—çš„æ˜¯æ¯ä¸ªç‚¹çš„ç‚¹åº¦ä¸­å¿ƒæ€§ï¼ˆdegree centralityï¼‰ï¼Œå³ä»¥ç‚¹çš„è¿æ¥æ•°æ¥è¡¡é‡ä¸­å¿ƒæ€§çš„é«˜ä½ã€‚\nçŸ©é˜µAä¹˜ä»¥è¿™ä¸ªå‘é‡çš„ç»“æœæ˜¯ä¸€ä¸ª5x1çš„å‘é‡ï¼š\nç»“æœå‘é‡çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç”¨çŸ©é˜µAçš„ç¬¬ä¸€è¡Œå»â€œè·å–â€æ¯ä¸€ä¸ªä¸ç¬¬ä¸€ä¸ªç‚¹æœ‰è¿æ¥çš„ç‚¹çš„å€¼ï¼ˆè¿æ¥æ•°ï¼Œç‚¹åº¦ä¸­å¿ƒæ€§ï¼‰ï¼Œä¹Ÿå°±æ˜¯ç¬¬2ä¸ªã€ç¬¬3ä¸ªå’Œç¬¬4ä¸ªç‚¹çš„å€¼ï¼Œç„¶åå°†å®ƒä»¬åŠ èµ·æ¥ã€‚\næ¢å¥è¯è¯´ï¼Œé‚»æ¥çŸ©é˜µåšçš„äº‹æƒ…æ˜¯å°†ç›¸é‚»èŠ‚ç‚¹çš„æ±‚å’Œå€¼é‡æ–°åˆ†é…ç»™æ¯ä¸ªç‚¹ã€‚è¿™æ ·åšçš„ç»“æœå°±æ˜¯â€œæ‰©æ•£äº†â€ç‚¹åº¦ä¸­å¿ƒæ€§ã€‚ä½ çš„æœ‹å‹çš„æœ‹å‹è¶Šå¤šï¼Œä½ çš„ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§å°±è¶Šé«˜ã€‚\næˆ‘ä»¬ç»§ç»­ç”¨çŸ©é˜µAä¹˜ä»¥ç»“æœå‘é‡ã€‚å¦‚ä½•ç†è§£å‘¢ï¼Ÿå®é™…ä¸Šï¼Œæˆ‘ä»¬å…è®¸è¿™ä¸€ä¸­å¿ƒæ€§æ•°å€¼å†æ¬¡æ²¿ç€å›¾çš„è¾¹ç•Œâ€œæ‰©æ•£â€ã€‚æˆ‘ä»¬ä¼šè§‚å¯Ÿåˆ°ä¸¤ä¸ªæ–¹å‘ä¸Šçš„æ‰©æ•£ï¼ˆç‚¹æ—¢ç»™äºˆä¹Ÿæ”¶è·ç›¸é‚»èŠ‚ç‚¹ï¼‰ã€‚æˆ‘ä»¬çŒœæµ‹ï¼Œè¿™ä¸€è¿‡ç¨‹æœ€åä¼šè¾¾åˆ°ä¸€ä¸ªå¹³è¡¡ï¼Œç‰¹å®šç‚¹æ”¶è·çš„æ•°é‡ä¼šå’Œå®ƒç»™äºˆç›¸é‚»èŠ‚ç‚¹çš„æ•°é‡å–å¾—å¹³è¡¡ã€‚æ—¢ç„¶æˆ‘ä»¬ä»…ä»…æ˜¯ç´¯åŠ ï¼Œæ•°å€¼ä¼šè¶Šæ¥è¶Šå¤§ï¼Œä½†æˆ‘ä»¬æœ€ç»ˆä¼šåˆ°è¾¾ä¸€ä¸ªç‚¹ï¼Œå„ä¸ªèŠ‚ç‚¹åœ¨æ•´ä½“ä¸­çš„æ¯”ä¾‹ä¼šä¿æŒç¨³å®šã€‚\nç°åœ¨æŠŠæ‰€æœ‰ç‚¹çš„æ•°å€¼æ„æˆçš„å‘é‡ç”¨æ›´ä¸€èˆ¬çš„å½¢å¼è¡¨ç¤ºï¼š\næˆ‘ä»¬è®¤ä¸ºï¼Œå›¾ä¸­çš„ç‚¹å­˜åœ¨ä¸€ä¸ªæ•°å€¼é›†åˆï¼Œå¯¹äºå®ƒï¼Œç”¨çŸ©é˜µAå»ä¹˜ä¸ä¼šæ”¹å˜å‘é‡å„ä¸ªæ•°å€¼çš„ç›¸å¯¹å¤§å°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒçš„æ•°å€¼ä¼šå˜å¤§ï¼Œä½†ä¹˜ä»¥çš„æ˜¯åŒä¸€ä¸ªå› å­ã€‚ç”¨æ•°å­¦ç¬¦å·è¡¨ç¤ºå°±æ˜¯ï¼š\næ»¡è¶³è¿™ä¸€å±æ€§çš„å‘é‡å°±æ˜¯çŸ©é˜µMçš„ç‰¹å¾å‘é‡ã€‚ç‰¹å¾å‘é‡çš„å…ƒç´ å°±æ˜¯å›¾ä¸­æ¯ä¸ªç‚¹çš„ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ã€‚\nç‰¹å¾å‘é‡ä¸­å¿ƒæ€§çš„è®¡ç®—éœ€è¦è¯»è€…å…·å¤‡çŸ©é˜µä¹˜æ³•å’Œç‰¹å¾å‘é‡çš„çŸ¥è¯†ï¼Œä½†ä¸å½±å“è¿™é‡Œè¯»è€…å¯¹ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§æ€æƒ³çš„ç†è§£ï¼Œä¸å†èµ˜è¿°ã€‚\nBetweenness centrality:ä¸­ä»‹ä¸­å¿ƒæ€§ å¦‚æœä¸€ä¸ªèŠ‚ç‚¹ä½äºå¾ˆå¤šæ¡å…¶ä»–èŠ‚ç‚¹çš„æœ€çŸ­è·¯å¾„ä¸Šï¼Œé‚£ä¹ˆæ”¹èŠ‚ç‚¹æ¯”è¾ƒé‡è¦ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š $c_{v}=\\sum_{s\\not=v\\not=t}{\\frac{#(shortes,paths ,betwen ,ğ‘  , and , ğ‘¡ , that ,contain ,ğ‘£)}{#(shortest ,paths ,between ,\u0026lsquo;ğ‘ \u0026rsquo; ,and ,\u0026lsquo;ğ‘¡\u0026rsquo;)}}$ æˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸ªä¸‹é¢çš„ä¾‹å­ï¼š å‡è®¾æˆ‘ä»¬è¦è®¡ç®—Dçš„ä¸­ä»‹ä¸­å¿ƒæ€§ï¼š\n é¦–å…ˆï¼Œæˆ‘ä»¬è®¡ç®—èŠ‚ç‚¹Dä¹‹å¤–ï¼Œæ‰€æœ‰èŠ‚ç‚¹å¯¹ä¹‹é—´çš„æœ€çŸ­è·¯å¾„æœ‰å¤šå°‘æ¡ï¼Œè¿™é‡Œæ˜¯1æ¡ï¼ˆåœ¨5ä¸ªèŠ‚ç‚¹ä¸­é€‰æ‹©ä¸¤ä¸ªèŠ‚ç‚¹å³èŠ‚ç‚¹å¯¹çš„ä¸ªæ•°ï¼‰ã€‚ ç„¶åï¼Œæˆ‘ä»¬å†çœ‹æ‰€æœ‰è¿™äº›æœ€çŸ­è·¯å¾„ä¸­æœ‰å¤šå°‘æ¡ç»è¿‡èŠ‚ç‚¹Dï¼Œä¾‹å¦‚èŠ‚ç‚¹Aè¦æƒ³æ‰¾åˆ°èŠ‚ç‚¹Eï¼Œå¿…é¡»ç»è¿‡èŠ‚ç‚¹Dã€‚ç»è¿‡èŠ‚ç‚¹Dçš„æœ€çŸ­è·¯å¾„æœ‰3æ¡ï¼ˆA-C-D-Eï¼ŒB-D-Eï¼ŒC-D-Eï¼‰ã€‚ æœ€åï¼Œæˆ‘ä»¬ç”¨ç»è¿‡èŠ‚ç‚¹Dçš„æœ€çŸ­è·¯å¾„é™¤ä»¥æ‰€æœ‰èŠ‚ç‚¹å¯¹çš„æœ€çŸ­è·¯å¾„æ€»æ•°ï¼Œè¿™ä¸ªæ¯”ç‡å°±æ˜¯èŠ‚ç‚¹Dçš„ä¸­ä»‹ä¸­å¿ƒæ€§ã€‚èŠ‚ç‚¹Dçš„ä¸­ä»‹ä¸­å¿ƒæ€§æ˜¯3/1=3ã€‚  4 PyTorch Geometricæ•™ç¨‹ å®˜æ–¹æ–‡æ¡£ï¼šhttps://pytorch-geometric.readthedocs.io/en/latest/index.html\nPyTorch Geometricï¼ˆPyGï¼‰æ˜¯PyTorchçš„æ‰©å±•åº“ã€‚ å®ƒæä¾›äº†æœ‰ç”¨çš„æ¡†æ¶æ¥å¼€å‘å›¾æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ŒåŒ…æ‹¬å„ç§å›¾ç¥ç»ç½‘ç»œå±‚å’Œå¤§é‡åŸºå‡†æ•°æ®é›†ã€‚\nå¦‚æœæˆ‘ä»¬æš‚æ—¶ä¸äº†è§£æŸäº›æ¦‚å¿µï¼Œä¾‹å¦‚â€œ GCNConvâ€ï¼Œè¯·ä¸è¦æ‹…å¿ƒï¼Œä¹‹åæˆ‘ä»¬å°†åœ¨ä»¥åçš„æ–‡ç« ä¸­ä»‹ç»è¿™äº›æ¦‚å¿µã€‚\nè¿™ä¸ªæ•™ç¨‹æ¥è‡ªï¼š https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=ci-LpZWhRJoI by Matthias Fey å¤§å®¶å¯ä»¥å‚ç…§colabæ•™ç¨‹ç›´æ¥è¿è¡Œ\n4.1 PyGå®‰è£…  æŸ¥çœ‹å½“å‰torchå’Œcudaç‰ˆæœ¬  !python -c \u0026quot;import torch; print(torch.__version__)\u0026quot; è¾“å‡ºï¼š1.6.0\n!python -c \u0026quot;import torch; print(torch.version.cuda)\u0026quot; è¾“å‡ºï¼š10.1\n å®‰è£…gpuç‰ˆæœ¬  # å®‰è£…GPUç‰ˆæœ¬ !pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html !pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html !pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html !pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html !pip install torch-geometric å¯èƒ½å®‰è£…gpuç‰ˆæœ¬æ¯”è¾ƒéº»çƒ¦ï¼Œå¤§å®¶å¯ä»¥å¤šå‚ç…§ä¸‹å®˜ç½‘è¿›è¡Œå®‰è£…ï¼š https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n å®‰è£…cudaç‰ˆæœ¬  !pip install torch-scatter==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.6.0.html !pip install torch-sparse==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.6.0.html !pip install torch-cluster==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.6.0.html !pip install torch-spline-conv==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.6.0.html !pip install torch-geometric 4.2 PyGæ•°æ®é›† PyTorch Geometric å¯ä»¥é€šè¿‡ torch_geometric.datasets å¿«é€Ÿçš„è·å–é»˜è®¤çš„æ•°æ®é›†:\nhttps://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html\nä¸€å…±æœ‰20+ç§æ•°æ®ï¼Œæ¯”è¾ƒä¸°å¯Œ~\n# å¯¼å…¥ç©ºæ‰‹é“ä¿±ä¹éƒ¨æ•°æ®é›† from torch_geometric.datasets import KarateClub dataset = KarateClub() print(f'Dataset: {dataset}:') print('======================') print(f'Number of graphs: {len(dataset)}') print(f'Number of features: {dataset.num_features}') print(f'Number of classes: {dataset.num_classes}') è¾“å‡ºï¼š\nDataset: KarateClub(): ====================== Number of graphs: 1 Number of features: 34 Number of classes: 4 åˆå§‹åŒ–[KarateClub]ï¼ˆhttps://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.KarateClubï¼‰ æ•°æ®é›†ä¹‹åï¼Œæˆ‘ä»¬é¦–å…ˆå¯ä»¥æ£€æŸ¥å…¶æŸäº›å±æ€§ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¯¥æ•°æ®é›†æ°å¥½æœ‰ä¸€ä¸ªGraphï¼Œå¹¶ä¸”è¯¥æ•°æ®é›†ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½è¢«åˆ†é…äº†** 34ç»´ç‰¹å¾å‘é‡**ï¼ˆå”¯ä¸€åœ°æè¿°äº†ç©ºæ‰‹é“ä¿±ä¹éƒ¨çš„æˆå‘˜ï¼‰ã€‚ æ­¤å¤–ï¼Œè¯¥å›¾æ­£å¥½åŒ…å«** 4ä¸ªç±»åˆ«**ï¼Œä»£è¡¨æ¯ä¸ªèŠ‚ç‚¹æ‰€å±çš„ç¤¾åŒºã€‚\nç°åœ¨è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°çœ‹ä¸€ä¸‹è¿™ä¸ªGraphï¼š\ndata = dataset[0] # è·å–graphå¯¹è±¡. print(data) print(\u0026#39;==============================================================\u0026#39;) # è·å–ä¸€äº›graphçš„ç»Ÿè®¡ä¿¡æ¯. print(f\u0026#39;Number of nodes: {data.num_nodes}\u0026#39;) # èŠ‚ç‚¹çš„ä¸ªæ•° print(f\u0026#39;Number of edges: {data.num_edges}\u0026#39;) # è¾¹çš„ä¸ªå±äº print(f\u0026#39;Average node degree: {data.num_edges / data.num_nodes:.2f}\u0026#39;) # èŠ‚ç‚¹çš„åº¦å¹³å‡æ•° print(f\u0026#39;Number of training nodes: {data.train_mask.sum()}\u0026#39;) print(f\u0026#39;Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}\u0026#39;) print(f\u0026#39;Contains isolated nodes: {data.contains_isolated_nodes()}\u0026#39;) print(f\u0026#39;Contains self-loops: {data.contains_self_loops()}\u0026#39;) print(f\u0026#39;Is undirected: {data.is_undirected()}\u0026#39;) è¾“å‡ºå¦‚ä¸‹ï¼š\n Data(edge_index=[2, 156], train_mask=[34], x=[34, 34], y=[34]) ============================================================== Number of nodes: 34 Number of edges: 156 Average node degree: 4.59 Number of training nodes: 4 Training node label rate: 0.12 Contains isolated nodes: False Contains self-loops: False Is undirected: True é€šè¿‡ä¸Šé¢çš„ä¿¡æ¯æˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œè¿™ä¸ªKarateClubç½‘ç»œå›¾ä¸€å…±æœ‰34ä¸ªèŠ‚ç‚¹ï¼Œè¾¹çš„ä¸ªæ•°ä¸º1ï¼Œæ¯ä¸ªèŠ‚ç‚¹åº¦çš„å¹³å‡æ•°æœ‰4.59ï¼Œæ˜¯ä¸€ä¸ªæ— å‘å›¾ç­‰ç­‰ã€‚\n4.3 Dataå¯¹è±¡ PyTorch Geometricä¸­çš„æ¯ä¸ªå›¾å½¢éƒ½ç”±å•ä¸ª[Data]ï¼ˆhttps://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Dataï¼‰å¯¹è±¡è¡¨ç¤ºï¼Œè¯¥å¯¹è±¡åŒ…å«æ‰€æœ‰ æè¿°å…¶å›¾å½¢è¡¨ç¤ºçš„ä¿¡æ¯ã€‚ æˆ‘ä»¬å¯ä»¥éšæ—¶é€šè¿‡printï¼ˆdataï¼‰æ‰“å°æ•°æ®å¯¹è±¡ï¼Œä»¥æ¥æ”¶æœ‰å…³å…¶å±æ€§åŠå…¶å½¢çŠ¶çš„ç®€çŸ­ä»‹ç»ï¼š\nData(edge_index=[2, 156], x=[34, 34], y=[34], train_mask=[34]) æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸ªdataå¯¹è±¡æ‹¥æœ‰4ä¸ªå±æ€§ï¼š ï¼ˆ1ï¼‰â€œ edge_indexâ€å±æ€§ä¿å­˜æœ‰å…³â€œå›¾å½¢è¿æ¥æ€§â€ï¼ˆå³*ï¼‰çš„ä¿¡æ¯ï¼Œå³æ¯ä¸ªè¾¹ç¼˜çš„æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹ç´¢å¼•çš„å…ƒç»„ã€‚ PyGè¿›ä¸€æ­¥å°† ï¼ˆ2ï¼‰èŠ‚ç‚¹ç‰¹å¾**ç§°ä¸ºxï¼ˆå‘34ä¸ªèŠ‚ç‚¹ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹åˆ†é…äº†34ç»´åº¦çš„ç‰¹å¾å‘é‡ï¼‰ï¼Œå°† ï¼ˆ3ï¼‰èŠ‚ç‚¹æ ‡è®°**ç§°ä¸ºyï¼ˆæ¯ä¸ªèŠ‚ç‚¹ä»…åˆ†é…ç»™ä¸€ä¸ªç±»åˆ«ï¼‰ã€‚ ï¼ˆ4ï¼‰è¿˜æœ‰ä¸€ä¸ªåä¸ºâ€œ train_maskâ€çš„é™„åŠ å±æ€§ï¼Œå®ƒæè¿°äº†æˆ‘ä»¬å·²ç»çŸ¥é“å…¶ç¤¾åŒºå½’å±çš„èŠ‚ç‚¹ã€‚ æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬åªçŸ¥é“4ä¸ªèŠ‚ç‚¹çš„åŸºæœ¬æ ‡ç­¾ï¼ˆæ¯ä¸ªç¤¾åŒºä¸€ä¸ªï¼‰ï¼Œä»»åŠ¡æ˜¯æ¨æ–­å…¶ä½™èŠ‚ç‚¹çš„ç¤¾åŒºåˆ†é…ã€‚\næ•°æ®å¯¹è±¡è¿˜æä¾›äº†ä¸€äº›â€œå®ç”¨åŠŸèƒ½â€æ¥æ¨æ–­åŸºç¡€å›¾çš„ä¸€äº›åŸºæœ¬å±æ€§ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾æ¨æ–­å›¾ä¸­æ˜¯å¦å­˜åœ¨å­¤ç«‹çš„èŠ‚ç‚¹ï¼ˆ* ie *ä»»ä½•èŠ‚ç‚¹éƒ½æ²¡æœ‰è¾¹ï¼‰ï¼Œå›¾æ˜¯å¦åŒ…å«è‡ªç¯(*i.e.*, $(v, v) \\in \\mathcal{E}$)ï¼Œæˆ–è€…å›¾å½¢æ˜¯å¦æ˜¯æ— å‘çš„ï¼ˆ (*i.e.*, for each edge $(v, w) \\in \\mathcal{E}$ there also exists the edge $(w, v) \\in \\mathcal{E}$).\nfrom IPython.display import Javascript # Restrict height of output cell. display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})''')) edge_index = data.edge_index # æ‰“å°èŠ‚ç‚¹ print(edge_index.t()) è¾“å‡ºï¼š\ntensor([[ 0, 1], [ 0, 2], [ 0, 3], [ 0, 4], [ 0, 5], [ 0, 6], [ 0, 7], [ 0, 8], [ 0, 10], .... [33, 31], [33, 32]]) é€šè¿‡æ‰“å°â€œ edge_indexâ€ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥äº†è§£PyGå¦‚ä½•åœ¨å†…éƒ¨è¡¨ç¤ºå›¾å½¢è¿æ¥ã€‚ æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äºæ¯ä¸ªè¾¹ç¼˜ï¼Œâ€œ edge_indexâ€éƒ½åŒ…å«ä¸¤ä¸ªèŠ‚ç‚¹ç´¢å¼•çš„å…ƒç»„ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå€¼æè¿°æºèŠ‚ç‚¹çš„èŠ‚ç‚¹ç´¢å¼•ï¼Œç¬¬äºŒä¸ªå€¼æè¿°è¾¹ç¼˜ç›®æ ‡èŠ‚ç‚¹çš„èŠ‚ç‚¹ç´¢å¼•ã€‚\nè¿™ç§è¡¨ç¤ºç§°ä¸º** COOæ ¼å¼ï¼ˆåæ ‡æ ¼å¼ï¼‰**ï¼Œé€šå¸¸ç”¨äºè¡¨ç¤ºç¨€ç–çŸ©é˜µã€‚ ä»£æ›¿ä»¥å¯†é›†è¡¨ç¤ºå½¢å¼ä¿å­˜é‚»æ¥ä¿¡æ¯ $\\mathbf{A} \\in { 0, 1 }^{|\\mathcal{V}| \\times |\\mathcal{V}|}$,ï¼ŒPyGç¨€ç–åœ°è¡¨ç¤ºå›¾å½¢ï¼Œè¿™æ˜¯æŒ‡ä»…ä¿å­˜ $\\mathbf{A}$ ä¸­çš„æ¡ç›®ä¸ºéé›¶çš„åæ ‡/å€¼ã€‚\næœ€åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†å›¾å½¢è½¬æ¢ä¸ºnetworkxåº“æ ¼å¼æ¥è¿›ä¸€æ­¥å¯è§†åŒ–å›¾å½¢ï¼Œè¯¥æ ¼å¼é™¤äº†å›¾å½¢æ“ä½œåŠŸèƒ½ä¹‹å¤–ï¼Œè¿˜å®ç°äº†å¼ºå¤§çš„å¯è§†åŒ–å·¥å…·ã€‚æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸“é—¨ç”¨äºå±•ç¤ºGraphçš„å‡½æ•°\n%matplotlib inline import torch import networkx as nx import matplotlib.pyplot as plt # Visualization function for NX graph or PyTorch tensor def visualize(h, color, epoch=None, loss=None): plt.figure(figsize=(7,7)) plt.xticks([]) plt.yticks([]) if torch.is_tensor(h): h = h.detach().cpu().numpy() plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\u0026quot;Set2\u0026quot;) if epoch is not None and loss is not None: plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16) else: nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False, node_color=color, cmap=\u0026quot;Set2\u0026quot;) plt.show() from torch_geometric.utils import to_networkx G = to_networkx(data, to_undirected=True) visualize(G, color=data.y) 4.4 å®æˆ˜ï¼šåŸºäºGCNçš„GraphèŠ‚ç‚¹åˆ†ç±»  æ¥ä¸‹æ¥å°†é€šè¿‡Pytorchå®ç°ä¸€ä¸ªæœ€åŸºæœ¬çš„GCNç½‘ç»œç”¨è¯­èŠ‚ç‚¹åˆ†ç±»ï¼ŒåŸºäºå¸¦æœ‰æ ‡ç­¾çš„èŠ‚ç‚¹æ•°æ®è¿›è¡Œè®­ç»ƒæ¨¡å‹ï¼Œç„¶åé¢„æµ‹æœªå¸¦æœ‰æ ‡ç­¾çš„æ•°æ®\n åœ¨äº†è§£äº†PyGçš„æ•°æ®å¤„ç†ä¹‹åï¼Œæ˜¯æ—¶å€™å®ç°æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªGraphç¥ç»ç½‘ç»œäº†ï¼æˆ‘ä»¬åœ¨è¿™é‡Œå°†ä½¿ç”¨æœ€ç®€å•çš„GNNç½‘ç»œä¹‹ä¸€ï¼Œå³GCNå±‚**ï¼ˆ[Kipfç­‰äººï¼ˆ2017ï¼‰]ï¼ˆhttps://arxiv.org/abs/1609.02907ï¼‰ï¼‰ç”¨äºGraphèŠ‚ç‚¹åˆ†ç±»ã€‚\nPyGé€šè¿‡[GCNConv]ï¼ˆhttps://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConvï¼‰æ¥å®ç°æ­¤å±‚ï¼Œå¯ä»¥é€šè¿‡ä¼ å…¥ èŠ‚ç‚¹è¦ç´ è¡¨ç¤ºå½¢å¼â€œ xâ€å’ŒCOOå›¾å½¢è¿æ¥æ€§è¡¨ç¤ºå½¢å¼â€œ edge_indexâ€ã€‚\nè¿™æ ·ï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡åœ¨torch.nn.Moduleç±»ä¸­å®šä¹‰æˆ‘ä»¬çš„ç½‘ç»œæ¶æ„æ¥åˆ›å»ºæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå›¾å½¢ç¥ç»ç½‘ç»œï¼š\nimport torch from torch.nn import Linear from torch_geometric.nn import GCNConv class GCN(torch.nn.Module): def __init__(self): super(GCN, self).__init__() torch.manual_seed(12345) self.conv1 = GCNConv(dataset.num_features, 4) self.conv2 = GCNConv(4, 4) self.conv3 = GCNConv(4, 2) self.classifier = Linear(2, dataset.num_classes) def forward(self, x, edge_index): h = self.conv1(x, edge_index) h = h.tanh() h = self.conv2(h, edge_index) h = h.tanh() h = self.conv3(h, edge_index) h = h.tanh() # Final GNN embedding space. # Apply a final (linear) classifier. out = self.classifier(h) return out, h model = GCN() print(model) ç½‘ç»œç»“æ„è¾“å‡ºå¦‚ä¸‹ï¼š\nGCN( (conv1): GCNConv(34, 4) (conv2): GCNConv(4, 4) (conv3): GCNConv(4, 2) (classifier): Linear(in_features=2, out_features=4, bias=True) ) åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨__init__ä¸­åˆå§‹åŒ–æ‰€æœ‰æ„å»ºå—ï¼Œå¹¶åœ¨â€œè½¬å‘â€ä¸­å®šä¹‰ç½‘ç»œçš„è®¡ç®—æµç¨‹ã€‚ æˆ‘ä»¬é¦–å…ˆå®šä¹‰å¹¶å †å ä¸‰å±‚å›¾å·ç§¯å±‚ï¼Œè¿™å¯¹åº”äºåœ¨æ¯ä¸ªèŠ‚ç‚¹å‘¨å›´ï¼ˆè·ç¦»3ä¸ªâ€œè·³â€ä¸ºæ­¢çš„æ‰€æœ‰èŠ‚ç‚¹ï¼‰æ±‡æ€»3è·³é‚»åŸŸä¿¡æ¯ã€‚ å¦å¤–ï¼ŒGCNConvå±‚å°†èŠ‚ç‚¹ç‰¹å¾ç»´æ•°å‡å°ä¸º$2$, i.e., $34 \\rightarrow 4 \\rightarrow 4 \\rightarrow 2$.ã€‚æ¯ä¸ª[GCNConv]å±‚éƒ½é€šè¿‡[tanh]ï¼ˆhttps://pytorch.org/docs/stable/generation/torch.nn.Tanh.html?highlight=tanh#torch.nn.Tanhï¼‰éçº¿æ€§è¿›è¡Œäº†å¢å¼ºã€‚\nä¹‹åï¼Œæˆ‘ä»¬åº”ç”¨å•ä¸ªçº¿æ€§å˜æ¢ï¼ˆ[torch.nn.Linear]ï¼ˆhttps://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nnã€‚çº¿æ€§ï¼‰ï¼‰ï¼Œç”¨ä½œå°†æˆ‘ä»¬çš„èŠ‚ç‚¹æ˜ å°„åˆ°4ä¸ªç±»/ç¤¾åŒºä¸­çš„1ä¸ªçš„åˆ†ç±»å™¨ã€‚\næˆ‘ä»¬è¿”å›æœ€ç»ˆåˆ†ç±»å™¨çš„è¾“å‡ºä»¥åŠGNNç”Ÿæˆçš„æœ€ç»ˆèŠ‚ç‚¹åµŒå…¥ã€‚ æˆ‘ä»¬ç»§ç»­é€šè¿‡GCN()åˆå§‹åŒ–æœ€ç»ˆæ¨¡å‹ï¼Œå¹¶æ‰“å°æˆ‘ä»¬çš„æ¨¡å‹ä»¥äº§ç”Ÿæ‰€æœ‰ä½¿ç”¨è¿‡çš„å­æ¨¡å—çš„æ¦‚æ‹¬ã€‚\nè·å–éšè—å±‚çš„è¡¨ç¤ºï¼š\nmodel = GCN() _, h = model(data.x, data.edge_index) print(f'Embedding shape: {list(h.shape)}') visualize(h, color=data.y) è¾“å‡ºï¼š\nEmbedding shape: [34, 2] åœ¨è¿™é‡Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå³ä½¿åœ¨è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹æƒé‡ä¹‹å‰ï¼Œè¿™ä¸ªåˆå§‹åŒ–çš„GCNç½‘ç»œä¹Ÿä¼šäº§ç”ŸèŠ‚ç‚¹çš„åµŒå…¥ï¼Œå¹¶ä¸”è¿™äº›åµŒå…¥ä¸å›¾çš„ç¤¾åŒºç»“æ„éå¸¸ç›¸ä¼¼ã€‚å°½ç®¡æˆ‘ä»¬çš„æ¨¡å‹çš„æƒé‡æ˜¯â€œå®Œå…¨éšæœºåœ°åˆå§‹åŒ–â€çš„ï¼Œå¹¶ä¸”åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰è¿›è¡Œä»»ä½•è®­ç»ƒï¼Œä½†æ˜¯ç›¸åŒé¢œè‰²ï¼ˆç¤¾åŒºï¼‰çš„èŠ‚ç‚¹å·²ç»åœ¨åµŒå…¥ç©ºé—´ä¸­ç´§å¯†åœ°èšé›†åœ¨ä¸€èµ·ã€‚å¾—å‡ºè¿™æ ·çš„ç»“è®ºï¼Œå³GNNå¼•å…¥äº†å¼ºçƒˆçš„èŠ‚ç‚¹åå·®ï¼Œä»è€Œå¯¼è‡´åœ¨è¾“å…¥å›¾ä¸­å½¼æ­¤é è¿‘çš„èŠ‚ç‚¹å…·æœ‰ç›¸ä¼¼çš„åµŒå…¥ã€‚\nä½†æ˜¯ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºå¹¶ä¸æ˜¯å¾ˆå®Œç¾ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºæ¥å››ç§ç±»åˆ«çš„èŠ‚ç‚¹è¿˜æ˜¯æ··åœ¨ä¸€å—äº†ï¼ˆå¯¹åº”é€”ä¸­æ˜¯å››ç§é¢œè‰²ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åšå¾—æ›´å¥½å—ï¼Ÿ è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼Œè¯¥ç¤ºä¾‹å¦‚ä½•åŸºäºå¯¹å›¾ä¸­4å››ç§èŠ‚ç‚¹çš„ç¤¾åŒºåˆ†é…ï¼ˆæ¯ä¸ªç¤¾åŒºä¸€ä¸ªï¼‰çš„çŸ¥è¯†æ¥è®­ç»ƒæˆ‘ä»¬çš„ç½‘ç»œå‚æ•°ï¼š\nç”±äºæ¨¡å‹ä¸­çš„æ‰€æœ‰å†…å®¹éƒ½æ˜¯å¯åŒºåˆ†çš„å’Œå‚æ•°åŒ–çš„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€äº›æ ‡ç­¾ï¼Œè®­ç»ƒæ¨¡å‹å¹¶è§‚å¯ŸåµŒå…¥å¦‚ä½•ååº”ã€‚ åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç§åŠç›‘ç£å­¦ä¹ ç¨‹åºï¼šæˆ‘ä»¬ä»…é’ˆå¯¹æ¯ä¸ªç±»è®­ç»ƒä¸€ä¸ªèŠ‚ç‚¹ï¼Œä½†æ˜¯å…è®¸ä½¿ç”¨å®Œæ•´çš„è¾“å…¥å›¾æ•°æ®ã€‚\nè¿™ä¸ªæ€ä¹ˆç†è§£å‘¢ï¼Œæˆ‘ä»¬å…¶å®å¯ä»¥è¾“å‡ºdata.yå’Œdata.train_maskå°±æ˜ç™½äº†:\ndata.y tensor([0, 0, 0, 0, 1, 1, 1, 0, 2, 2, 1, 0, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2]) data.train_mask tensor([ True, False, False, False, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False]) å¤§å®¶å¯ä»¥çœ‹åˆ°ç›¸å½“äºæˆ‘ä»¬è®­ç»ƒç½‘ç»œçš„æ—¶å€™åªé’ˆå¯¹æ¯ä¸€ä¸ªç±»åˆ«ä¸‹çš„tokenåšä¼˜åŒ–ï¼Œè¿™æ ·å¯ä»¥åŠ é€Ÿç½‘ç»œçš„è®­ç»ƒå’Œæ”¶æ•›ã€‚\nè®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ä¸ä»»ä½•å…¶ä»–PyTorchæ¨¡å‹éå¸¸ç›¸ä¼¼ã€‚ é™¤äº†å®šä¹‰æˆ‘ä»¬çš„ç½‘ç»œæ¶æ„ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å®šä¹‰äº†æŸå¤±å‡½æ•°åœ¨è¿™é‡Œ[[CrossEntropyLoss]]ï¼ˆhttps://pytorch.org/docs/stable/generate/torch.nn.CrossEntropyLoss.htmlï¼‰ï¼‰ å¹¶åˆå§‹åŒ–éšæœºæ¢¯åº¦ä¼˜åŒ–å™¨ï¼ˆæ­¤å¤„ä¸º[Adam]ï¼ˆhttps://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adamï¼‰ï¼‰ã€‚ ä¹‹åï¼Œæˆ‘ä»¬æ‰§è¡Œå¤šè½®ä¼˜åŒ–ï¼Œå…¶ä¸­æ¯ä¸€è½®éƒ½åŒ…å«ä¸€ä¸ªæ­£å‘å’Œåå‘ä¼ é€’ï¼Œä»¥è®¡ç®—æ¨¡å‹å‚æ•°w.r.tçš„æ¢¯åº¦ã€‚ä»å‰å‘é€šè¡Œè¯äº§ç”Ÿçš„æŸå¤±ã€‚ å¦‚æœæ‚¨å¯¹PyTorchå¹¶ä¸é™Œç”Ÿï¼Œåˆ™è¯¥æ–¹æ¡ˆåº”è¯¥å¯¹æ‚¨æ¥è¯´å¾ˆç†Ÿæ‚‰ã€‚ å¦åˆ™ï¼ŒPyTorchæ–‡æ¡£ä¼šæä¾›[æœ‰å…³å¦‚ä½•åœ¨PyTorchä¸­è®­ç»ƒç¥ç»ç½‘ç»œçš„å¾ˆå¥½çš„ä»‹ç»]ï¼ˆhttps://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-loss-function-and-optimizer ï¼‰ã€‚\nè¯·æ³¨æ„ï¼Œæˆ‘ä»¬çš„åŠç›‘ç£å­¦ä¹ åœºæ™¯æ˜¯é€šè¿‡ä»¥ä¸‹è¡Œå®ç°çš„ï¼š\nloss = criterion(out[data.train_mask], data.y[data.train_mask]) åœ¨è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„èŠ‚ç‚¹åµŒå…¥æ—¶ï¼Œæˆ‘ä»¬â€œä»…åˆ©ç”¨è®­ç»ƒèŠ‚ç‚¹æ¥è®¡ç®—lossâ€ **ã€‚ åœ¨è¿™é‡Œï¼Œè¿™æ˜¯é€šè¿‡è¿‡æ»¤åˆ†ç±»å™¨â€œ outâ€å’ŒçœŸå®æ€§æ ‡ç­¾â€œ data.yâ€çš„è¾“å‡ºä»¥ä»…åŒ…å«â€œ train_maskâ€ä¸­çš„èŠ‚ç‚¹æ¥å®ç°çš„ã€‚\nç°åœ¨è®©æˆ‘ä»¬å¼€å§‹è®­ç»ƒï¼Œçœ‹çœ‹æˆ‘ä»¬çš„èŠ‚ç‚¹åµŒå…¥éšæ—¶é—´å¦‚ä½•æ¼”å˜ï¼ˆæœ€å¥½æ˜¯æ˜¾å¼åœ°è¿è¡Œä»£ç ï¼Œæ‰“å°å‡ºæ¨¡å‹çš„è®­ç»ƒæ•ˆæœï¼‰ï¼š\nimport time from IPython.display import Javascript #ç”»å›¾. display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 430})''')) model = GCN() criterion = torch.nn.CrossEntropyLoss() # å®šä¹‰loss optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # ä¼˜åŒ–å™¨ def train(data): optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶. out, h = model(data.x, data.edge_index) # GCNæ¨¡å‹. loss = criterion(out[data.train_mask], data.y[data.train_mask]) # è®¡ç®—çœŸå®loss. loss.backward() # åå‘æ±‚å¯¼. optimizer.step() # å‚æ•°æ›´æ–°. return loss, h for epoch in range(401): loss, h = train(data) # æ¯10ä¸ªepochsæ‰“å°Graph if epoch % 10 == 0: visualize(h, color=data.y, epoch=epoch, loss=loss) time.sleep(0.3) è¿‡äº†ä¸€æ®µæ—¶é—´ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°GCNå¼ºå¤§çš„æ•ˆæœï¼š\nå¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„3å±‚GCNæ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°ç¤¾åŒºå‘ç°å¹¶æ­£ç¡®åœ°å¯¹å¤§å¤šæ•°èŠ‚ç‚¹è¿›è¡Œåˆ†ç±»ã€‚\n","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C04-graph-ml/","series":["å›¾ç¥ç»ç½‘ç»œ"],"tags":["å›¾ç¥ç»ç½‘ç»œ"],"title":"å›¾ç¥ç»ç½‘ç»œ(04)-åŸºäºGraphçš„ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•"},{"categories":["æŠ€æœ¯åšå®¢"],"content":"ç®€ä»‹ æ–°é—»åª’ä½“å·²æˆä¸ºå‘ä¸–ç•Œäººæ°‘ä¼ é€’ä¸–ç•Œä¸Šæ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…çš„ä¿¡æ¯çš„æ¸ é“ã€‚ äººä»¬é€šå¸¸è®¤ä¸ºæ–°é—»ä¸­ä¼ è¾¾çš„ä¸€åˆ‡éƒ½æ˜¯çœŸå®çš„ã€‚ åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œç”šè‡³æ–°é—»é¢‘é“ä¹Ÿæ‰¿è®¤ä»–ä»¬çš„æ–°é—»ä¸å¦‚ä»–ä»¬å†™çš„é‚£æ ·çœŸå®ã€‚ ä½†æ˜¯ï¼Œä¸€äº›æ–°é—»ä¸ä»…å¯¹äººæ°‘æˆ–æ”¿åºœäº§ç”Ÿé‡å¤§å½±å“ï¼Œè€Œä¸”å¯¹ç»æµä¹Ÿäº§ç”Ÿé‡å¤§å½±å“ã€‚ ä¸€åˆ™æ–°é—»å¯ä»¥æ ¹æ®äººä»¬çš„æƒ…ç»ªå’Œæ”¿æ²»å±€åŠ¿ä¸Šä¸‹ç§»åŠ¨æ›²çº¿ã€‚\nä»çœŸå®çš„çœŸå®æ–°é—»ä¸­è¯†åˆ«è™šå‡æ–°é—»éå¸¸é‡è¦ã€‚ è¯¥é—®é¢˜å·²é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·è§£å†³å¹¶å¾—åˆ°äº†è§£å†³ï¼Œæœ¬ç¯‡æ–‡ç« å¯å¸®åŠ©æˆ‘ä»¬æ ¹æ®å†å²æ•°æ®è¯†åˆ«å‡æ–°é—»æˆ–çœŸå®æ–°é—»ã€‚\né—®é¢˜æè¿° å¯¹äºå°åˆ·åª’ä½“å’Œæ•°å­—åª’ä½“ï¼Œä¿¡æ¯çš„çœŸå®æ€§å·²æˆä¸ºå½±å“ä¼ä¸šå’Œç¤¾ä¼šçš„é•¿æœŸé—®é¢˜ã€‚åœ¨ç¤¾äº¤ç½‘ç»œä¸Šï¼Œä¿¡æ¯ä¼ æ’­çš„èŒƒå›´å’Œå½±å“ä»¥å¦‚æ­¤å¿«çš„é€Ÿåº¦å‘ç”Ÿï¼Œå¹¶ä¸”å¦‚æ­¤è¿…é€Ÿåœ°æ”¾å¤§ï¼Œä»¥è‡³äºå¤±çœŸï¼Œä¸å‡†ç¡®æˆ–è™šå‡çš„ä¿¡æ¯å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œå¯åœ¨æ•°åˆ†é’Ÿå†…å¯¹æ•°ç™¾ä¸‡ç”¨æˆ·é€ æˆç°å®ä¸–ç•Œçš„å½±å“ã€‚æœ€è¿‘ï¼Œäººä»¬è¡¨è¾¾äº†å¯¹è¯¥é—®é¢˜çš„ä¸€äº›æ‹…å¿§ï¼Œå¹¶æå‡ºäº†ä¸€äº›ç¼“è§£è¯¥é—®é¢˜çš„æ–¹æ³•ã€‚\nåœ¨å„ç§ä¿¡æ¯å¹¿æ’­çš„æ•´ä¸ªå†å²ä¸­ï¼Œä¸€ç›´å­˜åœ¨ç€ä¸é‚£ä¹ˆç²¾ç¡®çš„å¼•äººæ³¨ç›®å’Œå¼•äººå…¥èƒœçš„æ–°é—»æ ‡é¢˜ï¼Œè¿™äº›æ–°é—»æ ‡é¢˜æ—¨åœ¨å¸å¼•è§‚ä¼—çš„æ³¨æ„åŠ›æ¥å‡ºå”®ä¿¡æ¯ã€‚ä½†æ˜¯ï¼Œåœ¨ç¤¾äº¤ç½‘ç«™ä¸Šï¼Œä¿¡æ¯ä¼ æ’­çš„èŒƒå›´å’Œå½±å“å¾—åˆ°äº†æ˜¾ç€æ”¾å¤§ï¼Œå¹¶ä¸”å‘å±•é€Ÿåº¦å¦‚æ­¤ä¹‹å¿«ï¼Œä»¥è‡³äºå¤±çœŸï¼Œä¸å‡†ç¡®æˆ–è™šå‡çš„ä¿¡æ¯å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œå¯åœ¨æ•°åˆ†é’Ÿå†…ä¸ºæ•°ç™¾ä¸‡çš„ç”¨æˆ·å¸¦æ¥çœŸæ­£çš„å½±å“ã€‚\nç›®æ ‡  æˆ‘ä»¬å”¯ä¸€çš„ç›®æ ‡æ˜¯å°†æ•°æ®é›†ä¸­çš„æ–°é—»åˆ†ç±»ä¸ºå‡æ–°é—»æˆ–çœŸå®æ–°é—»ã€‚ æ–°é—»çš„ç»†è‡´EDA é€‰æ‹©å¹¶å»ºç«‹å¼ºå¤§çš„åˆ†ç±»æ¨¡å‹  å¯¼å…¥ç›¸å…³åº“ è®©æˆ‘ä»¬å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“ä»¥è¿›è¡Œæ–‡æœ¬åˆ†æï¼Œå¹¶ä¸”å°†å¯¹æ•°æ®é›†è¿›è¡Œæ¸…æ´—ã€‚\n# åŸºæœ¬æ•°æ®åŒ…ï¼špandaså’Œnumpy import pandas as pd import numpy as np # å¯è§†åŒ–åŒ… import matplotlib.pyplot as plt from matplotlib import rcParams import seaborn as sns from textblob import TextBlob from plotly import tools import plotly.graph_objs as go from plotly.offline import iplot %matplotlib inline plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = [10, 5] import cufflinks as cf cf.go_offline() cf.set_config_file(offline=False, world_readable=True) # NLTK åŒ… import nltk import re import string from nltk.corpus import stopwords from wordcloud import WordCloud,STOPWORDS from nltk.stem.porter import PorterStemmer from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.feature_extraction.text import CountVectorizer # Machine Learning libraries import sklearn from sklearn.model_selection import GridSearchCV from sklearn.linear_model import LogisticRegression from sklearn.tree import DecisionTreeClassifier from sklearn.naive_bayes import MultinomialNB from sklearn.neighbors import KNeighborsClassifier from sklearn.model_selection import train_test_split # è¯„ä¼° from sklearn import metrics from sklearn.metrics import classification_report from sklearn.model_selection import cross_val_score from sklearn.metrics import roc_auc_score from sklearn.metrics import roc_curve from sklearn.metrics import confusion_matrix from sklearn.metrics import accuracy_score # é›†åˆ from collections import Counter # å¿½ç•¥è­¦å‘Š import warnings warnings.filterwarnings(\u0026#39;ignore\u0026#39;) # æ·±åº¦å­¦ä¹  from tensorflow.keras.layers import Embedding from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.models import Sequential from tensorflow.keras.preprocessing.text import one_hot from tensorflow.keras.layers import LSTM from tensorflow.keras.layers import Bidirectional from tensorflow.keras.layers import Dense from tensorflow.keras.layers import Dropout åŠ è½½æ•°æ® æ•°æ®ä¸‹è½½é“¾æ¥ï¼šæ·»åŠ é“¾æ¥æè¿° # è¯»å–æ•°æ®é›† fake_news = pd.read_csv(\u0026#39;data/Fake.csv\u0026#39;) true_news = pd.read_csv(\u0026#39;data/True.csv\u0026#39;) # è™šå‡æ–°é—»æ•°æ®é›†çš„å¤§å°ä»¥åŠå­—æ®µ print (\u0026#34;The shape of the data is (row, column):\u0026#34;+ str(fake_news.shape)) print (fake_news.info()) print(\u0026#34;\\n--------------------------------------- \\n\u0026#34;) # çœŸå®æ–°é—»æ•°æ®é›†çš„å¤§å°ä»¥åŠå­—æ®µ print (\u0026#34;The shape of the data is (row, column):\u0026#34;+ str(true_news.shape)) print (true_news.info()) æ•°æ®é›†çš„è¯¦æƒ… æ•°æ®æœ‰2ä¸ªCSVæ–‡ä»¶ï¼Œå…¶ä¸­ä¸€ä¸ªæ•°æ®é›†åŒ…å«å‡æ–°é—»ï¼Œå¦ä¸€ä¸ªåŒ…çœŸæ–°é—»ï¼Œæœ‰å°†è¿‘23481ä¸ªå‡æ–°é—»å’Œ21417ä¸ªçœŸæ–°é—»ã€‚ æ–‡ä»¶ä¸­åˆ—åçš„æè¿°:\n title-åŒ…å«æ–°é—»æ ‡é¢˜ text-åŒ…å«æ–°é—»å†…å®¹/æ–‡ç«  subject-æ–°é—»çš„ä¸»é¢˜ date-æ¶ˆæ¯å‘å¸ƒçš„æ—¥æœŸ  æ•°æ®é¢„å¤„ç†ä¸æ–‡æœ¬æ¸…æ´— åœ¨æ‰§è¡ŒEDAå¹¶å°†æ•°æ®æä¾›ç»™æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»æ‰§è¡ŒæŸäº›é¢„å¤„ç†æ­¥éª¤ï¼š\nåˆ›å»ºç›®æ ‡åˆ— è®©æˆ‘ä»¬ä¸ºå‡æ–°é—»å’ŒçœŸæ–°é—»åˆ›å»ºç›®æ ‡åˆ—ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ç›®æ ‡å€¼è¡¨ç¤ºä¸ºâ€œ 0â€ï¼ˆå‡æ–°é—»ï¼‰ï¼Œâ€œ 1â€ï¼ˆçœŸæ–°é—»ï¼‰ã€‚\n#å‡æ–°é—»çš„ç›®æ ‡å˜é‡ fake_news[\u0026#39;output\u0026#39;]=0 #çœŸæ–°é—»çš„ç›®æ ‡å˜é‡ true_news[\u0026#39;output\u0026#39;]=1 æ‹¼æ¥æ–°é—»æ ‡é¢˜å’Œå†…å®¹ æ–°é—»æ˜¯å°†æ ¹æ®æ ‡é¢˜å’Œæ–‡æœ¬è¿›è¡Œåˆ†ç±»ã€‚ åˆ†å¼€å¤„ç†æ–°é—»æ ‡é¢˜å’Œå†…å®¹ä¸ä¼šå¸¦æ¥ä»»ä½•å¥½å¤„ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å°†ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„ä¸¤ä¸ªåˆ—è¿æ¥èµ·æ¥ã€‚\n#åˆå¹¶titleä¸textåˆå¹¶ä¸ºnews fake_news[\u0026#39;news\u0026#39;]=fake_news[\u0026#39;title\u0026#39;]+fake_news[\u0026#39;text\u0026#39;] fake_news=fake_news.drop([\u0026#39;title\u0026#39;, \u0026#39;text\u0026#39;], axis=1) #åˆå¹¶titleä¸textåˆå¹¶ä¸ºnews true_news[\u0026#39;news\u0026#39;]=true_news[\u0026#39;title\u0026#39;]+true_news[\u0026#39;text\u0026#39;] true_news=true_news.drop([\u0026#39;title\u0026#39;, \u0026#39;text\u0026#39;], axis=1) # é‡æ„è¡¨æ ¼ fake_news = fake_news[[\u0026#39;subject\u0026#39;, \u0026#39;date\u0026#39;, \u0026#39;news\u0026#39;,\u0026#39;output\u0026#39;]] true_news = true_news[[\u0026#39;subject\u0026#39;, \u0026#39;date\u0026#39;, \u0026#39;news\u0026#39;,\u0026#39;output\u0026#39;]] å°†æ—¥æœŸåˆ—è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´æ ¼å¼ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨pd.datetimeå°†æ—¥æœŸåˆ—è½¬æ¢ä¸ºæ‰€éœ€çš„æ—¥æœŸæ ¼å¼ã€‚å°¤å…¶æ˜¯åœ¨fake_news dateåˆ—ä¸­ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥value_countsï¼ˆï¼‰çœ‹çœ‹é‡Œé¢æœ‰ä»€ä¹ˆã€‚\nffake_news[\u0026#39;date\u0026#39;].value_counts() Out[7]: May 10, 2017 46 May 26, 2016 44 May 5, 2016 44 May 6, 2016 44 May 11, 2016 43 .. November 20, 2017 1 Jun 21, 2015 1 December 11, 2017 1 Apr 2, 2015 1 Jul 19, 2015 1 Name: date, Length: 1681, dtype: int64 å¦‚æœæ‚¨æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬åœ¨æ—¥æœŸåˆ—å†…æœ‰é“¾æ¥å’Œæ–°é—»æ ‡é¢˜ï¼Œè¿™åœ¨è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´æ ¼å¼æ—¶ä¼šç»™æˆ‘ä»¬å¸¦æ¥éº»çƒ¦ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬ä»åˆ—ä¸­åˆ é™¤è¿™äº›è®°å½•ã€‚\n# åˆ é™¤å«æœ‰é“¾æ¥ä»¥åŠHostçš„æ•°æ®  fake_news=fake_news[~fake_news.date.str.contains(\u0026#34;http\u0026#34;)] fake_news=fake_news[~fake_news.date.str.contains(\u0026#34;HOST\u0026#34;)] # \u0026#39;\u0026#39;\u0026#39;ç­‰æ•ˆ\u0026#39;\u0026#39;\u0026#39; #fake_news=fake_news[fake_news.date.str.contains(\u0026#34;Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec\u0026#34;)] åªæœ‰å‡æ–°é—»æ•°æ®é›†çš„æ—¥æœŸåˆ—å­˜åœ¨é—®é¢˜ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ—¥æœŸåˆ—è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´æ ¼å¼ In [10]: # å°†æ—¥æœŸåˆ—è½¬ä¸ºæ—¶é—´æ ¼å¼ fake_news[\u0026#39;date\u0026#39;] = pd.to_datetime(fake_news[\u0026#39;date\u0026#39;]) true_news[\u0026#39;date\u0026#39;] = pd.to_datetime(true_news[\u0026#39;date\u0026#39;]) åˆå¹¶æ•°æ®é›† å½“æˆ‘ä»¬ä¸ºæ¨¡å‹æä¾›æ•°æ®é›†æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å°†å…¶ä½œä¸ºå•ä¸ªæ–‡ä»¶æä¾›ã€‚å› æ­¤ï¼Œæœ€å¥½åŒæ—¶æ·»åŠ çœŸå‡æ–°é—»æ•°æ®ï¼Œå¹¶å¯¹å…¶è¿›è¡Œè¿›ä¸€æ­¥é¢„å¤„ç†å¹¶æ‰§è¡ŒEDAã€‚\nframes = [fake_news, true_news] news_dataset = pd.concat(frames) news_dataset Out[11]: subject\tdate\tnews\toutput 0\tNews\t2017-12-31\tDonald Trump Sends Out Embarrassing New Yearâ€™...\t0 1\tNews\t2017-12-31\tDrunk Bragging Trump Staffer Started Russian ...\t0 2\tNews\t2017-12-30\tSheriff David Clarke Becomes An Internet Joke...\t0 3\tNews\t2017-12-29\tTrump Is So Obsessed He Even Has Obamaâ€™s Name...\t0 4\tNews\t2017-12-25\tPope Francis Just Called Out Donald Trump Dur...\t0 ...\t...\t...\t...\t... 21412\tworldnews\t2017-08-22\t\u0026#39;Fully committed\u0026#39; NATO backs new U.S. approach...\t1 21413\tworldnews\t2017-08-22\tLexisNexis withdrew two products from Chinese ...\t1 21414\tworldnews\t2017-08-22\tMinsk cultural hub becomes haven from authorit...\t1 21415\tworldnews\t2017-08-22\tVatican upbeat on possibility of Pope Francis ...\t1 21416\tworldnews\t2017-08-22\tIndonesia to buy $1.14 billion worth of Russia...\t1 44888 rows Ã— 4 columns æ–‡æœ¬å¤„ç† å¯¹äºä»»ä½•æ–‡æœ¬åˆ†æåº”ç”¨ç¨‹åºæ¥è¯´ï¼Œè¿™éƒ½æ˜¯é‡è¦çš„é˜¶æ®µã€‚ æ–°é—»ä¸­å°†æœ‰å¾ˆå¤šæ— ç”¨çš„å†…å®¹ï¼Œè¿™å¯èƒ½ä¼šé˜»ç¢æœºå™¨å­¦ä¹ æ¨¡å‹çš„å‘å±•ã€‚ é™¤éæˆ‘ä»¬åˆ é™¤å®ƒä»¬ï¼Œå¦åˆ™æœºå™¨å­¦ä¹ æ¨¡å‹å°†æ— æ³•æœ‰æ•ˆè¿è¡Œã€‚ è®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥èµ°ã€‚\næ ‡ç‚¹ç¬¦å·å»é™¤ clean_news=news_dataset.copy() def review_cleaning(text): \u0026#39;\u0026#39;\u0026#39;Make text lowercase, remove text in square brackets,remove links,remove punctuation and remove words containing numbers.\u0026#39;\u0026#39;\u0026#39; text = str(text).lower() text = re.sub(\u0026#39;\\[.*?\\]\u0026#39;, \u0026#39;\u0026#39;, text) text = re.sub(\u0026#39;https?://\\S+|www\\.\\S+\u0026#39;, \u0026#39;\u0026#39;, text) text = re.sub(\u0026#39;\u0026lt;.*?\u0026gt;+\u0026#39;, \u0026#39;\u0026#39;, text) text = re.sub(\u0026#39;[%s]\u0026#39; % re.escape(string.punctuation), \u0026#39;\u0026#39;, text) text = re.sub(\u0026#39;\\n\u0026#39;, \u0026#39;\u0026#39;, text) text = re.sub(\u0026#39;\\w*\\d\\w*\u0026#39;, \u0026#39;\u0026#39;, text) return text clean_news[\u0026#39;news\u0026#39;]=clean_news[\u0026#39;news\u0026#39;].apply(lambda x:review_cleaning(x)) clean_news.head() Out[13]: subject\tdate\tnews\toutput 0\tNews\t2017-12-31\tdonald trump sends out embarrassing new yearâ€™...\t0 1\tNews\t2017-12-31\tdrunk bragging trump staffer started russian ...\t0 2\tNews\t2017-12-30\tsheriff david clarke becomes an internet joke...\t0 3\tNews\t2017-12-29\ttrump is so obsessed he even has obamaâ€™s name...\t0 4\tNews\t2017-12-25\tpope francis just called out donald trump dur...\t0 åœç”¨è¯å»é™¤ åœæ­¢è¯æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„è¯(ä¾‹å¦‚â€œtheâ€ï¼Œâ€œAâ€ï¼Œâ€œanâ€ï¼Œâ€œinâ€)ï¼Œæœç´¢å¼•æ“åœ¨ä¸ºæœç´¢æ¡ç›®å»ºç«‹ç´¢å¼•å’Œä½œä¸ºæœç´¢æŸ¥è¯¢çš„ç»“æœæ£€ç´¢å®ƒä»¬æ—¶éƒ½å¿½ç•¥å®ƒã€‚æˆ‘ä»¬ä¸å¸Œæœ›è¿™äº›è¯å ç”¨æ•°æ®åº“ä¸­çš„ç©ºé—´ï¼Œæˆ–å ç”¨å®è´µçš„å¤„ç†æ—¶é—´ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°åˆ é™¤å®ƒä»¬ï¼Œæ–¹æ³•æ˜¯å­˜å‚¨ä¸€ç»„ä½ è®¤ä¸ºå¯ä»¥ç»ˆæ­¢å•è¯çš„å•è¯ã€‚pythonä¸­çš„NLTK(è‡ªç„¶è¯­è¨€å·¥å…·åŒ…)æœ‰ä¸€ä¸ªä»¥16ç§ä¸åŒè¯­è¨€å­˜å‚¨çš„stopwordsåˆ—è¡¨ã€‚\nimport nltk nltk.download(\u0026#39;stopwords\u0026#39;) [nltk_data] Downloading package stopwords to [nltk_data] C:\\Users\\yanqiang\\AppData\\Roaming\\nltk_data... [nltk_data] Unzipping corpora\\stopwords.zip. Out[15]: True In [16]: stop = stopwords.words(\u0026#39;english\u0026#39;) clean_news[\u0026#39;news\u0026#39;] = clean_news[\u0026#39;news\u0026#39;].apply(lambda x: \u0026#39; \u0026#39;.join([word for word in x.split() if word not in (stop)])) clean_news.head() Out[16]: subject\tdate\tnews\toutput 0\tNews\t2017-12-31\tdonald trump sends embarrassing new yearâ€™s eve...\t0 1\tNews\t2017-12-31\tdrunk bragging trump staffer started russian c...\t0 2\tNews\t2017-12-30\tsheriff david clarke becomes internet joke thr...\t0 3\tNews\t2017-12-29\ttrump obsessed even obamaâ€™s name coded website...\t0 4\tNews\t2017-12-25\tpope francis called donald trump christmas spe...\t0 æ–°é—»çš„äº‹ä»¶æ¼”å˜å’Œå¯è§†åŒ– åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å®Œæˆå¯¹æ–°é—»çš„æ¢ç´¢æ€§æ•°æ®åˆ†æï¼Œä¾‹å¦‚ngramåˆ†æï¼Œå¹¶äº†è§£å“ªäº›æ˜¯æ‰€æœ‰å•è¯ï¼Œä¸Šä¸‹æ–‡ï¼ˆæœ€æœ‰å¯èƒ½åœ¨ä¼ªé€ çš„newä¸­æ‰¾åˆ°ï¼‰ã€‚\næ–°é—»ä¸»é¢˜æ•° ax = sns.countplot(x=\u0026#34;subject\u0026#34;, data=clean_news, facecolor=(0, 0, 0, 0), linewidth=5, edgecolor=sns.color_palette(\u0026#34;dark\u0026#34;, 3)) # è®¾ç½®labelä¸å­—ä½“å¤§å° ax.set(xlabel=\u0026#39;Type of news\u0026#39;, ylabel=\u0026#39;Number of news\u0026#39;,title=\u0026#39;Count of news type\u0026#39;) ax.xaxis.get_label().set_fontsize(15) ax.yaxis.get_label().set_fontsize(15) åŸºäºçœŸå‡çš„æ–°é—»ä¸»é¢˜è®¡æ•° g = sns.catplot(x=\u0026#34;subject\u0026#34;, col=\u0026#34;output\u0026#34;, data=clean_news, kind=\u0026#34;count\u0026#34;, height=4, aspect=2) # æ—‹è½¬xè½´ g.set_xticklabels(rotation=45) Out[22]: \u0026lt;seaborn.axisgrid.FacetGrid at 0x2308e99f608\u0026gt; å‘ç°ï¼š\n å‡æ–°é—»æ— å¤„ä¸åœ¨ï¼Œæ”¿æ²»å’Œä¸–ç•Œæ–°é—»é™¤å¤– çœŸæ­£çš„æ–°é—»åªå­˜åœ¨äºæ”¿æ²»å’Œä¸–ç•Œæ–°é—»ä¸­ï¼Œè€Œä¸”æ•°é‡å¾ˆé«˜ è¿™æ˜¯ä¸€ä¸ªé«˜åº¦åå·®çš„æ•°æ®é›†ï¼Œè€ƒè™‘åˆ°æ•°æ®é›†çš„è´¨é‡è¾ƒå·®ï¼Œæˆ‘ä»¬å¯ä»¥æœŸæœ›æ›´é«˜çš„å‡†ç¡®æ€§ï¼Œä½†è¿™å¹¶ä¸æ„å‘³ç€å®ƒæ˜¯ä¸€ä¸ªå¥½çš„æ¨¡å‹  çœŸå‡æ–°é—»ç»Ÿè®¡ ax=sns.countplot(x=\u0026#34;output\u0026#34;, data=clean_news) # è®¾ç½®labelä»¥åŠå­—ä½“å¤§å° ax.set(xlabel=\u0026#39;Output\u0026#39;, ylabel=\u0026#39;Count of fake/true\u0026#39;,title=\u0026#39;Count of fake and true news\u0026#39;) ax.xaxis.get_label().set_fontsize(15) ax.yaxis.get_label().set_fontsize(15) å‘ç°ï¼š\n æˆ‘ä»¬æœ‰ä¸€ä¸ªéå¸¸å¹³è¡¡çš„æ•°æ® ä½†æ˜¯ï¼Œå‡æ–°é—»çš„æ•°é‡è¦æ¯”çœŸå®æ–°é—»çš„æ•°é‡é«˜ï¼Œä½†ç¨‹åº¦ä¸å¤§  ä»æ–°é—»ä¸­æå–æ–°ç‰¹å¾ è®©æˆ‘ä»¬ä»æ–°é—»ç‰¹å¾ä¸­æå–æ›´å¤šçš„ç‰¹å¾ï¼Œæ¯”å¦‚\n ææ€§:è¡¨ç¤ºæ–°é—»æƒ…æ„Ÿçš„å°ºåº¦ è¯„è®ºé•¿åº¦:æ–°é—»çš„é•¿åº¦(å­—æ¯å’Œç©ºæ ¼çš„æ•°é‡) å•è¯æ•°:æ–°é—»ä¸­å•è¯çš„æ•°é‡  # ä»æ–°é—»ä¸­æå–æ–°ç‰¹å¾ clean_news[\u0026#39;polarity\u0026#39;] = clean_news[\u0026#39;news\u0026#39;].map(lambda text: TextBlob(text).sentiment.polarity) clean_news[\u0026#39;review_len\u0026#39;] = clean_news[\u0026#39;news\u0026#39;].astype(str).apply(len) clean_news[\u0026#39;word_count\u0026#39;] = clean_news[\u0026#39;news\u0026#39;].apply(lambda x: len(str(x).split())) # æ–°ç‰¹å¾åˆ†å¸ƒ plt.figure(figsize = (20, 5)) plt.style.use(\u0026#39;seaborn-white\u0026#39;) plt.subplot(131) sns.distplot(clean_news[\u0026#39;polarity\u0026#39;]) fig = plt.gcf() plt.subplot(132) sns.distplot(clean_news[\u0026#39;review_len\u0026#39;]) fig = plt.gcf() plt.subplot(133) sns.distplot(clean_news[\u0026#39;word_count\u0026#39;]) fig = plt.gcf() å‘ç°ï¼š\n å¤§éƒ¨åˆ†ææ€§æ˜¯ä¸­æ€§çš„ï¼Œæ—¢ä¸è¡¨ç¤ºåæ¶ˆæ¯ä¹Ÿä¸è¡¨ç¤ºé«˜å…´æ¶ˆæ¯ã€‚ å­—æ•°åœ¨0åˆ°1000ä¹‹é—´ï¼Œæ–°é—»çš„é•¿åº¦åœ¨0åˆ°5000ä¹‹é—´ï¼Œå¹¶ä¸”æ¥è¿‘1000ä¸ªå•è¯ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ç¯‡æ–‡ç« ã€‚  N-gramåˆ†æ æ–°é—»ä¸­çš„å‰20ä¸ªè¯ è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹æ–°é—»ä¸­çš„å‰20ä¸ªè¯ï¼Œè¿™å¯ä»¥è®©æˆ‘ä»¬ç®€è¦äº†è§£ä¸€ä¸‹æ•°æ®é›†ä¸­æœ€å—æ¬¢è¿çš„æ–°é—»ã€‚\n# è·å–topnçš„è¯ def get_top_n_words(corpus, n=None): vec = CountVectorizer().fit(corpus) bag_of_words = vec.transform(corpus) sum_words = bag_of_words.sum(axis=0) words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()] words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True) return words_freq[:n] # è·å–top20å¸¸è§çš„è¯ common_words = get_top_n_words(clean_news[\u0026#39;news\u0026#39;], 20) # æ‰“å°è¯é¢‘ for word, freq in common_words: print(word, freq) # åˆ›å»ºè¯ä¸è¯é¢‘çš„dataframe df1 = pd.DataFrame(common_words, columns = [\u0026#39;news\u0026#39; , \u0026#39;count\u0026#39;]) df1.groupby(\u0026#39;news\u0026#39;).sum()[\u0026#39;count\u0026#39;].sort_values(ascending=False).iplot( kind=\u0026#39;bar\u0026#39;, yTitle=\u0026#39;Count\u0026#39;, linecolor=\u0026#39;black\u0026#39;, title=\u0026#39;Top 20 words in news\u0026#39;) trump 140400 said 130258 us 68081 would 55422 president 53189 people 41718 one 36146 state 33190 new 31799 also 31209 obama 29881 clinton 29003 house 28716 government 27392 donald 27376 reuters 27348 states 26331 republican 25287 could 24356 white 23823 å‘ç°ï¼š\n æ‰€æœ‰å‰20æ¡æ–°é—»éƒ½ä¸ç¾å›½æ”¿åºœæœ‰å…³ ç‰¹åˆ«æ˜¯å…³äºç‰¹æœ—æ™®å’Œç¾å›½ï¼Œå…¶æ¬¡æ˜¯å¥¥å·´é©¬ æˆ‘ä»¬å¯ä»¥äº†è§£åˆ°ï¼Œæ–°é—»æ¥è‡ªè·¯é€ç¤¾ã€‚  æ–°é—»ä¸­çš„topnçš„2ä¸ªè¯ç»„åˆ ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†æ¢ç´¢èŒƒå›´æ‰©å±•åˆ°æ–°é—»ä¸­çš„æœ€å¸¸è§çš„2ä¸ªè¯ç»„åˆã€‚\ndef get_top_n_bigram(corpus, n=None): vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus) bag_of_words = vec.transform(corpus) sum_words = bag_of_words.sum(axis=0) words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()] words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True) return words_freq[:n] common_words = get_top_n_bigram(clean_news[\u0026#39;news\u0026#39;], 20) for word, freq in common_words: print(word, freq) df3 = pd.DataFrame(common_words, columns = [\u0026#39;news\u0026#39; , \u0026#39;count\u0026#39;]) df3.groupby(\u0026#39;news\u0026#39;).sum()[\u0026#39;count\u0026#39;].sort_values(ascending=False).iplot( kind=\u0026#39;bar\u0026#39;, yTitle=\u0026#39;Count\u0026#39;, linecolor=\u0026#39;black\u0026#39;, title=\u0026#39;Top 20 bigrams in news\u0026#39;) donald trump 25059 united states 18394 white house 15485 hillary clinton 9502 new york 8110 north korea 7053 president donald 6928 image via 6188 barack obama 5603 trump said 4816 prime minister 4753 president trump 4646 supreme court 4595 last year 4560 last week 4512 said statement 4425 fox news 4074 president obama 4065 islamic state 4014 national security 3858 å‘ç°ï¼š\n å¦‚æˆ‘ä»¬æ‰€æ‹…å¿ƒçš„é‚£æ ·ï¼Œè€ƒè™‘åˆ°ç‹ç‰Œæ–°é—»çš„æ•°é‡ï¼Œæˆ‘è®¤ä¸ºè¯¥æ¨¡å‹çš„ç»“æœä¼šæœ‰åå·® æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹åˆ°æœé²œçš„æ–°é—»ï¼Œæˆ‘æƒ³è¿™å°†æ˜¯å…³äºç¾å›½å’ŒNKä¹‹é—´çš„äº‰ç«¯ fox æ–°é—»ä¹Ÿå¾ˆå°‘æœ‰æ–°é—»  def get_top_n_trigram(corpus, n=None): vec = CountVectorizer(ngram_range=(3, 3), stop_words=\u0026#39;english\u0026#39;).fit(corpus) bag_of_words = vec.transform(corpus) sum_words = bag_of_words.sum(axis=0) words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()] words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True) return words_freq[:n] common_words = get_top_n_trigram(clean_news[\u0026#39;news\u0026#39;], 20) for word, freq in common_words: print(word, freq) df6 = pd.DataFrame(common_words, columns = [\u0026#39;news\u0026#39; , \u0026#39;count\u0026#39;]) df6.groupby(\u0026#39;news\u0026#39;).sum()[\u0026#39;count\u0026#39;].sort_values(ascending=False).iplot( kind=\u0026#39;bar\u0026#39;, yTitle=\u0026#39;Count\u0026#39;, linecolor=\u0026#39;black\u0026#39;, title=\u0026#39;Top 20 trigrams in news\u0026#39;) president donald trump 6808 president barack obama 3735 new york times 2034 donald trump realdonaldtrump 1790 reuters president donald 1476 black lives matter 1436 president united states 1096 white house said 1050 presidentelect donald trump 1043 new york city 1006 president vladimir putin 955 news century wire 951 national security adviser 898 affordable care act 868 director james comey 860 speaker paul ryan 851 fbi director james 778 state rex tillerson 775 secretary state rex 765 russian president vladimir 745 å‘ç°ï¼š\n åœ¨å¼—æ´›ä¼Šå¾·ï¼ˆFloydï¼‰æ­»åï¼Œæœ‰ä¸€ä¸ªé‡è¦çš„æ–°é—»è£å®šç¾å›½åª’ä½“çš„â€œé»‘äººç”Ÿå‘½é—®é¢˜â€ã€‚ æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ–°é—»å·²ç»è¦†ç›–äº†æˆ‘ä»¬çš„æ•°æ®ã€‚ å…³äºæ­»äº¡çš„å‡æ–°é—»å¾ˆå¤šã€‚ å…¶ä½™æ–°é—»éƒ½ä¸ç¾å›½æ”¿æ²»æœ‰å…³  è™šå‡å’ŒçœŸå®æ–°é—»è¯äº‘ è™šå‡å’ŒçœŸå®æ–°é—»è¯äº‘ è®©æˆ‘ä»¬çœ‹çœ‹å‡æ–°é—»å’ŒçœŸå®æ–°é—»è¿™ä¸¤ä¸ªè¯äº‘.\ntext = fake_news[\u0026#34;news\u0026#34;] wordcloud = WordCloud( width = 3000, height = 2000, background_color = \u0026#39;black\u0026#39;, stopwords = STOPWORDS).generate(str(text)) fig = plt.figure( figsize = (40, 30), facecolor = \u0026#39;k\u0026#39;, edgecolor = \u0026#39;k\u0026#39;) plt.imshow(wordcloud, interpolation = \u0026#39;bilinear\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout(pad=0) plt.show() å‘ç°\n å¤§å¤šæ•°è™šå‡æ–°é—»éƒ½å›´ç»•å”çº³å¾·Â·ç‰¹æœ—æ™®å’Œç¾å›½ è¿˜æœ‰å…³äºéšç§ï¼Œäº’è”ç½‘ç­‰çš„è™šå‡æ–°é—»  text = true_news[\u0026#34;news\u0026#34;] wordcloud = WordCloud( width = 3000, height = 2000, background_color = \u0026#39;black\u0026#39;, stopwords = STOPWORDS).generate(str(text)) fig = plt.figure( figsize = (40, 30), facecolor = \u0026#39;k\u0026#39;, edgecolor = \u0026#39;k\u0026#39;) plt.imshow(wordcloud, interpolation = \u0026#39;bilinear\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout(pad=0) plt.show() å‘ç°ï¼š\n çœŸæ­£çš„æ–°é—»å¯¹å…±å’Œå…šå’Œä¿„ç½—æ–¯å¹¶æ²¡æœ‰å¤šå¤§çš„å¸®åŠ© æœ‰å…³äºé¢„ç®—æ¡ˆçš„æ¶ˆæ¯ï¼Œå†›äº‹æ¶ˆæ¯ä¹Ÿå—åˆ°æ”¿åºœçš„æ¶ˆæ¯æŠ¥é“  æ—¶é—´åºåˆ—åˆ†æ-è™šå‡/çœŸå®æ–°é—» è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹åœ¨åª’ä½“ä¸Šä¼ æ’­çš„çœŸå‡æ–°é—»çš„æ—¶é—´è¡¨ã€‚\n# åˆ›å»ºæ—¶é—´çš„æ•°é‡ç»Ÿè®¡ fake=fake_news.groupby([\u0026#39;date\u0026#39;])[\u0026#39;output\u0026#39;].count() fake=pd.DataFrame(fake) true=true_news.groupby([\u0026#39;date\u0026#39;])[\u0026#39;output\u0026#39;].count() true=pd.DataFrame(true) #Plotting the time series graph fig = go.Figure() fig.add_trace(go.Scatter( x=true.index, y=true[\u0026#39;output\u0026#39;], name=\u0026#39;True\u0026#39;, line=dict(color=\u0026#39;blue\u0026#39;), opacity=0.8)) fig.add_trace(go.Scatter( x=fake.index, y=fake[\u0026#39;output\u0026#39;], name=\u0026#39;Fake\u0026#39;, line=dict(color=\u0026#39;red\u0026#39;), opacity=0.8)) fig.update_xaxes( rangeslider_visible=True, rangeselector=dict( buttons=list([ dict(count=1, label=\u0026#34;1m\u0026#34;, step=\u0026#34;month\u0026#34;, stepmode=\u0026#34;backward\u0026#34;), dict(count=6, label=\u0026#34;6m\u0026#34;, step=\u0026#34;month\u0026#34;, stepmode=\u0026#34;backward\u0026#34;), dict(count=1, label=\u0026#34;YTD\u0026#34;, step=\u0026#34;year\u0026#34;, stepmode=\u0026#34;todate\u0026#34;), dict(count=1, label=\u0026#34;1y\u0026#34;, step=\u0026#34;year\u0026#34;, stepmode=\u0026#34;backward\u0026#34;), dict(step=\u0026#34;all\u0026#34;) ]) ) ) fig.update_layout(title_text=\u0026#39;True and Fake News\u0026#39;,plot_bgcolor=\u0026#39;rgb(248, 248, 255)\u0026#39;,yaxis_title=\u0026#39;Value\u0026#39;) fig.show() å‘ç°ï¼š\n è‡ª2017å¹´8æœˆä»¥æ¥ï¼ŒçœŸæ­£çš„æ–°é—»å°±å æ®äº†ä¸»å¯¼åœ°ä½ã€‚å› ä¸ºå®ƒä»¬çš„å‡ºç°ç‡å¾ˆé«˜ã€‚è¿™æ˜¯ä¸€ä¸ªå¥½å…†å¤´ çœŸå®æ¶ˆæ¯ä¸­çš„å¼‚å¸¸å€¼é«˜äºè™šå‡æ¶ˆæ¯çš„å¼‚å¸¸å€¼å¾ˆå°‘ï¼ˆ2016å¹´11æœˆ9æ—¥å’Œ2017å¹´4æœˆ7æ—¥ï¼‰ æˆ‘ä»¬çš„æ•°æ®é›†åŒ…å«çš„å‡æ–°é—»æ¯”çœŸå®æ–°é—»å¤šï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æ²¡æœ‰æ•´ä¸ª2015å¹´çš„çœŸå®æ–°é—»æ•°æ®ï¼Œå› æ­¤ï¼Œå‡æ–°é—»åˆ†ç±»å°†æ¯”å¯¹çœŸå®æ–°é—»è¿›è¡Œåˆ†ç±»æ›´ä¸ºå‡†ç¡®  Stemming \u0026amp; Vectorizing è¯å¹²åŒ–æ–°é—»\nè¯å¹²æå–æ˜¯ä»å˜å½¢è¯ä¸­å¾—å‡ºè¯æ ¹çš„ä¸€ç§æ–¹æ³•ã€‚ åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå–è¯„è®ºå¹¶å°†è¯„è®ºä¸­çš„å•è¯è½¬æ¢ä¸ºå…¶æ ¹è¯ã€‚ ä¾‹å¦‚ï¼Œ\n Going-\u0026gt;go Finally-\u0026gt;fina å¦‚æœæ‚¨æ³¨æ„åˆ°ï¼Œåˆ™è¯æ ¹æ— éœ€å¸¦æœ‰è¯­ä¹‰ã€‚ è¿˜æœ‰å¦ä¸€ç§ç§°ä¸ºâ€œè¯æ³•åŒ–â€çš„æŠ€æœ¯ï¼Œå®ƒå¯ä»¥å°†å•è¯è½¬æ¢ä¸ºå…·æœ‰è¯­ä¹‰å«ä¹‰çš„è¯æ ¹ã€‚  news_features=clean_news.copy() news_features=news_features[[\u0026#39;news\u0026#39;]].reset_index(drop=True) news_features.head() Out[31]: news 0\tdonald trump sends embarrassing new yearâ€™s eve... 1\tdrunk bragging trump staffer started russian c... 2\tsheriff david clarke becomes internet joke thr... 3\ttrump obsessed even obamaâ€™s name coded website... 4\tpope francis called donald trump christmas spe... In [32]: stop_words = set(stopwords.words(\u0026#34;english\u0026#34;)) # è¯å¹²åŒ– ps = PorterStemmer() # åˆ†è¯ç„¶åè¯å¹²åŒ– corpus = [] for i in range(0, len(news_features)): news = re.sub(\u0026#39;[^a-zA-Z]\u0026#39;, \u0026#39; \u0026#39;, news_features[\u0026#39;news\u0026#39;][i]) news= news.lower() news = news.split() news = [ps.stem(word) for word in news if not word in stop_words] news = \u0026#39; \u0026#39;.join(news) corpus.append(news) In [33]: corpus[1] Out[33]: \u0026#39;drunk brag trump staffer start russian collus investigationhous intellig committe chairman devin nune go bad day assumpt like mani us christoph steeledossi prompt russia investig lash depart justic fbi order protect trump happen dossier start investig accord document obtain new york timesform trump campaign advis georg papadopoulo drunk wine bar reveal knowledg russian opposit research hillari clintonon top papadopoulo covfef boy trump administr alleg much larger role none damn drunken fool wine bar coffe boy help arrang new york meet trump presid abdel fattah elsisi egypt two month elect known former aid set meet world leader trump team trump ran mere coffe boyin may papadopoulo reveal australian diplomat alexand downer russian offici shop around possibl dirt thendemocrat presidenti nomine hillari clinton exactli much mr papadopoulo said night kensington wine room australian alexand downer unclear report state two month later leak democrat email began appear onlin australian offici pass inform mr papadopoulo american counterpart accord four current former american foreign offici direct knowledg australian role papadopoulo plead guilti lie fbi cooper wit special counsel robert mueller teamthi presid badli script realiti tv showphoto win mcnameegetti imag\u0026#39; è¿™æ˜¯ç°åœ¨çš„æ ·å­ï¼Œå› ä¸ºè®¡ç®—æœºæ— æ³•ç†è§£å•è¯åŠå…¶è¯ä¹‰ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›å•è¯è½¬æ¢ä¸º1å’Œ0ã€‚ä¸ºäº†å¯¹å…¶è¿›è¡Œç¼–ç ï¼Œæˆ‘ä»¬ä½¿ç”¨TFIDFã€‚\nTFIDF(Term Frequency â€” Inverse Document Frequency) TF-IDFä»£è¡¨â€œè¯è¯­é¢‘ç‡-åå‘æ–‡æ¡£é¢‘ç‡â€ã€‚ è¿™æ˜¯ä¸€ç§é‡åŒ–æ–‡æ¡£ä¸­å•è¯çš„æŠ€æœ¯ï¼Œæˆ‘ä»¬é€šå¸¸è®¡ç®—æ¯ä¸ªå•è¯çš„æƒé‡ï¼Œè¡¨ç¤ºè¯¥å•è¯åœ¨æ–‡æ¡£å’Œè¯­æ–™åº“ä¸­çš„é‡è¦æ€§ã€‚ æ­¤æ–¹æ³•æ˜¯ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬æŒ–æ˜ä¸­å¹¿æ³›ä½¿ç”¨çš„æŠ€æœ¯ã€‚\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†bigramï¼ˆä¸¤ä¸ªå•è¯ï¼‰åˆ†å¼€å¹¶è€ƒè™‘å®ƒä»¬çš„æ€»æƒé‡ï¼Œè€Œä¸”æˆ‘ä»¬åªä»æ–°é—»ä¸­æå–å‰5000ä¸ªå•è¯ã€‚\ntfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(2,2)) # TFIDFçŸ©é˜µ X= tfidf_vectorizer.fit_transform(news_features[\u0026#39;news\u0026#39;]) X.shape Out[34]: (44888, 5000) In [35]: #ç›®æ ‡åˆ— y=clean_news[\u0026#39;output\u0026#39;] In [36]: print(f\u0026#39;Original dataset shape : {Counter(y)}\u0026#39;) Original dataset shape : Counter({0: 23471, 1: 21417}) In [37]: ## åˆ›å»ºtrainæˆ–è€…test X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state= æ¨¡å‹æ„å»ºï¼šLogistics Regression å‡æ–°é—»åˆ†ç±»å™¨ å› ä¸ºæˆ‘ä»¬å·²ç»æˆåŠŸå¤„ç†äº†æ–‡æœ¬æ•°æ®ï¼Œæ‰€ä»¥è¿™ä¸ä»…ä»…æ˜¯æ­£å¸¸çš„æœºå™¨å­¦ä¹ é—®é¢˜ã€‚æˆ‘ä»¬ä»ç¨€ç–çŸ©é˜µä¸­é¢„æµ‹ç›®æ ‡ç‰¹å¾ä¸­çš„ç±»ã€‚\ndef plot_confusion_matrix(cm, classes, normalize=False, title=\u0026#39;Confusion matrix\u0026#39;, cmap=plt.cm.Blues): \u0026#34;\u0026#34;\u0026#34; This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. \u0026#34;\u0026#34;\u0026#34; plt.imshow(cm, interpolation=\u0026#39;nearest\u0026#39;, cmap=cmap) plt.title(title) plt.colorbar() tick_marks = np.arange(len(classes)) plt.xticks(tick_marks, classes, rotation=45) plt.yticks(tick_marks, classes) if normalize: cm = cm.astype(\u0026#39;float\u0026#39;) / cm.sum(axis=1)[:, np.newaxis] print(\u0026#34;Normalized confusion matrix\u0026#34;) else: print(\u0026#39;Confusion matrix, without normalization\u0026#39;) thresh = cm.max() / 2. for i in range (cm.shape[0]): for j in range (cm.shape[1]): plt.text(j, i, cm[i, j], horizontalalignment=\u0026#34;center\u0026#34;, color=\u0026#34;white\u0026#34; if cm[i, j] \u0026gt; thresh else \u0026#34;black\u0026#34;) plt.tight_layout() plt.ylabel(\u0026#39;True label\u0026#39;) plt.xlabel(\u0026#39;Predicted label\u0026#39;) æ¨¡å‹é€‰æ‹© é¦–å…ˆä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©æœ€ä½³çš„æˆå‹æ¨¡å‹ã€‚ è®©æˆ‘ä»¬è€ƒè™‘æ‰€æœ‰åˆ†ç±»ç®—æ³•å¹¶æ‰§è¡Œæ¨¡å‹é€‰æ‹©è¿‡ç¨‹ æ³¨æ„ï¼šæˆ‘æ²¡æœ‰åœ¨æ­¤ç®—æ³•ä¸­åŒ…å«SVMï¼Œå› ä¸ºåœ¨è®¾å¤‡ä¸­è¿›è¡ŒåŸ¹è®­éœ€è¦èŠ±è´¹å¾ˆå¤šæ—¶é—´\n# åˆ›å»ºåˆ†ç±»å™¨ logreg_cv = LogisticRegression(random_state=0) dt_cv=DecisionTreeClassifier() knn_cv=KNeighborsClassifier() nb_cv=MultinomialNB(alpha=0.1) cv_dict = {0: \u0026#39;Logistic Regression\u0026#39;, 1: \u0026#39;Decision Tree\u0026#39;,2:\u0026#39;KNN\u0026#39;,3:\u0026#39;Naive Bayes\u0026#39;} cv_models=[logreg_cv,dt_cv,knn_cv,nb_cv] # å‡†ç¡®ç‡ for i,model in enumerate(cv_models): print(\u0026#34;{} Test Accuracy: {}\u0026#34;.format(cv_dict[i],cross_val_score(model, X, y, cv=10, scoring =\u0026#39;accuracy\u0026#39;).mean())) Logistic Regression Test Accuracy: 0.9660040199274997 Decision Tree Test Accuracy: 0.9347925003047657 KNN Test Accuracy: 0.613172841991654 Naive Bayes Test Accuracy: 0.9373328405462511 å‚æ•°è°ƒæ•´ param_grid = {\u0026#39;C\u0026#39;: np.logspace(-4, 4, 50), \u0026#39;penalty\u0026#39;:[\u0026#39;l1\u0026#39;, \u0026#39;l2\u0026#39;]} clf = GridSearchCV(LogisticRegression(random_state=0), param_grid,cv=5, verbose=0,n_jobs=-1) best_model = clf.fit(X_train,y_train) print(best_model.best_estimator_) print(\u0026#34;The mean accuracy of the model is:\u0026#34;,best_model.score(X_test,y_test)) LogisticRegression(C=24.420530945486497, random_state=0) The mean accuracy of the model is: 0.9803065407235787 In [42]: logreg = LogisticRegression(C=24.420530945486497, random_state=0) logreg.fit(X_train, y_train) y_pred = logreg.predict(X_test) print(\u0026#39;Accuracy of logistic regression classifier on test set: {:.2f}\u0026#39;.format(logreg.score(X_test, y_test))) Accuracy of logistic regression classifier on test set: 0.98 æ··æ·†çŸ©é˜µ cm = metrics.confusion_matrix(y_test, y_pred) plot_confusion_matrix(cm, classes=[\u0026#39;Fake\u0026#39;,\u0026#39;True\u0026#39;]) Confusion matrix, without normalization åˆ†ç±»æŠ¥å‘Š print(\u0026#34;Classification Report:\\n\u0026#34;,classification_report(y_test, y_pred)) Classification Report: precision recall f1-score support 0 0.98 0.98 0.98 5892 1 0.98 0.98 0.98 5330 accuracy 0.98 11222 macro avg 0.98 0.98 0.98 11222 weighted avg 0.98 0.98 0.98 11222 ROC-AUC Curve è¿™æ˜¯ä¸€æ¡éå¸¸é‡è¦çš„æ›²çº¿ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®å®¢è§‚æ ‡å‡†æ¥å†³å®šè¦è®¾ç½®çš„é˜ˆå€¼ã€‚\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test)) fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1]) plt.figure() plt.plot(fpr, tpr, label=\u0026#39;Logistic Regression (area = %0.2f)\u0026#39; % logit_roc_auc) plt.plot([0, 1], [0, 1],\u0026#39;r--\u0026#39;) plt.xlim([-0.01, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) plt.title(\u0026#39;Receiver operating characteristic\u0026#39;) plt.legend(loc=\u0026#34;lower right\u0026#34;) plt.show() æ·±åº¦å­¦ä¹ æ¨¡å‹-LSTM åœ¨æœ¬éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥é¢„æµ‹ç»™å®šæ–°é—»æ˜¯å¦ä¸ºå‡æ–°é—»ã€‚\næˆ‘ä»¬ä¸ä¼šä½¿ç”¨åƒANNè¿™æ ·çš„æ™®é€šç¥ç»ç½‘ç»œæ¥åˆ†ç±»ï¼Œè€Œæ˜¯ä½¿ç”¨LSTMï¼ˆé•¿æœŸçŸ­æœŸè®°å¿†ï¼‰æ¥å¸®åŠ©åŒ…å«åºåˆ—ä¿¡æ¯ã€‚é•¿æœŸçŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ç½‘ç»œæ˜¯ä¸€ç§èƒ½å¤Ÿå­¦ä¹ åºåˆ—ä¾èµ–çš„é€’å½’ç¥ç»ç½‘ç»œã€‚ åºåˆ—é¢„æµ‹é—®é¢˜ã€‚ è¿™æ˜¯æœºå™¨ç¿»è¯‘ï¼Œè¯­éŸ³è¯†åˆ«ç­‰å¤æ‚é—®é¢˜åŸŸä¸­æ‰€éœ€çš„è¡Œä¸ºã€‚\nåµŒå…¥å±‚-One Hotç¼–ç  # è¯æ±‡è¡¨å¤§å° voc_size=10000 #One hot ç¼–ç  onehot_repr=[one_hot(words,voc_size)for words in corpus] å¯¹é½åºåˆ— clean_news[\u0026#39;word_count\u0026#39;].describe() Out[49]: count 44888.000000 mean 237.051907 std 198.796232 min 3.000000 25% 124.000000 50% 210.000000 75% 294.000000 max 4831.000000 Name: word_count, dtype: float64 In [50]: # è®¾ç½®åºåˆ—é•¿åº¦ sent_length=5000 # è¡¥é½ embedded_docs=pad_sequences(onehot_repr,padding=\u0026#39;pre\u0026#39;,maxlen=sent_length) print(embedded_docs) [[ 0 0 0 ... 3061 6048 7061] [ 0 0 0 ... 5721 4842 7061] [ 0 0 0 ... 5552 4139 7061] ... [ 0 0 0 ... 7960 9583 8051] [ 0 0 0 ... 5323 5417 3542] [ 0 0 0 ... 8286 7502 4272]] LSTMæ¨¡å‹ #æ„å»ºlstmæ¨¡å‹ embedding_vector_features=40 model=Sequential() model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length)) model.add(Dropout(0.3)) model.add(LSTM(100)) # 100 model.add(Dropout(0.3)) model.add(Dense(1,activation=\u0026#39;sigmoid\u0026#39;)) # ç¼–è¯‘æ¨¡å‹ model.compile(loss=\u0026#39;binary_crossentropy\u0026#39;,optimizer=\u0026#39;adam\u0026#39;,metrics=[\u0026#39;accuracy\u0026#39;]) print(model.summary()) Model: \u0026#34;sequential\u0026#34; _________________________________________________________________ Layer (type) Output Shape Param #  ================================================================= embedding (Embedding) (None, 5000, 40) 400000 _________________________________________________________________ dropout (Dropout) (None, 5000, 40) 0 _________________________________________________________________ lstm (LSTM) (None, 100) 56400 _________________________________________________________________ dropout_1 (Dropout) (None, 100) 0 _________________________________________________________________ dense (Dense) (None, 1) 101 ================================================================= Total params: 456,501 Trainable params: 456,501 Non-trainable params: 0 _________________________________________________________________ None In [52]: len(embedded_docs),y.shape Out[52]: (44888, (44888,)) æ¨¡å‹è®­ç»ƒ # è½¬æ¢Xå’Œy X_final=np.array(embedded_docs) y_final=np.array(y) # Xå’Œyå¤§å° X_final.shape,y_final.shape Out[53]: ((44888, 5000), (44888,)) In [*]: # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42) # epochsè®¾ç½®ä¸º10 batch sizeå¤§å°ä¸º64 model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64) Epoch 1/10 470/470 [==============================] - 125s 267ms/step - loss: 0.2214 - accuracy: 0.9109 - val_loss: 0.0735 - val_accuracy: 0.9768 Epoch 2/10 470/470 [==============================] - 126s 269ms/step - loss: 0.0750 - accuracy: 0.9764 - val_loss: 0.0686 - val_accuracy: 0.9820 Epoch 3/10 470/470 [==============================] - 126s 268ms/step - loss: 0.0538 - accuracy: 0.9837 - val_loss: 0.0550 - val_accuracy: 0.9849 Epoch 4/10 303/470 [==================\u0026gt;...........] - ETA: 38s - loss: 0.0404 - accuracy: 0.9881 æ¨¡å‹è¯„ä¼° # æµ‹è¯•é›†æ•°æ®é¢„æµ‹ y_pred=model.predict_classes(X_test) # æ··æ·†çŸ©é˜µ # confusion_matrix(y_test,y_pred) cm = metrics.confusion_matrix(y_test, y_pred) plot_confusion_matrix(cm,classes=[\u0026#39;Fake\u0026#39;,\u0026#39;True\u0026#39;]) accuracy_score(y_test,y_pred) Out[56]: 0.9800864047522614 In [57]: print(classification_report(y_test,y_pred)) precision recall f1-score support 0 0.98 0.98 0.98 7777 1 0.98 0.98 0.98 7037 accuracy 0.98 14814 macro avg 0.98 0.98 0.98 14814 weighted avg 0.98 0.98 0.98 14814 Bidirectional LSTM Bi-LSTMæ˜¯æ ‡å‡†LSTMçš„æ‰©å±•ï¼Œå…·æœ‰ä¸¤ä¸ªç‹¬ç«‹çš„RNNã€‚ æ™®é€šçš„LSTMæ˜¯å•å‘çš„ï¼Œå®ƒæ— æ³•çŸ¥é“å°†æ¥çš„å•è¯ï¼Œè€Œåœ¨Bi-LSTMä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æµ‹å•è¯çš„æœªæ¥ä½¿ç”¨ï¼Œå› ä¸ºå­˜åœ¨ä»å¦ä¸€RNNå±‚åå‘ä¼ é€’çš„åå‘ä¿¡æ¯ã€‚\nä¸LSTMç›¸æ¯”ï¼Œä»£ç åªåšäº†ä¸€ä¸ªæ›´æ”¹ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨Bidirectionalï¼ˆï¼‰å‡½æ•°å¹¶åœ¨å†…éƒ¨è°ƒç”¨LSTMã€‚\nembedding_vector_features=40 model1=Sequential() model1.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length)) model1.add(Bidirectional(LSTM(100))) # Bidirectional LSTM layer model1.add(Dropout(0.3)) model1.add(Dense(1,activation=\u0026#39;sigmoid\u0026#39;)) model1.compile(loss=\u0026#39;binary_crossentropy\u0026#39;,optimizer=\u0026#39;adam\u0026#39;,metrics=[\u0026#39;accuracy\u0026#39;]) print(model1.summary()) Model: \u0026#34;sequential_1\u0026#34; _________________________________________________________________ Layer (type) Output Shape Param #  ================================================================= embedding_1 (Embedding) (None, 5000, 40) 400000 _________________________________________________________________ bidirectional (Bidirectional (None, 200) 112800 _________________________________________________________________ dropout_2 (Dropout) (None, 200) 0 _________________________________________________________________ dense_1 (Dense) (None, 1) 201 ================================================================= Total params: 513,001 Trainable params: 513,001 Non-trainable params: 0 _________________________________________________________________ None åŒå‘LSTMæ¨¡å‹çš„æ‹Ÿåˆä¸è¯„ä¼° ç°åœ¨è®©æˆ‘ä»¬å°†åŒå‘LSTMæ¨¡å‹æ‹Ÿåˆåˆ°æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®ä¹‹å‰å…·æœ‰ç›¸åŒå‚æ•°çš„æ•°æ®ä¸Šã€‚\n# æµ‹è¯•é›† y_pred1=model1.predict_classes(X_test) # æ··æ·†çŸ©é˜µ cm = metrics.confusion_matrix(y_test, y_pred1) plot_confusion_matrix(cm,classes=[\u0026#39;Fake\u0026#39;,\u0026#39;True\u0026#39;]) In [62]: # å‡†ç¡®ç‡ accuracy_score(y_test,y_pred1) Out[62]: 0.615161333873363 In [61]: # åˆ†ç±»æŠ¥å‘Š print(classification_report(y_test,y_pred1)) precision recall f1-score support 0 0.61 0.74 0.67 7777 1 0.62 0.48 0.54 7037 accuracy 0.62 14814 macro avg 0.62 0.61 0.61 14814 weighted avg 0.62 0.62 0.61 14814 ç»“è®º æˆ‘ä»¬å·²ç»åœ¨å¤„ç†æ•°æ®å’Œæ„å»ºæ¨¡å‹æ–¹é¢è¿›è¡Œäº†ä¸»æµå·¥ä½œã€‚ æˆ‘ä»¬æœ¬å¯ä»¥åœ¨å‘é‡åŒ–æ–‡æœ¬æ•°æ®çš„åŒæ—¶æ²‰è¿·äºæ›´æ”¹ngramã€‚ æˆ‘ä»¬æ‹¿äº†2ä¸ªå­—å¹¶å°†å…¶å‘é‡åŒ–ã€‚ æ‚¨å¯ä»¥é€šè¿‡åŒæ—¶è€ƒè™‘1å’Œ2ä¸ªå•è¯æ¥æ£€æŸ¥Shretaåœ¨åŒä¸€æ•°æ®é›†ä¸Šçš„å·¥ä½œï¼Œå¥¹åœ¨LSTMå’ŒBi-LSTMç½‘ç»œçš„å¸®åŠ©ä¸‹è·å¾—äº†æ›´å¥½çš„ç»“æœã€‚è®©æˆ‘ä»¬è®¨è®ºæ•°æ®é›†çš„ä¸€èˆ¬è§è§£ã€‚\nå¤§å¤šæ•°è™šå‡æ–°é—»éƒ½è¢«é€‰ä¸¾æ–°é—»å’Œç‰¹æœ—æ™®æ‰€åŒ…å›´ã€‚ è€ƒè™‘åˆ°2020å¹´ç¾å›½å¤§é€‰ã€‚æœ‰ä¼ æ’­å‡æ–°é—»çš„æœºä¼šï¼Œå°†éå¸¸éœ€è¦è¿™äº›æŠ€æœ¯çš„åº”ç”¨ã€‚ å‡æ–°é—»ç›®å‰åœ¨è¿™ç§å¤§æµè¡Œæƒ…å†µä¸­æ ¹æ·±è’‚å›ºï¼Œä»¥æ‰“æ”¿æ²»ï¼Œæå“äººä»¬å¹¶å¼ºè¿«ä»–ä»¬è´­ä¹°å•†å“ å¤§å¤šæ•°æ–°é—»æ¥è‡ªè·¯é€ç¤¾ã€‚ æˆ‘ä»¬ä¸çŸ¥é“è¿™ç§æ–°é—»åª’ä½“æ˜¯å¦å—åˆ°æ”¿æ²»å½±å“ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬åº”å§‹ç»ˆè€ƒè™‘æ–°é—»æ¥æºï¼Œä»¥æŸ¥æ‰¾æ–°é—»æ˜¯è™šå‡è¿˜æ˜¯çœŸå®ã€‚\næœ€åæ¬¢è¿å¤§å®¶å…³æ³¨æˆ‘ä»¬çš„å…¬ä¼—å·ï¼šChallengeHubï¼ŒåŠ å…¥ChallengeHubç²‰ä¸ç¾¤ï¼Œå…±åŒæ¢è®¨ï¼Œå…±åŒå­¦ä¹ ï¼Œå…±åŒè¿›æ­¥ï¼ï¼ï¼ ","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/%E5%9F%BA%E4%BA%8Elstm%E7%9A%84%E7%BE%8E%E5%9B%BD%E5%A4%A7%E9%80%89%E7%9A%84%E6%96%B0%E9%97%BB%E7%9C%9F%E5%81%87%E5%88%86%E7%B1%BB/","series":["æ·±åº¦å­¦ä¹ è¯¾ç¨‹"],"tags":["æ·±åº¦å­¦ä¹ è¯¾ç¨‹"],"title":"åŸºäºLSTMçš„ç¾å›½å¤§é€‰çš„æ–°é—»çœŸå‡åˆ†ç±»ã€NLP æ–°å¹´å¼€èƒƒèœã€‘"},{"categories":["æŠ€æœ¯åšå®¢"],"content":"#æˆ‘ä»¬å›å½’ä¸‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºGraphsç”¨æ¥åšä¼ ç»Ÿæœºå™¨å­¦ä¹ ä»»åŠ¡çš„æµç¨‹ä¸ºï¼šç»™å®šè¾“å…¥Graph,ç„¶åç”¨æ¥æå–èŠ‚ç‚¹ï¼Œè¾¹ä»¥åŠå›¾çº§åˆ«çš„ç‰¹å¾ï¼Œä¹‹åå­¦ä¹ æ¨¡å‹ï¼ˆæ¯”å¦‚SVM,NNç­‰ç­‰ï¼‰ï¼Œæœ€åå°†ç‰¹å¾æ˜ å°„ä¸ºæ ‡ç­¾ã€‚ 1 å¼•è¨€ å›¾è¡¨ç¤ºå­¦ä¹ å¯ä»¥å‡è½»ç‰¹å¾å·¥ç¨‹çš„éœ€æ±‚ï¼Œè¡¨ç¤ºå­¦ä¹ å¯ä»¥è‡ªåŠ¨å­¦ä¹ Graphçš„ç‰¹å¾ï¼Œç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œç†Ÿæ‚‰NLPçš„åŒå­¦æ¯”è¾ƒæ¸…æ¥šï¼Œä¼ ç»Ÿæ–‡æœ¬ç‰¹å¾æ„å»ºä¾èµ–äºç»Ÿè®¡æ‰‹æ®µæ¥å®ç°ï¼Œå†—ä½™ä¸”æ•ˆæœæœ‰é™ï¼Œåœ¨è¯å‘é‡Word2Vecå’Œé¢„è®­ç»ƒæ¨¡å‹Bertç­‰å‡ºç°ä¹‹åï¼Œæ–‡æœ¬è¡¨ç¤ºå˜å¾—æ›´ä¸ºä¾¿åˆ©ä¸”æ•ˆæœå¼ºå¤§ï¼Œè‡ªæ­¤ä¸‡ç‰©çš†å¯Embeddingã€‚\nå›¾çš„è¡¨ç¤ºå­¦ä¹ çš„ç›®çš„å°±æ˜¯è·å¾—ç‹¬ç«‹äºä¸åŒä»»åŠ¡çš„é«˜æ•ˆç‰¹å¾ï¼Œé€šä¿—ç‚¹è®²å°±æ˜¯èƒ½å¤Ÿé’ˆå¯¹ä¸åŒä»»åŠ¡å­¦ä¹ å¾—åˆ°é€‚åˆä»»åŠ¡çš„åµŒå…¥è¡¨ç¤ºã€‚ Node Embeddingçš„ç›®çš„å°±æ˜¯èƒ½å¤Ÿå°†èŠ‚ç‚¹æ˜ å°„åˆ°ä¸åŒçš„embeddingç©ºé—´ï¼š\n èŠ‚ç‚¹é—´çš„embeddingçš„ç›¸ä¼¼æ€§å¯ä»¥è¡¨ç¤ºäº†èŠ‚ç‚¹é—´åœ¨ç½‘ç»œçš„ç›¸ä¼¼æ€§ï¼šå¦‚æœä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´å­˜åœ¨è¾¹ï¼Œé‚£ä¹ˆä¸¤ä¸ªèŠ‚ç‚¹è¶Šç›¸ä¼¼ èŠ‚ç‚¹çš„Embeddingèƒ½å¤Ÿç¼–ç ç½‘ç»œä¿¡æ¯ å¯ä»¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œæ¯”å¦‚èŠ‚ç‚¹åˆ†ç±»ï¼Œè¾¹çš„é¢„æµ‹ï¼Œå›¾çš„åˆ†ç±»ç­‰ ä¸‹é¢æ˜¯ä¸€ä¸ªZachary\u0026rsquo;s Karate Club Networkçš„2ç»´èŠ‚ç‚¹Embeddingå±•ç¤ºï¼š   2 èŠ‚ç‚¹åµŒå…¥ï¼šç¼–ç å’Œè§£ç  è¿™ä¸€èŠ‚æˆ‘ä»¬ä¸»è¦æŒæ¡ä¸‹å¦‚ä½•å­¦ä¹ èŠ‚ç‚¹çš„åµŒå…¥å‘é‡\n2.1 æ„å»ºè¾“å…¥-å›¾ é¦–å…ˆï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå›¾$G$ï¼š\n $V$ä»£è¡¨èŠ‚ç‚¹çš„é›†åˆ $A$ ä»£è¡¨é“¾æ¥çŸ©é˜µ ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬é»˜è®¤è®¤ä¸ºèŠ‚ç‚¹æ²¡æœ‰å…¶ä»–çš„é¢å¤–ç‰¹å¾ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š   2.2 å­¦ä¹ ç›®æ ‡-Node Embedding æˆ‘ä»¬çš„ç›®æ ‡æ˜¯èƒ½å¤Ÿå­¦ä¹ åˆ°èŠ‚ç‚¹çš„åµŒå…¥è¡¨ç¤ºï¼Œè¿™ç§èŠ‚ç‚¹åµŒå…¥çš„ç›¸ä¼¼æ€§èƒ½å¤Ÿè¿‘ä¼¼èŠ‚ç‚¹åœ¨å›¾ä¸­çš„ç›¸ä¼¼æ€§ã€‚ å›¾ä¸­$ENC(u)$ä»£è¡¨å¯¹èŠ‚ç‚¹$u$è¿›è¡Œç¼–ç è¡¨ç¤ºå¾—åˆ°$z_{u}$,åŒæ ·$ENC(v)$ä»£è¡¨å¯¹èŠ‚ç‚¹$u$è¿›è¡Œç¼–ç è¡¨ç¤ºå¾—åˆ°$z_{v}$\n2.3 å­¦ä¹ æ–¹æ³•-Encoderå’ŒDecoder  **Encoder**èƒ½å¤Ÿå°†èŠ‚ç‚¹æ˜ å°„æˆå‘é‡ å®šä¹‰ä¸€ä¸ªèŠ‚ç‚¹ç›¸ä¼¼æ€§å‡½æ•°(æ¯”å¦‚èŠ‚ç‚¹åœ¨åŸå§‹å›¾ä¸­çš„ç›¸ä¼¼æ€§è¯„ä¼°æ–¹æ³•) Decoder DECèƒ½å¤Ÿå°†èŠ‚ç‚¹å‘é‡æ˜ å°„æˆç›¸ä¼¼æ€§åˆ†æ•° ä¼˜åŒ–ç¼–ç å™¨çš„å‚æ•°ï¼š åŸå§‹ç½‘ç»œçš„ç›¸ä¼¼æ€§ï¼š$similarity(u,v)$ $\\approx$ èŠ‚ç‚¹åµŒå…¥çš„ç›¸ä¼¼æ€§ ï¼š $z_{v}^Tz_{u}$  å…¶ä¸­æœ‰ä¸¤ä¸ªéå¸¸å…³é”®å› ç´ ï¼šç¼–ç å’Œç›¸ä¼¼æ€§å‡½æ•°ã€‚ç¼–ç å™¨èƒ½å¤Ÿå­¦ä¹ åˆ°èŠ‚ç‚¹çš„å‘é‡ï¼Œç›¸ä¼¼æ€§å‡½æ•°èƒ½å¤Ÿæä¾›æˆ‘ä»¬ä¼˜åŒ–çš„ç›®æ ‡ï¼Œå¦‚æœä¸¤ä¸ªèŠ‚ç‚¹åœ¨å›¾ä¸­å­˜åœ¨è¾¹æˆ–è€…è·ç¦»è¶Šè¿‘ï¼Œé‚£ä¹ˆå®ƒä»¬å¯¹åº”çš„èŠ‚ç‚¹å‘é‡åœ¨å‘é‡ç©ºé—´ä¸­ç›¸ä¼¼æ€§ä¹Ÿä¼šè¶Šå¤§ã€‚ å¦‚ä½•é€‰æ‹©å®šä¹‰èŠ‚ç‚¹ç›¸ä¼¼æ€§çš„æ–¹æ³•æ˜¯å…³é”®çš„åœ°æ–¹ï¼Œæˆ‘ä»¬è€ƒè™‘ä¸‹ä»€ä¹ˆæƒ…å†µä¸‹ï¼Œä¸¤ä¸ªèŠ‚ç‚¹çš„ç›¸ä¼¼æ€§æ¯”è¾ƒé«˜ï¼Ÿ\n æ˜¯å¦å­˜åœ¨è¾¹æˆ–è€…è¿æ¥ æ˜¯å¦å…±äº«é‚»å±…èŠ‚ç‚¹ æ˜¯å¦åŒ…æ‹¬ç›¸ä¼¼çš„å±æ€§ç‰¹å¾ æ¥ä¸‹æ¥æˆ‘ä»¬é€šè¿‡éšæœºæ¸¸èµ°ï¼ˆRandom Walksï¼‰æ¥å­¦ä¹ èŠ‚ç‚¹ç›¸ä¼¼æ€§ï¼Œä»¥åŠä¼˜åŒ–èŠ‚ç‚¹çš„åµŒå…¥å‘é‡ã€‚  3 Random Walk Node Embeddingsçš„è®¡ç®—æ–¹æ³•ä¹‹ä¸€å°±æ˜¯Random Walkï¼Œä¸ºäº†æ–¹é¢èµ·è§æˆ‘ä»¬å®šä¹‰å’Œå¼•å‡ºä¸‹é¢çš„ç¬¦å·ï¼Œä»¥ä¾¿ç»Ÿä¸€è§£é‡Šã€‚\n3.1 ç¬¦å· ä¸ºäº†æ–¹é¢æ¥ä¸‹æ¥çš„å…¬å¼æ¨å¯¼ï¼Œæˆ‘ä»¬ç»Ÿä¸€ä¸‹ç¬¦å·æ ‡è®°ï¼š\n å‘é‡ $z_{u}$:  uèŠ‚ç‚¹çš„åµŒå…¥å‘é‡\n  æ¦‚ç‡$P(v|z_{u})$ï¼š  ä»èŠ‚ç‚¹$u$å‡ºå‘é€šè¿‡éšæœºæ¸¸èµ°è®¿é—®èŠ‚ç‚¹$v$çš„æ¦‚ç‡\n  Softmaxå‡½æ•°ï¼šé€šè¿‡softmaxå‡½æ•°ä¸€ä½œç”¨ï¼Œä¸€ä¸ªKç»´å‘é‡å°±æ˜ å°„æˆä¸º(0,1)çš„å€¼ï¼Œè€Œè¿™äº›å€¼çš„ç´¯å’Œä¸º1ï¼ˆæ»¡è¶³æ¦‚ç‡çš„æ€§è´¨ï¼‰ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥å°†å®ƒç†è§£æˆæ¦‚ç‡ï¼Œåœ¨æœ€åé€‰å–è¾“å‡ºç»“ç‚¹çš„æ—¶å€™ï¼Œæˆ‘ä»¬å°±å¯ä»¥é€‰å–æ¦‚ç‡æœ€å¤§ï¼ˆä¹Ÿå°±æ˜¯å€¼å¯¹åº”æœ€å¤§çš„ï¼‰ç»“ç‚¹ï¼Œä½œä¸ºæˆ‘ä»¬çš„é¢„æµ‹ç›®æ ‡ã€‚ $\\sigma(z){i}=\\frac{e^{Z{i}}}{\\sum_{j=1}^Ke^{Z_{j}}}$ Sigmoidå‡½æ•°ï¼š $S(x)=\\frac{1}{1+e^{-x}}$å°†ä¸€ä¸ªæ•°æ˜ å°„åˆ°ï¼ˆ0,1ï¼‰çš„åŒºé—´  3.2 Random Walk å®šä¹‰ ç»™å®šä¸€ä¸ªGraphå’Œä¸€ä¸ªèµ·å§‹ç‚¹ï¼Œæˆ‘ä»¬é€‰æ‹©éšæœºé€‰æ‹©è¯¥ç‚¹çš„é‚»å±…èŠ‚ç‚¹ï¼Œå¹¶ä¸”ç§»åŠ¨åˆ°è¯¥é‚»å±…èŠ‚ç‚¹ï¼›ç„¶åæˆ‘ä»¬æ ¹æ®å½“å‰èŠ‚ç‚¹éšæœºé€‰æ‹©ä¸€ä¸ªé‚»å±…èŠ‚ç‚¹ï¼Œç„¶åç§»åŠ¨åˆ°è¯¥é‚»å±…èŠ‚ç‚¹ï¼Œé‡å¤ä¸Šè¿°æ­¥éª¤\u0026hellip;é€šè¿‡è¿™ç§éšæœºæ¸¸èµ°è®¿é—®GraphèŠ‚ç‚¹çš„æ–¹å¼å¯ä»¥äº§ç”Ÿéšæœºåºåˆ—ã€‚ä¸‹å›¾æè¿°äº†ä¸€ä¸ªéšæœºæ¸¸èµ°çš„å®ä¾‹ï¼Œç¬¬ä¸€æ­¥ä»èµ·å§‹èŠ‚ç‚¹å‡ºå‘ç§»åŠ¨åˆ°èŠ‚ç‚¹5ï¼Œç¬¬äºŒæ­¥ä»èŠ‚ç‚¹5ç§»åŠ¨èŠ‚ç‚¹8ï¼Œç¬¬ä¸‰æ­¥ä»èŠ‚ç‚¹8ç§»åŠ¨èŠ‚ç‚¹9ï¼Œç¬¬å››æ­¥åˆä»èŠ‚ç‚¹9ç§»åŠ¨åˆ°èŠ‚ç‚¹8ï¼Œä¹‹åç¬¬5æ­¥ç§»åŠ¨åˆ°èŠ‚ç‚¹11ï¼Œè¿™æ ·è®¿é—®è·¯å¾„æ„æˆä¸€ä¸ªåºåˆ—ï¼š\nstart_node-\u0026gt;5-\u0026gt;8-\u0026gt;9-\u0026gt;8-\u0026gt;11 3.3 Random Walkå¦‚ä½•å¾—åˆ°Node Embeddings ç›¸ä¿¡å¤§å®¶å¯¹ä¸‹é¢çš„å…¬å¼ä¸ä¼šæ„Ÿåˆ°é™Œç”Ÿï¼Œä¸€èˆ¬æˆ‘ä»¬è¡¡é‡ä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼æ€§æ—¶å¯ä»¥é€šè¿‡ä¸¤ä¸ªå‘é‡ç‚¹ç§¯è®¡ç®—å¾—åˆ°ï¼Œç›¸ä¼¼åœ°ä¸¤ä¸ªèŠ‚ç‚¹åŒæ—¶å‡ºç°åœ¨åŒä¸€éšæœºæ¸¸èµ°åºåˆ—çš„æ¦‚ç‡å¯ä»¥ç”¨å¦‚ä¸‹è¡¨ç¤ºï¼š æ‰€ä»¥æˆ‘ä»¬é€šè¿‡Rankdom Walkå¾—åˆ°Node Embeddingå¯ä»¥é€šè¿‡ä¸¤ä¸ªæ­¥éª¤ï¼š (1) é€šè¿‡æŸç§éšæœºæ¸¸èµ°ç­–ç•¥$R$ï¼ˆä¸‹æ–‡å°†ä¼šä»‹ç»ï¼‰å¾—åˆ°ä»èŠ‚ç‚¹$u$å‡ºå‘è®¿é—®åˆ°èŠ‚ç‚¹$v$çš„è·¯å¾„ï¼Œç„¶åå¯ä»¥ä¼°è®¡å‡ºèŠ‚ç‚¹$u$å’Œ$v$åŒæ—¶å‡ºç°çš„æ¦‚ç‡ (2) ä¼˜åŒ–èŠ‚ç‚¹çš„embeddingsè¡¨ç¤ºï¼Œä½¿å¾—èŠ‚ç‚¹çš„åµŒå…¥è¡¨ç¤ºèƒ½å¤Ÿè¡¨è¾¾æˆ–è€…è¿‘ä¼¼æˆ‘ä»¬ä¸Šè¿°éšæœºæ¸¸èµ°å¾—åˆ°çš„ç»Ÿè®¡ å›æƒ³ä¸€ä¸‹æˆ‘ä»¬æœºå™¨å­¦ä¹ æˆ–è€…æ·±åº¦å­¦ä¹ çš„å„ç§ä»»åŠ¡ï¼Œæ— éå°±æ˜¯åœ¨ä¼˜åŒ–ä¸€ä¸ªç›®æ ‡ï¼Œä¸€ä¸ªè¿‘ä¼¼ç›®æ ‡ï¼Œæˆ‘ä»¬å¯ä»¥ç¬¼ç»Ÿåœ°å°†æˆ‘ä»¬è¾“å…¥è¡¨ç¤ºæˆXï¼Œç„¶åé€šè¿‡æ–¹æ³•fæ¥è¿‘ä¼¼yã€‚è¯´åˆ°è¿™é‡Œä¸Šé¢ä¸¤ä¸ªæ­¥éª¤ç‰¹åˆ«åƒNLPä¸­Gloveå‘é‡çš„ä¼˜åŒ–æ­¥éª¤ï¼Œé¦–å…ˆæˆ‘ä»¬ç»Ÿè®¡ä¸¤ä¸ªè¯åœ¨è¯­æ–™ä¸­å…±ç°æ¦‚ç‡ï¼Œç„¶åé€šè¿‡è¯å‘é‡æ¥è¿‘ä¼¼å…±ç°æ¦‚ç‡ã€‚\n","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C03-node-embeddings/","series":["å›¾ç¥ç»ç½‘ç»œ"],"tags":["å›¾ç¥ç»ç½‘ç»œ"],"title":"å›¾ç¥ç»ç½‘ç»œï¼ˆ03ï¼‰-Node Embeddings"},{"categories":["ChallengeHub"],"content":" ChallengeHub:A community dedicated to AI knowledge sharing\n æˆå‘˜ä¿¡æ¯  è‡´Greatï¼Œæ¯•ä¸šäºä¸­å›½äººæ°‘å¤§å­¦ï¼Œå°±èŒäºæŸç ”ç©¶é™¢ï¼Œç®—æ³•å·¥ç¨‹å¸ˆï¼› lrhaoï¼Œå°±èŒäºæŸäº’è”ç½‘å¤§å‚æ•°æ®åˆ†æï¼› ä¸æ˜¯å§é˜¿sirï¼Œåä¸œå¸ˆèŒƒå¤§å­¦ç ”äºŒå­¦ç”Ÿï¼Œç›®å‰æŸäº’è”ç½‘å¤§å‚ç®—æ³•å®ä¹ ï¼› WintoMTï¼Œä¸­å—å¤§å­¦ç ”äºŒå­¦ç”Ÿï¼› starryï¼Œæ¯•ä¸šäºåŒæµå¤§å­¦ï¼Œå°±èŒäºæŸäº’è”ç½‘å¤§å‚ï¼Œç®—æ³•å·¥ç¨‹å¸ˆ  æˆå‘˜è£èª‰  2019å¹´å¦é—¨å›½é™…é“¶è¡Œæ•°åˆ›é‡‘èæ¯ å† å†› 2021å¹´æ°´åˆ©çŸ¥è¯†å›¾è°±æ„å»ºæŒ‘æˆ˜èµ› äºšå†› 2020å¹´CCFåä¸ºserverlessè´Ÿè½½é¢„æµ‹ äºšå†› 2020å¹´æ–°ç½‘é“¶è¡Œç”¨æˆ·è¡Œä¸ºä½“è¯†åˆ« äºšå†› 2020å¹´ä¼—å®‰ç§‘æŠ€ç”¨æˆ·éª—ä¿è¡Œä¸ºè¯†åˆ« äºšå†› 2020å¹´ä¸­å›½ç”µä¿¡ç¿¼æ”¯ä»˜é£é™©ç”¨æˆ·è¯†åˆ« å­£å†› 2020å¹´äººå·¥æ™ºèƒ½å›¾åƒåˆ†ç±»åº”ç”¨æŒ‘æˆ˜èµ› å­£å†› 2020å¹´é•¿ä¸‰è§’åˆ›åŒä½“æ•°æ®æŒ–æ˜ç«èµ› å­£å†› 2020å¹´CCFä¼ä¸šé£é™©éæ³•é›†èµ„é¢„æµ‹ å­£å†› 2019å¹´ä¸­å›½é“¶è”ç”¨æˆ·è¡Œä¸ºè´­ä¹°é¢„æµ‹ äºšå†›  è”ç³»é‚®ç®± challengehub@126.com\n","permalink":"/about/challengehub/","series":null,"tags":["ChallengeHub"],"title":"ChallengeHub"},{"categories":["æŠ€æœ¯åšå®¢"],"content":"æœ¬æ–‡å±•ç¤ºäº†å¦‚æœä½¿ç”¨ scikit-learn ä½¿ç”¨ã€‚\nsklearn (scikit-learn) æ˜¯åŸºäº Python è¯­è¨€çš„æœºå™¨å­¦ä¹ å·¥å…·\n å®˜æ–¹é“¾æ¥ï¼šhttps://scikit-learn.org/stable/\n å®‰è£…  é€šè¿‡pipå®‰è£…  $ pip install -U scikit-learn  é€šè¿‡condaå®‰è£…  $ conda install -c intel scikit-learn å®ä¾‹ from sklearn.ensemble import RandomForestClassifier clf = RandomForestClassifier(random_state=0) X = [[ 1, 2, 3], # 2 samples, 3 features [11, 12, 13]] y = [0, 1] # classes of each sample clf.fit(X, y) RandomForestClassifier(random_state=0) ","permalink":"/posts/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/scikit-learn/","series":["Scikit-Learnç³»åˆ—æ•™ç¨‹"],"tags":["scikit-learn"],"title":"Scikit-Learn"},{"categories":["æ¯”èµ›æ¨é€"],"content":"KDD 2021 èµ›é¢˜ èµ›é¢˜1 åŸºäºå¤šæ•°æ®é›†çš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹  Multi-dataset Time Series Anomaly Detection https://compete.hexagon-ml.com/practice/competition/39/\n èƒŒæ™¯æè¿°-æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ è¿‘å¹´æ¥ï¼ŒSIGKDDä»¥åŠå…¶ä»–æ•°æ®æŒ–æ˜ï¼Œæœºå™¨å­¦ä¹ å’Œæ•°æ®åº“ä¼šè®®ä¸Šå‡ºç°äº†æœ‰å…³æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹çš„è®ºæ–‡ã€‚è¿™äº›è®ºæ–‡ä¸­çš„å¤§å¤šæ•°éƒ½åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸­è¿›è¡Œæµ‹è¯•ï¼ŒåŒ…æ‹¬ç”±NASAï¼ŒYahooï¼ŒNumentaå’Œæ¸…å-OMNI ç­‰åˆ›å»ºçš„æ•°æ®é›†ã€‚\nå°½ç®¡ç¤¾åŒºåº”è¯¥éå¸¸èµèµè¿™äº›å›¢é˜Ÿå…±äº«æ•°æ®çš„åŠªåŠ›ï¼Œä½†æœ€è¿‘çš„å‡ ç¯‡è®ºæ–‡[a]è®¤ä¸ºè¿™äº›æ•°æ®é›†ä¸é€‚ç”¨äºè¡¡é‡å¼‚å¸¸æ£€æµ‹çš„è¿›å±•ã€‚\nç®€è€Œè¨€ä¹‹ï¼Œåå¯¹ä½¿ç”¨è¿™äº›æ•°æ®é›†çš„ä¸¤ä¸ªæœ€å¼•äººæ³¨ç›®çš„è®ºæ®æ˜¯ï¼š\nå†—ä½™æ€§ï¼šå‡ ä¹æ‰€æœ‰ä¸Šè¿°åŸºå‡†æ•°æ®é›†éƒ½å¯ä»¥å®Œç¾è§£å†³ï¼Œè€Œæ— éœ€æŸ¥çœ‹ä»»ä½•è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”ä½¿ç”¨å·²æœ‰åå¹´å†å²çš„ç®—æ³•ã€‚ æ ‡ç­¾é”™è¯¯ï¼šæ°¸è¿œä¸èƒ½å®Œå…¨æ¶ˆé™¤é”™è¯¯æ£€æµ‹åŸºå‡†é”™è¯¯è´´æ ‡ç­¾çš„å¯èƒ½æ€§ã€‚ä½†æ˜¯ï¼Œä¸Šé¢æåˆ°çš„æŸäº›æ•°æ®é›†åœ¨åŸºæœ¬äº‹å®ä¸­ä¼¼ä¹æœ‰å¤§é‡å‡é˜³æ€§å’Œå‡é˜´æ€§ã€‚å·²ç»å‘è¡¨äº†ä¸€äº›è®ºæ–‡ï¼Œè®¤ä¸ºæ–¹æ³•Aæ¯”æ–¹æ³•Bæ›´å¥½ï¼Œå› ä¸ºå®ƒåœ¨åŸºå‡†Xä¸Šçš„å‡†ç¡®æ€§è¦é«˜5ï¼…ã€‚ä½†æ˜¯ï¼Œä»”ç»†æ£€æŸ¥åŸºå‡†Xå¯ä»¥å‘ç°ï¼Œæœ‰25ï¼…ä»¥ä¸Šçš„æ ‡ç­¾æ˜¯é”™è¯¯çš„ï¼Œè¿™ä¸ªæ•°å­—ä½¿æ ‡ç­¾Açš„å‡†ç¡®æ€§ç›¸å½¢è§warã€‚å£°ç§°æ‰€æ¯”è¾ƒç®—æ³•ä¹‹é—´çš„å·®å¼‚ã€‚\né™¤äº†ä¸Šé¢åˆ—å‡ºçš„é—®é¢˜ä»¥åŠæ–‡ä»¶é‡å çš„å¯èƒ½æ€§å¤–ï¼Œæˆ‘ä»¬è®¤ä¸ºç¤¾åŒºè¿˜å­˜åœ¨ä¸€ç³»åˆ—ä¸åˆé€‚çš„åŸºå‡†ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œä½œä¸ºæ¯”èµ›çš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä¸ºæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹åˆ›å»ºäº†æ–°çš„åŸºå‡†ã€‚\nä¸ºæ­¤ç«èµ›åˆ›å»ºçš„åŸºå‡†æ•°æ®é›†æ—¨åœ¨ç¼“è§£æ­¤é—®é¢˜ã€‚é‡è¦çš„æ˜¯è¦æ³¨æ„æˆ‘ä»¬çš„ä¸»å¼ æ˜¯â€œç¼“è§£â€ï¼Œè€Œä¸æ˜¯â€œè§£å†³â€ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œéå¸¸æœ‰å¾ˆå¤šç ”ç©¶è€…æœ¬ç€CASP [d]çš„ç²¾ç¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜å°†æ˜¯å¾ˆæ£’çš„ã€‚\nåŒæ—¶ï¼Œä½œä¸ºè¿™ä¸€æŒ‘æˆ˜çš„ä¸€éƒ¨åˆ†çš„200ä¸ªæ•°æ®é›†åæ˜ äº†20å¤šå¹´ç ”ç©¶æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹æ–‡çŒ®å¹¶æ”¶é›†æ•°æ®é›†çš„å·¥ä½œã€‚é™¤äº†è¿™åœºç«èµ›çš„æœ¬èº«ï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒä»¬å¯ä»¥åœ¨æœªæ¥å‡ å¹´ä¸­ä¸ºç¤¾åŒºæä¾›èµ„æºï¼Œå¹¶æ¿€å‘å¯¹å¼‚å¸¸æ£€æµ‹è¯„ä¼°çš„æ›´æ·±åˆ»çš„æ€è€ƒã€‚\nèµ›é¢˜å¥–åŠ±  ä¸€ç­‰å¥–ï¼š$ 2000 USD äºŒç­‰å¥–ï¼š$ 1000 USD ä¸‰ç­‰å¥–ï¼š$ 500ç¾å…ƒ å¯¹äºæ’åå‰15ä½çš„å‚ä¸è€…ï¼Œæˆ‘ä»¬å°†æä¾›å…·æœ‰ç­‰çº§çš„è¯ä¹¦ã€‚ å¯¹äºæ‰€æœ‰å…¶ä»–å‚ä¸è€…ï¼Œæˆ‘ä»¬å°†æä¾›å‚èµ›è¯ä¹¦ï¼ˆé˜³å…‰æ™®ç…§å¥–ï¼‰  èµ›é¢˜æ—¶é—´è½´  é˜¶æ®µ1:2021å¹´3æœˆ15æ—¥-2021å¹´4æœˆ7æ—¥ é˜¶æ®µ2:2021å¹´4æœˆ7æ—¥-20210å¹´6æœˆ1æ—¥  èµ›é¢˜ä»»åŠ¡ä¸æ•°æ® èµ›é¢˜ä»»åŠ¡ï¼šé¢„æµ‹æ—¶é—´åºåˆ—ä¸­å¼‚å¸¸å‘ç”Ÿçš„ä½ç½®\næ•°æ®    å§“å ä¸‹è½½     æäº¤æ ·ä¾‹ [ä¸‹è½½](https://compete.hexagon-ml.com/media/data/multi-dataset-time-series-anomaly-detection-39/submissionsample.csv)    æ•°æ® [ä¸‹è½½](https://compete.hexagon-ml.com/media/data/multi-dataset-time-series-anomaly-detection-39/data.zip)    æ–‡ä»¶æ ¼å¼\nè¿™äº›æ–‡ä»¶ä½¿ç”¨å‘½åçº¦å®šï¼Œè¯¥çº¦å®šåœ¨æµ‹è¯•å’Œè®­ç»ƒä¹‹é—´æä¾›äº†åˆ†éš”ã€‚\n_ \u0026lt;åç§°\u0026gt; _ \u0026lt;æ‹†åˆ†å·\u0026gt; .txt\nä¾‹å¦‚004_UCR_Anomaly_2500.txtã€‚Â æ­¤å¤„split-number = 2500è¡¨ç¤ºä»2500å¼€å§‹å­˜åœ¨å¼‚å¸¸ã€‚\næ ·æœ¬æäº¤æ–‡ä»¶\næç¤ºï¼š\næäº¤æ–‡ä»¶çš„columnæ ‡å¤´åº”â€œå®Œå…¨â€åŒ¹é…é¢„æœŸçš„æ ¼å¼ã€‚ä¾‹å¦‚ï¼Œç¼–å·ï¼Œä½ç½®\nè¡Œæ•°åº”ä¸æ€»è®¡æ•°å®Œå…¨åŒ¹é…ï¼ˆç¬¬ä¸€é˜¶æ®µï¼š25è¡Œï¼Œç¬¬äºŒé˜¶æ®µï¼š200è¡Œï¼‰\nlocationçš„å€¼æ˜¯ä¸€ä¸ªæ•´æ•°ã€‚\nç¬¬ä¸€é˜¶æ®µÂ æ•°æ®éƒ¨åˆ†å°†æä¾›25ä¸ªæ—¶é—´åºåˆ—æ–‡ä»¶ä»¥åŠç¤ºä¾‹æäº¤æ–‡ä»¶ã€‚Â è¿™å°†æ˜¯ä¸€ä¸ªåŸ¹è®­é˜¶æ®µï¼Œåœ¨è¿›å…¥ç¬¬äºŒé˜¶æ®µæ—¶å°†æ¸…é™¤æ’è¡Œæ¦œã€‚\nç¬¬äºŒé˜¶æ®µ\næ¯”èµ›ç¬¬äºŒé˜¶æ®µå°†æä¾›200ä¸ªæ—¶é—´åºåˆ—æ–‡ä»¶ï¼ŒåŒ…æ‹¬ç¬¬ä¸€é˜¶æ®µçš„å‰25ä¸ªæ–‡ä»¶ã€‚\næäº¤è¯„ä¼° æˆ‘ä»¬åœ¨å¼‚å¸¸èŒƒå›´çš„ä¸¤ä¾§æ·»åŠ äº†+/- 100ä¸ªä½ç½®ï¼Œä»¥å¥–åŠ±æ­£ç¡®çš„ç­”æ¡ˆã€‚\nä¾‹å­\næœ‰200ä¸ªæ–‡ä»¶ï¼Œå¯¹äºæ¯ä¸ªæ­£ç¡®çš„ç­”æ¡ˆï¼Œæ‚¨å°†è·å¾—1åˆ†ï¼Œå¯¹äºé”™è¯¯çš„ç­”æ¡ˆå°†è·å¾—0åˆ†ã€‚æ‚¨å¯ä»¥è·å¾—çš„æœ€é«˜åˆ†æ•°æ˜¯100ï¼…ï¼ˆåªè¦æ‚¨ä½¿ç”¨ç®—æ³•åœ¨ä»£ç ä¸­æ‰§è¡Œæ­¤æ“ä½œï¼Œå°±æ— éœ€äººå·¥æ ‡è®°ï¼‰ã€‚å¦‚æœæˆ‘ä»¬æ€€ç–‘æœ‰ä»»ä½•å‚ä¸è€…\nèµ›é¢˜å¯ä»¥æäº¤äº†ï¼Œåˆ«ç­‰å¾…äº†~ èµ›é¢˜2 åŸå¸‚å¤§è„‘æŒ‘æˆ˜-äº¤é€šç½‘ç»œè°ƒåº¦  City Brain Challenge http://www.yunqiacademy.org/\n èµ›é¢˜èƒŒæ™¯ æ²¡æœ‰äººå–œæ¬¢è¢«å¡åœ¨åŸå¸‚äº¤é€šä¸­ã€‚å°½ç®¡æˆ‘ä»¬åœ¨åŸå¸‚ä¸­è§‚å¯Ÿåˆ°è®¸å¤šè½¦è¾†ï¼Œä½†äº¤é€šæ‹¥å µçš„åŸå› ä»ä¸æ¸…æ¥šã€‚æ˜¯å› ä¸ºè½¦è¾†æ•°é‡è¶…å‡ºäº†åŸå¸‚çš„æ‰¿è½½èƒ½åŠ›ï¼Œè¿˜æ˜¯å› ä¸ºæˆ‘ä»¬æœªèƒ½ä»¥æœ€å¤§æ‰¿è½½èƒ½åŠ›åˆ©ç”¨é“è·¯ç½‘ç»œï¼Ÿ\nä»¥ä¸–ç•Œä¸Šæœ€å¤§çš„ä¸¤ä¸ªåŸå¸‚ä¸ºä¾‹ã€‚ä¸œäº¬å’Œçº½çº¦å¸‚çš„äº¤é€šæ‹¥å µæŒ‡æ•°æ’åç›¸ä¼¼ã€‚ä½†æ˜¯ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸œäº¬çš„æ³¨å†Œè½¦è¾†æ¯”çº½çº¦å¸‚å¤š50ï¼…ï¼Œè€Œä¸œäº¬çš„ä¿¡å·äº¤å‰å£ä»…æ¯”çº½çº¦å¸‚å¤š15ï¼…ï¼Œé“è·¯é•¿åº¦æ¯”çº½çº¦å¤š30ï¼…ã€‚ï¼ˆä¸œäº¬ï¼šæ³¨å†Œè½¦è¾†313ä¸‡ï¼Œ äº¤é€šä¿¡å·15,000Â  ï¼Œé“è·¯24,650å…¬é‡Œã€‚ çº½çº¦å¸‚æ³¨å†Œè½¦è¾†219ä¸‡ï¼Œ äº¤é€šä¿¡å·13,000Â  ï¼Œé“è·¯18,684 kmã€‚ ï¼‰      ä¸ºä»€ä¹ˆä¸œäº¬å¯ä»¥æä¾›æ¯”çº½çº¦æ›´å¤šçš„è½¦è¾†æœåŠ¡ï¼Ÿçº½çº¦å¸‚æ˜¯å¦ä»¥æœ€å¤§è½½å®¢é‡è¿è¥äº¤é€šï¼Ÿä½œä¸ºæ•°æ®ç§‘å­¦å®¶ï¼Œæˆ‘ä»¬é‚€è¯·æ‚¨åè°ƒäº¤é€šï¼Œå¹¶æ ¹æ®åŸå¸‚è§„æ¨¡çš„è·¯ç½‘åŠå…¶äº¤é€šéœ€æ±‚æ‰¾åˆ°æœ€å¤§äº¤é€šå®¹é‡ã€‚\næ¯”èµ›æè¿° åœ¨è¿™ä¸€æŒ‘æˆ˜ä¸­ï¼Œæˆ‘ä»¬å°†ä¸ºæ‚¨æä¾›ä¸€ä¸ªåŸå¸‚è§„æ¨¡çš„é“è·¯ç½‘ç»œï¼Œå…¶äº¤é€šéœ€æ±‚æ¥è‡ªçœŸå®çš„äº¤é€šæ•°æ®ã€‚æ‚¨å°†è´Ÿè´£åè°ƒä¿¡å·äº¤å‰å£çš„äº¤é€šï¼ŒåŒæ—¶å°†å»¶è¿ŸæŒ‡æ•°ä¿æŒåœ¨é¢„å®šä¹‰çš„é˜ˆå€¼ä»¥ä¸‹ã€‚æˆ‘ä»¬å°†å¢åŠ æµé‡éœ€æ±‚ï¼Œå¹¶æŸ¥çœ‹æ‚¨çš„åè°ƒæ¨¡å‹æ˜¯å¦ä»ç„¶å¯ä»¥å‡‘æ•ˆã€‚\nä¸ºäº†ä¿ƒè¿›æ‚¨çš„æ–¹æ³•å¼€å‘ï¼Œæˆ‘ä»¬å°†é¦–æ¬¡å‘å¸ƒCity Brain Open Research Platformã€‚è¯¥å¹³å°åŒ…å«ä¸€ä¸ªåŸå¸‚è§„æ¨¡çš„äº¤é€šæ¨¡æ‹Ÿç¯å¢ƒå’Œä¸€ä¸ªå…·æœ‰å¤šæ ¸è®¡ç®—æœºçš„äº‘è®¡ç®—é›†ç¾¤ã€‚ æ—¶é—´çº¿  æŠ¥å 4/1/2021  å‚èµ›é€‰æ‰‹ç†Ÿæ‚‰åŒºåŸŸäº¤é€šçš„æ•°æ®ä»¥åŠç†Ÿæ‚‰æ¨¡æ‹Ÿç¯å¢ƒã€‚\n å‚èµ› 5/1/2021  å‚ä¸è€…å°†è¿›è¡ŒåŸå¸‚è§„æ¨¡çš„äº¤é€šåè°ƒã€‚å¯ä»¥å¤„ç†æ›´å¤§æµé‡éœ€æ±‚çš„å›¢é˜Ÿå°†è¿›å…¥æœ€åä¸€è½®ã€‚\n æœ€ç»ˆæäº¤ 6/1/2021  æä¾›å¤§è§„æ¨¡çš„äº‘è®¡ç®—å¹³å°ã€‚å›¢é˜Ÿå°†å¼€å‘æ–¹æ³•æ¥å¤„ç†åŸå¸‚èŒƒå›´å†…å„ç§æœªçŸ¥çš„äº¤é€šæµé‡ã€‚\n æ¯”èµ›ç»“æŸ 7/1/2021  æ¯”èµ›å¥–åŠ± å¥–é‡‘ï¼š\n ç¬¬ä¸€åï¼š$ 3000 ç¬¬äºŒåï¼š$ 2000 ç¬¬ä¸‰åï¼š$ 1000 ç¬¬å››è‡³ç¬¬ååï¼š$ 500  ç ”ç©¶æ”¯æŒï¼š\n å¤§è§„æ¨¡è®¡ç®—èµ„æº æ½œåœ¨çš„ç°å®ä¸–ç•Œçº§ç ”ç©¶å®éªŒ çº¸è´¨å‡ºç‰ˆç‰©çš„å…¶ä»–æ”¯æŒ  èµ›é¢˜3 å¤§å‹å›¾æœºå™¨å­¦ä¹ æ¯”èµ›ï¼š OGB-LSC  OGB Large-Scale Challenge https://ogb.stanford.edu/kddcup2021/\n ä¸ºä»€ä¹ˆè¦ä¸¾è¡Œå¤§å‹å›¾MLæ¯”èµ›ï¼Ÿ ç”±äºåœ¨å®é™…åº”ç”¨ä¸­æ™®éä½¿ç”¨å›¾ç»“æ„åŒ–æ•°æ®ï¼Œå› æ­¤å›¾ä¸Šçš„æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰è¿‘å¹´æ¥å¼•èµ·äº†æå¤§çš„å…³æ³¨ã€‚ç°ä»£åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç½‘ç»œè§„æ¨¡çš„ç¤¾äº¤ç½‘ç»œï¼Œæ¨èç³»ç»Ÿï¼Œè¶…é“¾æ¥çš„ç½‘ç»œæ–‡æ¡£ï¼ŒçŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ï¼Œä»¥åŠé€šè¿‡ä¸æ–­å¢é•¿çš„ç§‘å­¦è®¡ç®—ç”Ÿæˆçš„åˆ†å­æ¨¡æ‹Ÿæ•°æ®ã€‚è¿™äº›åŸŸæ¶‰åŠå…·æœ‰æ•°åäº¿ä¸ªè¾¹çš„å¤§è§„æ¨¡å›¾å½¢æˆ–å…·æœ‰æ•°ç™¾ä¸‡ä¸ªå›¾å½¢çš„æ•°æ®é›†ã€‚å¤§è§„æ¨¡éƒ¨ç½²å‡†ç¡®çš„å›¾MLå°†äº§ç”Ÿå·¨å¤§çš„å®é™…å½±å“ï¼Œä»è€Œå®ç°æ›´å¥½çš„æ¨èç»“æœï¼Œæ”¹è¿›çš„Webæ–‡æ¡£æœç´¢ï¼Œæ›´å…¨é¢çš„KGä»¥åŠåŸºäºMLçš„å‡†ç¡®è¯ç‰©å’Œææ–™å‘ç°ã€‚\nç„¶è€Œï¼Œç¤¾åŒºåœ¨å¤§è§„æ¨¡å›¾å½¢MLä¸­å‘å±•æœ€æ–°æŠ€æœ¯çš„åŠªåŠ›éå¸¸æœ‰é™ã€‚å®é™…ä¸Šï¼Œå¤„ç†å¤§è§„æ¨¡å›¾å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæœ€å…ˆè¿›çš„è¡¨è¾¾æ€§å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ï¼Œå› ä¸ºå®ƒä»¬ä¼šæ ¹æ®æ¥è‡ªè®¸å¤šå…¶ä»–èŠ‚ç‚¹çš„ä¿¡æ¯å¯¹æ¯ä¸ªèŠ‚ç‚¹è¿›è¡Œé¢„æµ‹ã€‚è¦æœ‰æ•ˆåœ°å¤§è§„æ¨¡è®­ç»ƒè¿™äº›æ¨¡å‹ï¼Œå°±éœ€è¦å¤æ‚çš„ç®—æ³•ï¼Œè€Œè¿™äº›ç®—æ³•è¿œè¿œè¶…å‡ºäº†åŸºäºiidæ•°æ®çš„æ ‡å‡†SGDã€‚æœ€è¿‘ï¼Œç ”ç©¶äººå‘˜é€šè¿‡æ˜¾ç€ç®€åŒ–GNNæ¥æé«˜æ¨¡å‹å¯ä¼¸ç¼©æ€§ï¼Œè¿™ä¸å¯é¿å…åœ°é™åˆ¶äº†å®ƒä»¬çš„è¡¨è¾¾èƒ½åŠ›ã€‚\nä½†æ˜¯ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œä¸€éåˆä¸€éåœ°è¡¨æ˜ï¼Œäººä»¬éœ€è¦å¤§å‹çš„è¡¨è¾¾æ¨¡å‹å¹¶åœ¨å¤§æ•°æ®ä¸Šå¯¹å…¶è¿›è¡Œè®­ç»ƒï¼Œä»¥å®ç°æœ€ä½³æ€§èƒ½ã€‚åœ¨å›¾MLä¸­ï¼Œè¶‹åŠ¿æ˜¯ç›¸åçš„-æ¨¡å‹å˜å¾—ç®€åŒ–ä¸”è¡¨è¾¾èƒ½åŠ›è¾ƒå¼±ï¼Œå› æ­¤æ— æ³•ç¼©æ”¾åˆ°å¤§å›¾ã€‚å› æ­¤ï¼Œå­˜åœ¨ç€å·¨å¤§çš„æœºä¼šæ¥ç§»åŠ¨ç¤¾åŒºä»¥ä½¿ç”¨ç°å®çš„å’Œå¤§è§„æ¨¡çš„å›¾å½¢æ•°æ®é›†ï¼Œå¹¶å°†é¢†åŸŸçš„çŠ¶æ€å‘å‰ç§»åŠ¨åˆ°éœ€è¦çš„åœ°æ–¹ã€‚\nOGB-LSCæ¦‚è¿° åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤§å‹å›¾MLç«èµ›ï¼Œå³OGBå¤§å‹æŒ‘æˆ˜èµ›ï¼ˆOGB-LSCï¼‰ï¼Œä»¥é¼“åŠ±å¼€å‘é€‚ç”¨äºæµ·é‡ç°ä»£æ•°æ®é›†çš„æœ€æ–°å›¾MLæ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æä¾›äº†ä¸‰ä¸ªæ•°æ®é›†ï¼šMAG240M-LSC ï¼ŒWikiKG90M-LSC å’ŒPCQM4M-LSC ï¼Œå®ƒä»¬çš„è§„æ¨¡ç©ºå‰å¤§ï¼Œå¹¶ä¸”åˆ†åˆ«è¦†ç›–äº†èŠ‚ç‚¹ï¼Œé“¾æ¥å’Œå›¾å½¢çº§åˆ«çš„é¢„æµ‹ã€‚Â æ¯ä¸ªæ•°æ®é›†æä¾›ä¸€ä¸ªç‹¬ç«‹çš„ä»»åŠ¡ï¼Œä¼˜èƒœè€…å°†åˆ†åˆ«ä¸ºæ¯ä¸ªæ•°æ®é›†é€‰æ‹©ã€‚Â æˆ‘ä»¬å°†å®£å¸ƒæ¯ä¸ªæ•°æ®é›†çš„å‰3åè·èƒœå›¢é˜Ÿï¼ˆæ€»å…±9ä¸ªè·èƒœå›¢é˜Ÿï¼‰ï¼Œä»–ä»¬å°†æœ‰æœºä¼šåœ¨KDD Cupç ”è®¨ä¼šä¸Šå±•ç¤ºä»–ä»¬çš„è§£å†³æ–¹æ¡ˆã€‚ ä¸‹é¢æä¾›äº†ä¸‰ä¸ªOGB-LSCæ•°æ®é›†çš„è¯´æ˜æ€§æ¦‚è¿°ï¼š  **MAG240M-LSC **æ˜¯ä¸€ä¸ªå¼‚æ„çš„å­¦æœ¯å›¾ï¼Œå…¶ä»»åŠ¡æ˜¯é¢„æµ‹ä½äºå¼‚æ„å›¾ä¸­çš„è®ºæ–‡çš„ä¸»é¢˜åŒºåŸŸï¼ˆèŠ‚ç‚¹åˆ†ç±»ï¼‰ã€‚ **WikiKG90M-LSC **æ˜¯ä¸€ä¸ªçŸ¥è¯†å›¾ï¼Œå…¶ä»»åŠ¡æ˜¯ä¼°ç®—ç¼ºå°‘çš„ä¸‰å…ƒç»„ï¼ˆé“¾æ¥é¢„æµ‹ï¼‰ã€‚ **PCQM4M-LSC **æ˜¯é‡å­åŒ–å­¦æ•°æ®é›†ï¼Œå…¶ä»»åŠ¡æ˜¯é¢„æµ‹ç»™å®šåˆ†å­çš„é‡è¦åˆ†å­ç‰¹æ€§ï¼Œå³HOMO-LUMOé—´éš™ï¼ˆå›¾å½¢å›å½’ï¼‰ã€‚  å¯¹äºæ¯ä¸ªæ•°æ®é›†ï¼Œæˆ‘ä»¬éƒ½ä¼šä»”ç»†è®¾è®¡å…¶é¢„æµ‹ä»»åŠ¡å’Œæ•°æ®æ‹†åˆ†ï¼Œä»¥ä¾¿åœ¨ä»»åŠ¡ä¸Šå®ç°è¾ƒé«˜çš„é¢„æµ‹æ€§èƒ½å°†ç›´æ¥å½±å“ç›¸åº”çš„åº”ç”¨ç¨‹åºã€‚æ¯ä¸ªæ•°æ®é›†é¡µé¢ä¸­éƒ½æä¾›äº†æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚\næ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯å’ŒåŸºæœ¬ä¿¡æ¯æ€»ç»“å¦‚ä¸‹ï¼Œè¡¨æ˜æˆ‘ä»¬çš„æ•°æ®é›†éå¸¸å¤§ã€‚ æ‰€æœ‰è¿™äº›æ•°æ®é›†éƒ½å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„ogbPythonåŒ… ä¸‹è½½å¹¶å‡†å¤‡ã€‚Â æ¨¡å‹è¯„ä¼°å’Œæµ‹è¯•æäº¤æ–‡ä»¶çš„å‡†å¤‡å·¥ä½œä¹Ÿç”±æˆ‘ä»¬çš„è½¯ä»¶åŒ…å¤„ç†ã€‚Â ç”¨æ³•åœ¨æ¯ä¸ªæ•°æ®é›†é¡µé¢ä¸­éƒ½æœ‰æè¿°ã€‚è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼å®‰è£…/æ›´æ–°ï¼š\nåœ¨æˆ‘ä»¬çš„**è®ºæ–‡ä¸­ **ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¯¹æ¯ä¸ªæ•°æ®é›†è¿›è¡Œäº†å¹¿æ³›çš„åŸºçº¿åˆ†æï¼Œå¤§è§„æ¨¡å®ç°äº†ç®€å•çš„åŸºçº¿æ¨¡å‹ä»¥åŠé«˜çº§çš„è¡¨è¾¾æ¨¡å‹ã€‚æˆ‘ä»¬å‘ç°ï¼Œå°½ç®¡éœ€è¦æ›´å¤šçš„åŠªåŠ›æ¥è¿›è¡Œæ‰©å±•ï¼Œä½†å…ˆè¿›çš„è¡¨è¾¾æ¨¡å‹ç¡®å®ä¼šä»å¤§æ•°æ®ä¸­å—ç›Šï¼Œå¹¶ä¸”æ˜æ˜¾ä¼˜äºæ˜“äºæ‰©å±•çš„ç®€å•åŸºçº¿æ¨¡å‹ã€‚æˆ‘ä»¬æ‰€æœ‰çš„åŸºå‡†ä»£ç å‡å·²**å…¬å¼€æä¾›ï¼Œ **ä»¥æ–¹ä¾¿å…¬ä¼—ç ”ç©¶ã€‚\npip install -U ogb # Make sure below prints the required package version for the dataset you are working on. python -c \u0026quot;import ogb; print(ogb.__version__)\u0026quot; æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„KDDæ¯å°†é¼“åŠ±ç¤¾åŒºå¼€å‘å’Œæ‰©å±•è¡¨è¾¾æ€§å›¾MLæ¨¡å‹ï¼Œè¿™å¯ä»¥åœ¨å„ä¸ªé¢†åŸŸå–å¾—é‡å¤§çªç ´ã€‚æˆ‘ä»¬å¸Œæœ›åœ¨2021å¹´KDDæ¯ä¸Šçš„OGB-LSCèƒ½å¤Ÿæˆä¸ºå›¾MLé¢†åŸŸçš„â€œ ImageNetå¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜â€ï¼Œé¼“åŠ±ç¤¾åŒºè‡´åŠ›äºç°å®å’Œå¤§è§„æ¨¡çš„å›¾æ•°æ®é›†ï¼Œå¹¶æ˜¾ç€æé«˜ç°çŠ¶-è‰ºæœ¯ã€‚ OGB-LSCæ•°æ®é›†è®ºæ–‡ \nKaggleæ–°èµ›é¢˜ èµ›é¢˜1 Shopee - Price Match Guarantee é€šè¿‡ä¸¤ä¸ªå›¾åƒç¡®å®šä¸¤ä¸ªäº§å“æ˜¯å¦ç›¸åŒ\n https://www.kaggle.com/c/shopee-product-matching/overview/description\n è¯„ä¼°æŒ‡æ ‡ é‡‡ç”¨F1-Scoreï¼Œå‚èµ›ä½œå“å°†æ ¹æ®å…¶å¹³å‡F1åˆ†æ•° è¿›è¡Œè¯„ä¼°ã€‚å‡å€¼ä»¥æ ·æœ¬æ–¹å¼è®¡ç®—ï¼Œè¿™æ„å‘³ç€å°†ä¸ºæ¯ä¸ªé¢„æµ‹è¡Œè®¡ç®—F1åˆ†æ•°ï¼Œç„¶åå–å¹³å‡å€¼ã€‚\né€‰æ‰‹å¿…é¡»åˆ›å»ºä¸€ä¸ªä»¥ç©ºæ ¼åˆ†éš”çš„åˆ—è¡¨ï¼Œposting_idè¯¥åˆ—è¡¨ä¸è¯¥posting_idåˆ—ä¸­çš„å‘å¸ƒåŒ¹é…çš„æ‰€æœ‰ã€‚å¸–å­æ€»æ˜¯è‡ªæˆ‘åŒ¹é…çš„ã€‚åŒ¹é…ä¸ªæ•°ä¸Šé™ä¸º50ï¼Œå› æ­¤é¢„æµ‹50åœºä»¥ä¸Šçš„å¯¹æ¯”èµ›æ²¡æœ‰å¥½å¤„ã€‚\nè¯¥æ–‡ä»¶åº”æœ‰ä¸€ä¸ªæ ‡é¢˜ï¼Œåä¸ºsubmission.csvï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\nposting_id,matches test_123,test_123 test_456,test_456 test_789 æ‚¨åº”è¯¥é¢„æµ‹æ¯ä¸ªæ¯”èµ›posting_idã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨è®¤ä¸ºAä¸Bå’ŒCç›¸åŒ¹é…ï¼Œåˆ™A,A B Cè¿˜åº”åŒ…å«B,B A Cå’ŒC,C A Bã€‚\næ—¶é—´çº¿  2021 å¹´3æœˆ8æ—¥-æ¯”èµ›å¼€å§‹æ—¥æœŸ 2021 å¹´5æœˆ3æ—¥-æŠ¥åæˆªæ­¢æ—¥æœŸã€‚æ‚¨å¿…é¡»åœ¨æ­¤æ—¥æœŸä¹‹å‰æ¥å—æ¯”èµ›è§„åˆ™æ‰èƒ½å‚åŠ æ¯”èµ›ã€‚ 2021 å¹´5æœˆ3æ—¥-åˆå¹¶å›¢é˜Ÿæˆªæ­¢æ—¥æœŸã€‚è¿™æ˜¯å‚ä¸è€…å¯ä»¥åŠ å…¥æˆ–åˆå¹¶å›¢é˜Ÿçš„æœ€åä¸€å¤©ã€‚ 2021 å¹´5æœˆ10æ—¥-æœ€ç»ˆæäº¤æˆªæ­¢æ—¥æœŸã€‚  å¥–é‡‘  ç¬¬ä¸€å-$ 15,000 ç¬¬äºŒå-$ 10,000 ç¬¬ä¸‰å-$ 5,000  æ•°æ®é›† åœ¨å¤§å‹æ•°æ®é›†ä¸­æŸ¥æ‰¾è¿‘é‡å¤é¡¹æ˜¯è®¸å¤šåœ¨çº¿ä¸šåŠ¡çš„é‡è¦é—®é¢˜ã€‚å¯¹äºShopeeï¼Œæ—¥å¸¸ç”¨æˆ·å¯ä»¥ä¸Šä¼ è‡ªå·±çš„å›¾åƒå¹¶æ’°å†™è‡ªå·±çš„äº§å“è¯´æ˜ï¼Œä»è€Œå¢åŠ äº†æŒ‘æˆ˜ã€‚æ‚¨çš„ä»»åŠ¡æ˜¯ç¡®å®šå“ªäº›äº§å“å·²é‡å¤å‘å¸ƒã€‚ç›¸å…³äº§å“ä¹‹é—´çš„å·®å¼‚å¯èƒ½å¾®å¦™ï¼Œè€Œç›¸åŒäº§å“çš„ç…§ç‰‡åˆ™å¯èƒ½åƒå·®ä¸‡åˆ«ï¼\nç”±äºè¿™æ˜¯ä¸€åœºä»£ç ç«èµ›ï¼Œå› æ­¤ä»…å‘å¸ƒæµ‹è¯•é›†çš„å‰å‡ è¡Œ/å›¾åƒï¼›å…¶ä½™çš„ä»…åœ¨æäº¤ç¬”è®°æœ¬åæ‰å¯¹æ‚¨çš„ç¬”è®°æœ¬å¯ç”¨ã€‚é¢„è®¡å°†åœ¨éšè—çš„æµ‹è¯•é›†ä¸­æ‰¾åˆ°å¤§çº¦70,000å¼ å›¾åƒã€‚æä¾›çš„ä¸€äº›æµ‹è¯•è¡Œå’Œå›¾åƒæ—¨åœ¨è¯´æ˜éšè—çš„æµ‹è¯•é›†æ ¼å¼å’Œæ–‡ä»¶å¤¹ç»“æ„ã€‚\n **[train / test] .csv-**è®­ç»ƒé›†æ•°æ®ã€‚æ¯è¡ŒåŒ…å«ä¸€æ¬¡è¿‡å¸çš„æ•°æ®ã€‚å¤šä¸ªè®¢å•å¯èƒ½å…·æœ‰å®Œå…¨ç›¸åŒçš„å›¾åƒIDï¼Œä½†æ ‡é¢˜ä¸åŒï¼Œåä¹‹äº¦ç„¶ã€‚    posting_idÂ -å‘å¸ƒçš„IDç ã€‚\n  imageÂ -å›¾ç‰‡ID / md5sumã€‚\n  image_phash-å›¾åƒçš„æ„ŸçŸ¥å“ˆå¸Œ ã€‚\n  titleÂ -å‘å¸ƒçš„äº§å“è¯´æ˜ã€‚\n  label_group-æ˜ å°„åˆ°åŒä¸€äº§å“çš„æ‰€æœ‰å‘å¸ƒçš„IDç ã€‚æœªæä¾›æµ‹è¯•é›†ã€‚\n  [train / test]Â images-ä¸å‘å¸ƒç›¸å…³çš„å›¾åƒã€‚\n**sample_submission.csv-**æ ¼å¼æ­£ç¡®çš„ç¤ºä¾‹æäº¤æ–‡ä»¶ã€‚\n  posting_idÂ -å‘å¸ƒçš„IDç ã€‚\n  matches-ä»¥ç©ºæ ¼åˆ†éš”çš„ä¸æ­¤å‘å¸ƒåŒ¹é…çš„æ‰€æœ‰å‘å¸ƒIDçš„åˆ—è¡¨ã€‚postingæ˜¯è‡ªæˆ‘åŒ¹é…ï¼ŒåŒ¹é…ä¸ªæ•°ä¸Šé™ä¸º50ï¼Œå› æ­¤æ— éœ€é¢„æµ‹è¶…è¿‡50ä¸ªæ•°ã€‚\n  èµ›é¢˜2 Bristol-Myers Squibb â€“ Molecular Translation åŒ–å­¦åˆ†å­å›¾åƒè½¬æ¢ä¸ºåŒ–å­¦ç»“æ„åºåˆ— https://www.kaggle.com/c/bms-molecular-translation\nèƒŒæ™¯æè¿° åœ¨æŠ€æœ¯è¿›æ­¥çš„ä¸–ç•Œä¸­ï¼Œæœ‰æ—¶æœ€å¥½ï¼Œæœ€ç®€å•çš„å·¥å…·ä»ç„¶æ˜¯çº¸å’Œç¬”ã€‚æœ‰æœºåŒ–å­¦å®¶ç»å¸¸åˆ©ç”¨éª¨æ¶å¼ï¼ˆSkeletal formulaï¼‰æ¥ç»˜åˆ¶åˆ†å­å·¥ä½œï¼Œéª¨æ¶å¼æ˜¯ä¸€ä¸ªä¸–çºªä»¥æ¥ä½¿ç”¨çš„ç»“æ„ç¬¦å·ã€‚æœ€è¿‘çš„å‡ºç‰ˆç‰©è¿˜ç”¨æœºå™¨å¯è¯»çš„åŒ–å­¦æè¿°ï¼ˆInChIï¼‰è¿›è¡Œäº†æ³¨é‡Šï¼Œä½†æ˜¯æ•°åå¹´çš„æ‰«ææ–‡æ¡£æ— æ³•è‡ªåŠ¨æœç´¢ç‰¹å®šçš„åŒ–å­¦æè¿°ã€‚åœ¨æœºå™¨å­¦ä¹ çš„å¸®åŠ©ä¸‹ï¼Œå…‰å­¦åŒ–å­¦ç»“æ„çš„è‡ªåŠ¨è¯†åˆ«å¯ä»¥åŠ å¿«ç ”å‘çš„é€Ÿåº¦ã€‚\nä¸å¹¸çš„æ˜¯ï¼Œå¤§å¤šæ•°å…¬å…±æ•°æ®é›†å¤ªå°ï¼Œæ— æ³•æ”¯æŒç°ä»£æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ç°æœ‰å·¥å…·åªèƒ½åœ¨æœ€ä½³æ¡ä»¶ä¸‹äº§ç”Ÿ90ï¼…çš„ç²¾åº¦ã€‚å†å²æ¥æºé€šå¸¸ä¼šåœ¨æŸç§ç¨‹åº¦ä¸Šç ´åå›¾åƒï¼Œä»è€Œå°†æ€§èƒ½é™ä½åˆ°æ¥è¿‘é›¶ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œéœ€è¦è€—æ—¶çš„æ‰‹åŠ¨æ“ä½œæ‰èƒ½å°†æ‰«æçš„åŒ–å­¦ç»“æ„å›¾åƒå¯é åœ°è½¬æ¢ä¸ºæœºå™¨å¯è¯»æ ¼å¼ã€‚\nç™¾æ—¶ç¾æ–½è´µå®å…¬å¸æ˜¯ä¸€å®¶å…¨çƒæ€§ç”Ÿç‰©åˆ¶è¯å…¬å¸ï¼Œè‡´åŠ›äºé€šè¿‡ç§‘å­¦æ”¹å˜æ‚£è€…çš„ç”Ÿæ´»ã€‚ä»–ä»¬çš„ä»»åŠ¡æ˜¯å‘ç°ï¼Œå¼€å‘å’Œæä¾›å¯å¸®åŠ©æ‚£è€…æˆ˜èƒœä¸¥é‡ç–¾ç—…çš„åˆ›æ–°è¯ç‰©ã€‚\nåœ¨è¿™åœºæ¯”èµ›ä¸­ï¼Œæ‚¨å°†è§£é‡Šæ—§çš„åŒ–å­¦å›¾åƒã€‚é€šè¿‡è®¿é—®ç”±Bristol-Myers Squibbç”Ÿæˆçš„å¤§é‡åˆæˆå›¾åƒæ•°æ®ï¼Œæ‚¨å¯ä»¥å°†å›¾åƒè½¬æ¢å›æ ‡æ³¨ä¸ºInChIæ–‡æœ¬çš„åŸºç¡€åŒ–å­¦ç»“æ„ã€‚\næ•´ç†åŒ–å­¦æ–‡çŒ®çš„å·¥å…·å°†å¯¹ç ”ç©¶äººå‘˜å¸¦æ¥é‡å¤§å¥½å¤„ã€‚å¦‚æœæˆåŠŸï¼Œæ‚¨å°†å¸®åŠ©åŒ–å­¦å®¶æ‰©å¤§è¿›è¡Œé›†ä½“åŒ–å­¦ç ”ç©¶çš„æœºä¼šã€‚åè¿‡æ¥ï¼Œé€šè¿‡é¿å…é‡å¤å…ˆå‰å‘è¡¨çš„åŒ–å­¦æ–¹æ³•ï¼Œå¹¶é€šè¿‡æŒ–æ˜å¤§æ•°æ®é›†æ¥è¯†åˆ«æ–°è¶‹åŠ¿ï¼Œè¿™å°†åŠ å¿«è®¸å¤šå…³é”®é¢†åŸŸçš„ç ”å‘å·¥ä½œã€‚\nè¯„ä¼°æŒ‡æ ‡ æ ¹æ®æ‚¨æäº¤çš„InChiå­—ç¬¦ä¸²ä¸åœ°é¢çœŸå®InChiå€¼ä¹‹é—´çš„å¹³å‡Levenshteinè·ç¦» è¯„ä¼°æäº¤çš„å†…å®¹ã€‚\næäº¤æ–‡ä»¶ å¯¹äºimage_idæµ‹è¯•é›†ä¸­çš„æ¯ä¸€ä¸ªï¼Œæ‚¨å¿…é¡»åœ¨ç›¸åº”çš„å›¾åƒä¸­é¢„æµ‹åˆ†å­çš„InChiå­—ç¬¦ä¸²ã€‚è¯¥æ–‡ä»¶åº”åŒ…å«æ ‡å¤´ï¼Œå¹¶å…·æœ‰ä»¥ä¸‹æ ¼å¼ï¼š\nimage_id,InChI 00000d2a601c,InChI=1S/H2O/h1H2 00001f7fc849,InChI=1S/H2O/h1H2 000037687605,InChI=1S/H2O/h1H2 etc. æ—¶é—´è½´  2021 å¹´3æœˆ2æ—¥-æ¯”èµ›å¼€å§‹æ—¥æœŸ 2021 å¹´5æœˆ26æ—¥-æŠ¥åæˆªæ­¢æ—¥æœŸã€‚æ‚¨å¿…é¡»åœ¨æ­¤æ—¥æœŸä¹‹å‰æ¥å—æ¯”èµ›è§„åˆ™æ‰èƒ½å‚åŠ æ¯”èµ›ã€‚ 2021 å¹´5æœˆ26æ—¥-åˆå¹¶å›¢é˜Ÿæˆªæ­¢æ—¥æœŸã€‚è¿™æ˜¯å‚ä¸è€…å¯ä»¥åŠ å…¥æˆ–åˆå¹¶å›¢é˜Ÿçš„æœ€åä¸€å¤©ã€‚ 2021 å¹´6æœˆ2æ—¥-æœ€ç»ˆæäº¤æˆªæ­¢æ—¥æœŸã€‚  å¥–é‡‘  ç¬¬ä¸€å-$ 25,000 ç¬¬äºŒå-$ 15,000 ç¬¬ä¸‰å-$ 10,000  æ•°æ®é›† åœ¨æœ¬æ¬¡æ¯”èµ›ä¸­ï¼Œæ‚¨å°†è·å¾—åŒ–å­¦å“çš„å›¾åƒï¼Œç›®çš„æ˜¯é¢„æµ‹å›¾åƒä¸­ç›¸åº”çš„å›½é™…åŒ–å­¦å“è¯†åˆ«ç  ï¼ˆInChIï¼‰æ–‡æœ¬å­—ç¬¦ä¸²ã€‚æ‰€æä¾›çš„å›¾åƒï¼ˆè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ä¸­çš„å›¾åƒï¼‰éƒ½å¯ä»¥æ—‹è½¬åˆ°ä¸åŒçš„è§’åº¦ï¼Œå…·æœ‰ä¸åŒçš„åˆ†è¾¨ç‡ï¼Œå¹¶ä¸”å…·æœ‰ä¸åŒçš„å™ªå£°æ°´å¹³ã€‚\n**æ³¨æ„ï¼š**æ­¤æ•°æ®é›†ä¸­æ€»å…±çº¦æœ‰4må¼ å›¾åƒã€‚è§£å‹ç¼©ä¸‹è½½çš„æ•°æ®å°†èŠ±è´¹æ—¶é—´ã€‚\n train / -è®­ç»ƒå›¾åƒï¼Œç”±3çº§æ–‡ä»¶å¤¹ç»“æ„æ’åˆ—image_id  test / -æµ‹è¯•å›¾åƒï¼Œä¸æ–‡ä»¶å¤¹ä½äºç›¸åŒçš„æ–‡ä»¶å¤¹ç»“æ„ä¸­train/ train_labels.csv-è®­ç»ƒå›¾åƒçš„åœ°é¢çœŸç›¸InChiæ ‡ç­¾ sample_submission.csv-æ ¼å¼æ­£ç¡®çš„æ ·æœ¬æäº¤æ–‡ä»¶  ","permalink":"/posts/%E6%AF%94%E8%B5%9B%E6%8E%A8%E9%80%81/kaggle%E9%A1%B6%E7%BA%A7%E8%B5%9B%E4%BA%8B%E7%AD%89%E4%BD%A0%E6%9D%A5%E6%8E%92%E4%BD%8D/","series":["æ¯”èµ›æ¨é€"],"tags":["æ¯”èµ›æ¨é€"],"title":"ã€æ¯”èµ›æ¨é€ã€‘KDD 2021/ Kaggle é¡¶çº§èµ›äº‹ç­‰ä½ æ¥æ’ä½"},{"categories":["æ‹›è˜ä¿¡æ¯"],"content":"1 äº¬ä¸œæ¢ç´¢ç ”ç©¶é™¢ï¼ˆç¤¾æ‹›ï¼‰  äº¬ä¸œæˆç«‹æ¢ç´¢ç ”ç©¶é™¢ï¼Œå°†æ·±è€•â€œäººå·¥æ™ºèƒ½â€ã€â€œé‡å­è®¡ç®—â€ã€â€œæ•°æ®ç§‘å­¦ã€å·¥ç¨‹ä¸ç®¡ç†â€ã€â€œå»ä¸­å¿ƒåŒ–è®¡ç®—â€ã€â€œæŠ€æœ¯ä¼¦ç†é“å¾·â€ã€â€œç§‘å­¦ä¸è‰ºæœ¯â€å…­å¤§æŠ€æœ¯é¢†åŸŸï¼Œä»åŸºç¡€ç†è®ºå±‚é¢å®ç°é¢ è¦†å¼åˆ›æ–°ï¼Œèšç„¦äºæ‰“é€ äº§ä¸šæ•°æ™ºåŒ–é¦–ä¸ªæºå¤´æ€§ç§‘æŠ€é«˜åœ°ï¼Œæˆä¸ºæ¯”è‚©å›½é™…é¢†å…ˆç§‘ç ”æœºæ„çš„å‰æ²¿æŠ€æœ¯åŸºåœ°ï¼Œé€šè¿‡ä¸æ–­åŠªåŠ›ï¼Œåœ¨ä¸–ç•Œèˆå°ä¸Šå±•ç°ä¸€å®¶ä¸­å›½ç§‘æŠ€å…¬å¸çš„æ‹…å½“ã€é£èŒƒã€‚\n  ç°åœ¨ï¼Œäº¬ä¸œæ¢ç´¢ç ”ç©¶é™¢å°†åœ¨é‡å­è®¡ç®—ã€æœºå™¨æ„ŸçŸ¥ã€ç†è®ºç®—æ³•æ–¹å‘æ‹›å‹Ÿä¸–ç•Œé¡¶çº§ç§‘å­¦å®¶ï¼Œç»„å»ºé¦–æ‰¹ç§‘ç ”å›¢é˜Ÿï¼ŒåŒæ—¶åŠ±ä¼—æ›´å¤šâ€œé’å¹´ç§‘å­¦å®¶â€åŠ å…¥ã€‚æ”¹å˜ä¸–ç•Œï¼Œä»æ­¤åˆ»å¼€å§‹ã€‚\n 2 èš‚èšé›†å›¢ï¼ˆæ˜¥æ‹›å®ä¹ ï¼‰ å†…æ¨æ–¹å¼ï¼š\nå¤§ä½¬æœ‹å‹çš„ç»„ï¼ŒåŒå­¦ä»¬æŠ“ç´§ä¸Šè½¦ 2022æ ¡æ‹›å®ä¹ å¼€å§‹äº†ï¼Œæ‰«ç å†…æ¨ï¼Œæˆ–è€…ç›´æ¥å‘ç®€å†åˆ°yongliang.wyl@antgroup.comã€‚ é˜¿é‡Œäº‘ (æš‘æœŸå®ä¹ ) ã€é˜¿é‡Œäº‘-åˆ†å¸ƒå¼å—å­˜å‚¨ç ”å‘-æš‘æœŸå®ä¹ ç›´æ¨ã€‘ï¼ˆå®ä¹ é¢å‘2022å¹´æ¯•ä¸šçš„å­¦ç”Ÿï¼‰ ä¸€ã€å›¢é˜Ÿä»‹ç»ï¼š é˜¿é‡Œäº‘å—å­˜å‚¨å›¢é˜Ÿï¼Œç›®å‰æä¾›äº†ä¸­å›½æœ€å¤§çš„çº¿ä¸Šäº‘å­˜å‚¨æœåŠ¡ã€‚å›¢é˜Ÿç®¡ç†é«˜æ•ˆï¼ŒæŠ€æœ¯ç§¯ç´¯ä¸°å¯Œï¼ŒåŸ¹å…»ä½“ç³»æˆç†Ÿï¼Œåœ¨æ­å·ã€åŒ—äº¬å‡è®¾æœ‰å›¢é˜Ÿã€‚\näºŒã€å²—ä½èŒè´£ï¼š 1.è´Ÿè´£é˜¿é‡Œäº‘åˆ†å¸ƒå¼å—å­˜å‚¨ä¸‡äº¿çº§åˆ«ä¸šåŠ¡çš„æ¶æ„è®¾è®¡ã€ç ”å‘ï¼Œæä¾›é«˜ç¨³å®šæ€§ã€é«˜å¯é æ€§çš„åˆ†å¸ƒå¼å­˜å‚¨æœåŠ¡ï¼› 2.åœ¨ç°æœ‰ç³»ç»Ÿè®¾è®¡åŸºç¡€ä¸Šï¼Œå®Œå–„ä¼˜åŒ–ç°æœ‰ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§åŠå¯é æ€§ï¼› 3.ä¸ºç°æœ‰ç³»ç»Ÿçš„ç¨³å®šå¯é è¿è¡Œï¼Œæä¾›æŠ€æœ¯æ”¯æŒï¼›\nä¸‰ã€å²—ä½è¦æ±‚ï¼š\n æœ¬ç§‘åŠä»¥ä¸Šå­¦å†åœ¨è¯»å­¦ç”Ÿï¼Œè®¡ç®—æœºã€è½¯ä»¶å·¥ç¨‹æˆ–ç›¸å…³ä¸“ä¸šæˆ–å¤šå¹´åˆ†å¸ƒå¼å¼€å‘ç›¸å…³ç»éªŒè€…ï¼› ç†Ÿæ‚‰Linuxç³»ç»Ÿå¼€å‘ç¯å¢ƒï¼Œå…·æœ‰è‰¯å¥½çš„ä»£ç é£æ ¼å’Œè´¨é‡æ„è¯†ï¼Œç†Ÿæ‚‰C/C++ç­‰ç¼–ç¨‹è¯­è¨€ï¼ˆå…¶ä»–è¯­è¨€ä¹Ÿå¯ä»¥è€ƒè™‘ï¼Œä½†éœ€å¯¹C/C++æœ‰ä¸€å®šäº†è§£ï¼‰; æœ‰ä¼˜ç§€çš„å‘ç°åŠè§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œè‰¯å¥½çš„æ²Ÿé€šèƒ½åŠ›åŠå›¢é˜Ÿåˆä½œæ„è¯†; å¯¹åˆ†å¸ƒå¼ç³»ç»Ÿçš„æ¶æ„å’ŒåŸç†æœ‰æ·±å…¥äº†è§£è€…ä¼˜å…ˆè€ƒè™‘ï¼› æœ‰ç¼–ç¨‹ç«èµ›ç»éªŒè€…æˆ–åˆ†å¸ƒå¼ç³»ç»Ÿå¼€å‘ç»éªŒè€…ä¼˜å…ˆè€ƒè™‘ã€‚  å››ã€ç®€å†æŠ•é€’ é‚®ç®±ï¼šliangliang.sll@alibaba-inc.com qqï¼š495096408 ç›´æ¥å‘é€ç®€å†åˆ°é‚®ç®±æˆ–è€…qqè”ç³»æœ¬äºº\n3 Moka(ç¤¾æ‹›) 4 å­—èŠ‚è·³åŠ¨2021æ˜¥å­£æ ¡å›­æ‹›è˜å…¨é¢å¯åŠ¨ï¼ï¼ˆæ ¡æ‹›ï¼‰  psï¼šä¿¡æ¯æ¥è‡ªå‹åœˆï¼Œæœ‰ç–‘é—®æˆ–è€…é—®é¢˜å¯ä»¥è”ç³»åå°è¿›è¡Œå¤„ç†\n ","permalink":"/posts/%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/kaggle%E9%A1%B6%E7%BA%A7%E8%B5%9B%E4%BA%8B%E7%AD%89%E4%BD%A0%E6%9D%A5%E6%8E%92%E4%BD%8D/","series":["æ‹›è˜ä¿¡æ¯"],"tags":["æ‹›è˜ä¿¡æ¯"],"title":"ã€é˜¿é‡Œï¼Œå­—èŠ‚ï¼ŒMokaã€‘æ‹›è˜ä¿¡æ¯æ±‡æ€»ï¼ˆMLã€CVã€NLPï¼‰"}]